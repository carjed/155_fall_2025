# Simple logistic regression



```{r include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, 
  warning = FALSE,
  message = FALSE,
  error = TRUE)
```


<!-- create student notes from activity in core-->

{{< include _create_student_notes.qmd >}}

```{r}
#| echo: false
#| eval: true
make_student_notes('Simple logistic regression', '_L16-logistic-univariate.qmd')
```

<!-- pull activity from core -->

```{r knitr-opts}
#| echo: false
#| cache: false
knitr::opts_chunk$set(eval = FALSE, echo = TRUE)
```

{{< include core/_L16-logistic-univariate.qmd >}}



\
\
\
\



# Solutions


```{r eval = TRUE, echo = FALSE}
library(readr)
library(ggplot2)
library(ggmosaic)
library(dplyr)

titanic <- read_csv("https://mac-stat.github.io/data/titanic.csv")
```

## Exercise 1: Exploring age

The boxplot doesn't clearly indicate a difference in the age distributions across survivors and non-survivors, but we do notice from the density plot that there is a greater density of younger passengers among the survivors. We also see from the last plot that younger passengers tend to have a higher survival chance.

```{r eval = TRUE}
# Create a boxplot
ggplot(titanic, aes(x = factor(Survived), y = Age)) +
    geom_boxplot()

# Can flip the boxplot on its side too
ggplot(titanic, aes(y = factor(Survived), x = Age)) +
    geom_boxplot()

# Create a density plot
ggplot(titanic, aes(x = Age, color = factor(Survived))) +
    geom_density()

# Use the code below to create a plot of the fraction who survived at each age
titanic_summ <- titanic %>% 
    group_by(Age) %>%
    summarize(frac_survived = mean(Survived))

ggplot(titanic_summ, aes(x = Age, y = frac_survived)) +
    geom_point() +
    geom_smooth(se = FALSE)
```



## Exercise 2: Exploring sex and ticket class

- Females were more likely to survive than males.
- 1st class was most likely to survive, followed by 2nd then 3rd class.

```{r eval = TRUE}
# Standard bar plots
ggplot(titanic, aes(x = Sex, fill = factor(Survived))) +
    geom_bar(position = "fill")

ggplot(titanic, aes(x = PClass, fill = factor(Survived))) +
    geom_bar(position = "fill")

# Mosaic plots
ggplot(data = titanic %>% mutate(Survived = as.factor(Survived))) +
    geom_mosaic(aes(x = product(Sex), fill = Survived))

ggplot(data = titanic %>% mutate(Survived = as.factor(Survived))) +
    geom_mosaic(aes(x = product(PClass), fill = Survived))
```



## Exercise 3: Linear regression model

```{r eval = TRUE}
titanic %>% 
    count(PClass, Survived)
```

a. 

Class     | Died     | Survived | Total 
----------|----------|----------|-------
1st Class | 129      |  193     | 322
2nd Class | 160      |  119     | 279
3rd Class | 573      |  138     | 711
Total     | 862      |  450     | 1312

b. 
    - the probability of surviving among 1st class passengers: 193/322 = `r round(193/322,3)`
    - the probability of surviving among 2nd class passengers: 119/279 = `r round(119/279,3)`
    - the probability of surviving among 3rd class passengers: 138/711 = `r round(138/711,3)`
    - the difference in the probability of surviving, comparing 2nd class passengers to 1st class passengers (i.e., how much lower is the probability of 2nd class passengers as compared to 1st class passengers?): 119/279 - 193/322 = `r round(119/279 - 193/322, 3)`
    - the difference in the probability of surviving, comparing 3rd class passengers to 1st class passengers  (i.e., how much lower is the probability of 3rd class passengers as compared to 1st class passengers?): 138/711 - 193/322 = `r round(138/711 - 193/322, 3)`

c. This model can be written as: $E[Survived | PClass] = \beta_0 + \beta_1 PClass2nd + \beta_2 PClass3rd$.
    - In the context of a binary variable, the expected value/average is the same as the probability that the variable equals one. To see an example of this, calculate the average of this list of 0's and 1's: (0,0,1,1,0,1,0,1). Now calculate the proportion of 1's. What do you notice?
    - This means that we can also write this model as follows: $P[Survived = 1 | PClass] = \beta_0 + \beta_1 PClass2nd + \beta_2 PClass3rd$

```{r eval = TRUE}
lin_mod <- lm(Survived ~ PClass, data = titanic)
summary(lin_mod)
```

d. The coefficient estimates are the differences in probability from part b!
    - `(Intercept)`: the estimated probability of survival for passengers in 1st class is 0.599 (59.9%)
    - `PClass2nd`: the difference in the estimated probability of survival comparing passengers in 1st class to passengers in 2nd class is 0.173 (17.3%), where passengers in 1st class have the higher estimated survival probability
        - OR... comparing passengers in 1st class to passengers in 2nd class, the difference in the proportion of passengers that survived is 0.173 (17.3%), with 1st class having a higher proportion of passengers that survived
        - OR... the probability of survival is 17.3% lower among passengers in 2nd class than it is among passengers in 1st class
    - `PClass3rd`: the difference in the estimated probability of survival comparing passengers in 1st class to passengers in 3rd class is 0.405 (40.5%), where passengers in 1st class have the higher estimated survival probability



## Exercise 4: Logistic regression model (categorical predictor)

a. 
    - the odds of surviving among 1st class passengers: 193/129 = `r round(193/129,3)`
    - the odds of surviving among 2nd class passengers: 119/160 = `r round(119/160,3)`
    - the odds of surviving among 3rd class passengers: 138/573 = `r round(138/573,3)`
    - the ratio of the odds of surviving, comparing 2nd class passengers to 1st class passengers (i.e., how many times higher/lower is the odds of survival among 2nd class passengers as compared to 1st class passengers?): (119/160)/(193/129) = `r round((119/160) / (193/129), 3)`
    - the ratio of the odds of surviving, comparing 3rd class passengers to 1st class passengers: (138/573)/(193/129) = `r round((138/573) / (193/129), 3)`

b. $\log(Odds[Survived = 1 | PClass]) = \beta_0 + \beta_1 PClass2nd + \beta_2 PClass3rd$

```{r eval = TRUE}
log_mod <- glm(Survived ~ PClass, data = titanic, family = "binomial")

# These logistic coefficient estimates are NOT exponentiated
coef(summary(log_mod))
```

```{r eval = TRUE}
# Calculations for exponentiating coefficients
exp(0.4028778)
exp(-0.6989281)
exp(-1.8265098)
```


d. These exponentiated coefficient estimates compare to your the odds and odds ratios in part a!
    - exp(Intercept): the estimated odds of survival among passengers in first class is 1.496 (i.e., passengers in first class are 1.496 times more likely to survive than they are to die)
    - exp(PClass2nd): we estimate that the odds of survival for passengers in 2nd class are only 0.50 times as high as the odds of survival among passengers in 1st class (i.e., the odds of survival are 2 times higher among passengers in 1st class than they are among passengers in 2nd class)
    - exp(PClass3rd): we estimate that the odds of survival for passengers in 3rd class are only 0.16 times as high as the odds of survival among passengers in 1st class (i.e., the odds of survival are 1/0.16 = `r round(1/0.1609744, 2)` times higher among passengers in 1st class than they are among passengers in 3rd class)

## Exercise 5: Logistic regression model (quantitative predictor)

a. After fitting the logistic regression model below, write out the model formula using correct notation.

```{r eval = TRUE}
log_mod <- glm(Survived ~ Age, data = titanic, family = "binomial")
coef(summary(log_mod))
```

$\log(Odds[Survived = 1 | Age]) = \beta_0 + \beta_1 Age$

b. Write an interpretation of each of the *exponentiated* coefficients in this logistic regression model.

- exp(Intercept): $exp(-0.0814)=0.92$ --> the estimated odds of survival among passengers who are 0 years old is 0.92 (i.e., passengers who are 0 years old are 0.92 times more likely to survive than they are to die--so very slightly *more* likely to die)
- exp(Age): $exp(-0.0088)=0.99$ --> For every 1-year increase in a passenger's age, the estimated odds of survival *decrease* by about 1%.

## Exercise 6: Linear vs. logistic modeling

To highlight a key difference between linear vs. logistic modeling, consider the following linear and logistic regression models of survival with sex and age as predictors in addition to ticket class.

```{r eval = TRUE}
lin_mod2 <- lm(Survived ~ PClass + Sex + Age, data = titanic)
coef(summary(lin_mod2))

log_mod2 <- glm(Survived ~ PClass + Sex + Age, data = titanic, family = "binomial")
coef(summary(log_mod2))
```

a.

```{r eval = TRUE}
## predict for Rose
## (by hand)
1.130523 + (-0.207434)*0 + (-0.393344)*0 + (-0.501326)*0 + (-0.006005)*17

## (using predict)
predict(lin_mod2, newdata = data.frame(PClass = "1st", Sex = "female", Age = 17))

## predict for Jack
## (by hand)
1.130523 + (-0.207434)*0 + (-0.393344)*1 + (-0.501326)*1 + (-0.006005)*20

## (using predict)
predict(lin_mod2, newdata = data.frame(PClass = "3rd", Sex = "male", Age = 20))
```


b. 

```{r eval = TRUE}
## predict for Rose
## (by hand)
log_odds_rose <- 3.75966210 + (-1.29196240)*0 + (-2.52141915)*0 + (-2.63135683)*0 + (-0.03917681)*17
odds_rose <- exp(log_odds_rose)
odds_rose/(1+odds_rose)

## (using predict)
predict(log_mod2, newdata = data.frame(PClass = "1st", Sex = "female", Age = 17), type = "response")

## predict for Jack
## (by hand)
log_odds_jack <- 3.75966210 + (-1.29196240)*0 + (-2.52141915)*1 + (-2.63135683)*1 + (-0.03917681)*20
odds_jack <- exp(log_odds_jack)
odds_jack/(1+odds_jack)

## (using predict)
predict(log_mod2, newdata = data.frame(PClass = "3rd", Sex = "male", Age = 20), type = "response")
```

c. Our linear model predicted that Rose's probability of survival was over 100% (which doesn't make sense). The predictions for Jack are fairly similar: 10.2% based on our logistic model and 11.6% based on our linear model.


