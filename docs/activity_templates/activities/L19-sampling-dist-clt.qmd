# Sampling distributions & the CLT



<!-- NOTES to instructor: -->


<!-- - I didn't put in any readings or math boxes. -->
<!-- - I recommend doing the first 3 exercises together -->




```{r include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, 
  warning = FALSE,
  message = FALSE,
  error = TRUE)
```


<!-- create student notes from activity in core-->

{{< include _create_student_notes.qmd >}}

```{r}
#| echo: false
#| eval: true
make_student_notes('Sampling distributions & the CLT', '_L19-sampling-dist-clt.qmd')
```

<!-- pull activity from core -->

```{r knitr-opts}
#| echo: false
#| cache: false
knitr::opts_chunk$set(eval = FALSE, echo = TRUE)
```

{{< include core/_L19-sampling-dist-clt.qmd >}}


\
\
\
   
  



# Solutions

```{r eval = TRUE, echo = FALSE}
# Load the data & handy packages
library(tidyverse) # this includes dplyr, ggplot2, & other related packages
library(usdata)
data(county_complete)

# Wrangle the data
county_clean <- county_complete %>% 
  mutate(pci_2019 = per_capita_income_2019 / 1000, 
         pci_2017 = per_capita_income_2017 / 1000) %>% 
  select(state, name, fips, pci_2019, pci_2017)
```



## Exercise 1: 500 samples of size 10

**Reflect**

a. `do()` repeats the code within the parentheses as many times as you tell it. do()` is a shortcut for a for loop.

b. 500 different sample estimates of the model







## Exercise 2: Sampling distribution

The 500 sample slopes are normally distributed around the population slope and range from roughly 0.4 to 1.6.




## Exercise 3: Standard error

For example, for samples of size 10, we expect estimates of the sample slope (the expected change in pci_2019 per $1k increase in pci_2017) to be off by 0.16.
The standard errors decrease as sample size increases.






## Exercise 4: Central Limit Theorem (CLT)

yes






## Exercise 5: Using the CLT

a. 95%
b. 5%
c. 0.15% ((100 - 99.7%)/2) 
    



## Exercise 6: CLT and the 68-95-99.7 Rule

68%, 95%, 99.7%





## Exercise 7: Increasing sample size

intuition. no wrong answer.







## Exercise 8: 500 samples of size n

```{r eval = TRUE}
set.seed(155)
sample_models_50 <- mosaic::do(500)*(
  county_clean %>% 
    sample_n(size = 50, replace = FALSE) %>% 
    with(lm(pci_2019 ~ pci_2017))
)

# Check it out
head(sample_models_50)
```


```{r eval = TRUE}
set.seed(155)
sample_models_200 <- mosaic::do(500)*(
  county_clean %>% 
    sample_n(size = 200, replace = FALSE) %>% 
    with(lm(pci_2019 ~ pci_2017))
)

# Check it out
head(sample_models_200)
```











## Exercise 9: Impact of sample size (part I)

The sample model lines become less and less variable from sample to sample.






## Exercise 10: Impact of sample size (part II)

No matter the sample size, the sample estimates are normally distributed around the population slope. But as sample size increases, the variability of the sample estimates decreases.









## Exercise 11: Properties of sampling distributions


a. For all sample sizes, the shape of the sampling distribution is roughly **normal** and the sampling distribution is roughly centered around **1.027**, the true population slope.  

b. As sample size increases:    
    The average sample slope estimate IS FAIRLY STABLE.    
    The standard error of the sample slopes DECREASES / IS FAIRLY STABLE.
    
c. Thus, as sample size increases, our sample slopes become MORE RELIABLE.
  
  
  
  








