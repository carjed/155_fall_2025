# Simple linear regression: formalizing concepts

```{r include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, 
  warning = FALSE,
  message = FALSE,
  error = TRUE)
```


<!-- create student notes from activity in core-->

{{< include _create_student_notes.qmd >}}

```{r}
#| echo: false
#| eval: true
make_student_notes('Simple linear regression: formalizing concepts', '_L04-slr-formalization.qmd')
```

<!-- pull activity from core -->

```{r knitr-opts}
#| echo: false
#| cache: false
knitr::opts_chunk$set(eval = FALSE, echo = TRUE)
```

{{< include core/_L04-slr-formalization.qmd >}}


\
\
\
\



# Solutions

```{r eval = TRUE, echo = FALSE}
# Load packages and import data
library(readr)
library(ggplot2)
library(dplyr)

bikes <- read_csv("https://mac-stat.github.io/data/bikeshare.csv")
```

## Exercise 1: Get to know the data

```{r eval = TRUE}
dim(bikes)

head(bikes)
```

a. A case represents a day of the year.
b. We have 15 variables broadly concerning weather, day of week information, whether the day is a holiday.
c. Lots of answers are reasonable here! When and where seem to be particularly relevant because this is for a rideshare based in Washington DC with data from 2011-2012. Ridership likely changes a lot from city to city and over time.



## Exercise 2: Get to know the outcome/response variable

The distribution of the `riders_registered` variable looks fairly symmetric. On average there are about 3600 registered riders per day (mean = 3656, median = 3662). On any given day, the number of registered riders is about 1560 from the mean. There seem to be a small number of low outliers (minimum ridership was 20).

```{r eval = TRUE}
ggplot(bikes, aes(x = riders_registered)) +
    geom_histogram()

ggplot(bikes, aes(y = riders_registered)) +
    geom_boxplot()

summary(bikes$riders_registered)

bikes %>% 
    summarize(sd(riders_registered))
```




## Exercise 3: Explore the relationship between ridership and temperature

We'd like to understand how daily ridership among registered users relates with the temperature that it feels like that day (`temp_feel`).

a. Scatterplot (outcome and predictor are both quantitative)
b.

```{r eval = TRUE}
ggplot(bikes, aes(x = temp_feel, y = riders_registered)) +
    geom_point()
```

c. If we only displayed the red line of best fit on the plot, we might miss the slight downward trend at the highest temperatures that we can see more clearly with the blue curve of best fit. A linear model is not appropriate if fit to the whole range of the data, but there does seem to be a linear relationship between ridership and temperature below 80 degrees Fahrenheit.

```{r eval = TRUE}
# Add a red straight line of best fit and a blue curve of best fit
ggplot(bikes, aes(x = temp_feel, y = riders_registered)) +
    geom_point() +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    geom_smooth(color = "blue", se = FALSE)
```



## Exercise 4: Filtering our data

```{r eval = TRUE}
# The %>% is called a "pipe" and feeds what comes before it
# into what comes after (bikes data is "fed into" the filter() function)
bikes_sub <- bikes %>% 
    filter(temp_feel < 80)
```



## Exercise 5: Model fitting and coefficient interpretation

Let's fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.

```{r eval = TRUE}
# Construct and save the model as bike_mod
# What's the purpose of "riders_registered ~ temp_feel"?
# What's the purpose of "data = bikes_sub"?
bike_mod <- lm(riders_registered ~ temp_feel, data = bikes_sub)
```

```{r eval = TRUE}
# A long summary of the model stored in bike_mod
summary(bike_mod)
```

```{r eval = TRUE}
# A simplified model summary
coef(summary(bike_mod))
```

a. E[riders_registered | temp_feel] = -2486.41180 + 86.49251 * temp_feel

b. **Intercept interpretation:** On days that feel like 0 degrees Fahrenheit, we can expect an average of -2486.41180 riders---a negative number of riders doesn't make sense! This results because of **extrapolation**---0 degrees is so far below the minimum temperature in the data. We only have information on the relationship between ridership and temperature in the ~40-100 degree range and have no idea what that relationship looks like outside that range.

c. **Slope interpretation:** Every 1 degree increase in feeling temperature is associated with an average of about 86 more riders.



## Exercise 6: Predictions and residuals

On August 17, 2012, the `temp_feel` was 53.816 degrees and there were 5665 riders. We can get data for this day using the `filter()` and `select()` `dplyr` functions. Note, but don't worry about the syntax -- we haven't learned this yet:
    
```{r eval = TRUE}
bikes_sub %>% 
    filter(date == "2012-08-17") %>% 
    select(riders_registered, temp_feel) 
```

a. *More* riders than expected -- the point is far above the trend line

b. -2486.41180 + 86.49251 * 53.816 = 2168.269

c. We get the same result with `predict()`:

```{r eval = TRUE}
# What is the purpose of newdata = ___???
predict(bike_mod, newdata = data.frame(temp_feel = 53.816))
```

d. residual = 5665 - 2168.269 = 3496.731. On August 17, 2012, there were 3496.731 more riders than would be expected from our model.

e. 
    - Positive residuals are above the trend line---we under-estimate ridership.
    - Negative residuals are below the trend line---we over-estimate ridership.

f. On an 85 degree day, we would predict 4865.452 riders. Even though we can compute this prediction, it's not a good idea because of extrapolation--the data that we used to fit our model was filtered to days less than 80 degrees.

```{r eval = TRUE}
-2486.41180 + 86.49251 * 85
predict(bike_mod, newdata = data.frame(temp_feel = 85))
```




## Exercise 7: Changing temperature units (CHALLENGE)

If we had measured temperature in degrees Celsius rather than degrees Fahrenheit, both the intercept and slope should change. The intercept would now represent 0 degrees Celsius (32 degrees Fahrenheit) and a one unit change in temperature is now 1 degree Celsius (1.8 degrees Fahrenheit).



## Exercise 8: Ridership and windspeed

Let's pull together everything that you've practiced in the preceding exercises to investigate the relationship between `riders_registered` and `windspeed`. Go back to using the `bikes` dataset (instead of `bikes_sub`) because we no longer need to only keep days less than 80 degrees.
    
```{r eval = TRUE}
# Construct and interpret a visualization of this relationship
# Include a representation of the relationship trend
ggplot(bikes, aes(x = windspeed, y = riders_registered)) + 
    geom_point() + 
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    geom_smooth(color = "blue", se = FALSE)

# Use lm to construct a model of riders_registered vs windspeed
# Save this as bike_mod2
bike_mod2 <- lm(riders_registered ~ windspeed, data = bikes)

# Get a short summary of this model
coef(summary(bike_mod2))
```

a. There’s a weak, negative relationship – ridership tends to be smaller on windier days.

b. E[riders_registered | windspeed] = 4490.09761 - 65.34145 windspeed

c.
    - **Intercept:** On days with no wind, we’d expect around 4490 riders. (0 is a little below the minimum of the observed data, but not by much! So extrapolation in interpreting the intercept isn't a huge concern.)
    - **Slope:** Every 1mph increase in windspeed is associated with a ridership decrease of 65 riders on average.

d. See the code below to predict ridership on August 17, 2012 and calculate the corresponding residual. Note that this residual is smaller than the residual from the temperature model (that residual was 3496.731). This indicates that August 17 was more of an outlier in ridership given the temperature than the windspeed.

```{r eval = TRUE}
bikes %>% 
    filter(date == "2012-08-17") %>% 
    select(riders_registered, windspeed)

# prediction
4490.09761 - 65.34145 * 15.50072

# residual 
5665 - 3477.258
```


## Exercise 9: Data drills (`filter`, `select`, `summarize`)

This exercise is designed to help you keep building your `dplyr` skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We'll work with a simpler set of 10 data points:

```{r eval = TRUE}
new_bikes <- bikes %>% 
    select(date, temp_feel, humidity, riders_registered, day_of_week) %>% 
    head(10)
```

### Verb 1: `summarize`

`summarize()` calculates numerical summaries of variables (columns).
    
```{r eval = TRUE}
new_bikes %>% 
    summarize(mean(temp_feel), mean(humidity))
```
    

### Verb 2: `select`

`select()` selects variables (columns).

```{r eval = TRUE}
new_bikes %>%
    select(date, temp_feel)
```

```{r eval = TRUE}
new_bikes %>% 
    select(-date, -temp_feel)
```

### Verb 3: `filter`

`filter()` keeps only days (rows) that meet the given condition(s).

```{r eval = TRUE}
new_bikes %>% 
    filter(riders_registered > 850)
```

```{r eval = TRUE}
new_bikes %>% 
    filter(day_of_week == "Sat")
```

```{r eval = TRUE}
new_bikes %>% 
    filter(riders_registered > 850, day_of_week == "Sat")
```

## Exercise 10: Your turn

Use `dplyr` verbs to complete each task below.
   
```{r eval = TRUE}
# Keep only information about the humidity and day of week
new_bikes %>% 
    select(humidity, day_of_week)

# Keep only information about the humidity and day of week using a different approach
new_bikes %>% 
    select(-date, -temp_feel, -riders_registered)

# Keep only information for Sundays
new_bikes %>% 
    filter(day_of_week == "Sun")

# Keep only information for Sundays with temperatures below 50
new_bikes %>% 
    filter(day_of_week == "Sun", temp_feel < 50)

# Calculate the maximum and minimum temperatures
new_bikes %>% 
    summarize(min(temp_feel), max(temp_feel))
```




