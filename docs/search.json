[
  {
    "objectID": "activities/L01-foundations-welcome.html#step-1",
    "href": "activities/L01-foundations-welcome.html#step-1",
    "title": "Data Collection Activity and Intro to R",
    "section": "Step 1",
    "text": "Step 1\nAt your table, write a one to two word answer to each of the following 7 question(s), each on a separate post-it note (do this individually). If there are two questions: write your answer to the first question on the left-hand side of the post-it note, and your answer to the second question on the bottom of the post-it note.\n\nHow many hours of sleep did you get last night? How many cups of coffee did you drink this morning?\nWhat is your declared or potential major? (If you are a double major, just pick whichever one you think of first.)\nWhat is your class year? (first year, sophomore, junior, senior)\nHow many stats courses have you taken in the past?\nOn a scale of 1 (get me out of here) to 10 (yay!), how excited are you about this course?\nIs it your birthday this semester? (yes/no)\nHow many unread emails do you have in your inbox right now?\nHave you used R/RStudio a lot, a little, or never?",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L01-foundations-welcome.html#step-2",
    "href": "activities/L01-foundations-welcome.html#step-2",
    "title": "Data Collection Activity and Intro to R",
    "section": "Step 2",
    "text": "Step 2\nDesignate one person from your table to distribute your group’s answers to the questions to the corresponding “station” around the classroom. Each table should have a number on it, corresponding to the “station”/question.",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L01-foundations-welcome.html#step-3",
    "href": "activities/L01-foundations-welcome.html#step-3",
    "title": "Data Collection Activity and Intro to R",
    "section": "Step 3",
    "text": "Step 3\nFill out an electronic version of these questions. We’ll come back to this in a future class. Wait until everyone in your group is done with this before moving on to the exercises.",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L01-foundations-welcome.html#exercise-1",
    "href": "activities/L01-foundations-welcome.html#exercise-1",
    "title": "Data Collection Activity and Intro to R",
    "section": "Exercise 1",
    "text": "Exercise 1\nWith your group, in no more than two sentences per question, respond to the questions posed by the 5 W’s + H for the data at your group’s table. If you need a refresher on the 5 W’s + H, check out the related readings posted at the top of this activity!\nWho\n\n  Your answer:\n  \n\nWhat\n\n  Your answer:\n  \n\nWhen\n\n  Your answer:\n  \n\nWhere\n\n  Your answer:\n  \n\nWhy\n\n  Your answer:\n  \n\nHow\n\n  Your answer:",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L01-foundations-welcome.html#exercise-2",
    "href": "activities/L01-foundations-welcome.html#exercise-2",
    "title": "Data Collection Activity and Intro to R",
    "section": "Exercise 2",
    "text": "Exercise 2\nMove the post-it notes around to construct a visualization of the responses at your station.",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L01-foundations-welcome.html#exercise-3",
    "href": "activities/L01-foundations-welcome.html#exercise-3",
    "title": "Data Collection Activity and Intro to R",
    "section": "Exercise 3",
    "text": "Exercise 3\nCalculate at least one numerical summary of the post-it note responses at your station, and record your numerical summary in the response text below. Write a complete sentence, not just the numerical summary alone! This is good practice for summarizing data in more formal writing.\n\n  Your answer:",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L01-foundations-welcome.html#exercise-4",
    "href": "activities/L01-foundations-welcome.html#exercise-4",
    "title": "Data Collection Activity and Intro to R",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn no more than three sentences, describe what you learn about from the visual and numerical summaries. Try to write your description in a way that tells an interesting story about the people in this class.\n\n  Your answer:",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L01-foundations-welcome.html#exercise-5",
    "href": "activities/L01-foundations-welcome.html#exercise-5",
    "title": "Data Collection Activity and Intro to R",
    "section": "Exercise 5",
    "text": "Exercise 5\nImagine that you took all the post-it notes in this room and organized them into a spreadsheet. What would each row in the underlying data set represent? What would each column of the data set represent? Check out the first related reading, linked at the top of this activity, if you need assistance!\n\n  Your answer:",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L01-foundations-welcome.html#reflection",
    "href": "activities/L01-foundations-welcome.html#reflection",
    "title": "Data Collection Activity and Intro to R",
    "section": "Reflection",
    "text": "Reflection\nIn three to four sentences, reflect upon today’s activity. Some reflection prompts are found below:\n\nDo you think the context in which the data was collected influenced the results you found?\nWho would the numerical summaries you calculated potentially be represented of? Could you generalize the information you learned to a broader population (all students at Mac, perhaps), or would you have ethical concerns with generalizing your results?\nWhat (if anything) surprised you about the numerical summaries calculated by your group, or other groups?\nDid your data visualization help you better understand, or discover new things about the data that otherwise would have been difficult to distinguish? Why or why not?\n\n\n  Your answer:\n  \n\n/ /",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L01-foundations-welcome.html#a-brief-introduction-to-r",
    "href": "activities/L01-foundations-welcome.html#a-brief-introduction-to-r",
    "title": "Data Collection Activity and Intro to R",
    "section": "A brief introduction to R",
    "text": "A brief introduction to R\nFor the next section of today’s activity, we’ll get a taste of working with R code. For this activity, you can do everything interactively within this browser window, but going forward, you’ll do all of your coding using either the RStudio desktop app or the Macalester RStudio Server.\n\nExercise 1: R as a calculator\nWe can do simple calculations in R! Place your cursor in the area below, and hit Ctrl+Enter or click the “Run Code” button. It should output [1] 6 underneath. Take some time to play around with some other simple arithmetic operations and see what happens!\n\n\n\n\n\n\n\n\nWhat if we try using 4(2+3) as shorthand for 4*(2+3)?\n\n\n\n\n\n\n\n\n…you should get an error that says Error: attempt to apply non-function. Errors like this are important to learning how R code does and doesn’t work. In this case, we’ve encountered the concept of a function in R.\n\n\nExercise 2: Introduction to Functions\nFunctions are modular units of code designed to perform specific tasks. In R, a function is denoted by a name of the function, followed by parentheses. The name of a function is usually (but not always!) intuitive about what it does.\nInside the parentheses goes some sort of “input”, called arguments, and the function produces some sort of output.\nIn each of the examples below, identify:\n\nthe name of the function\nthe argument(s) given to the function,\nthe output, and\nbased on the name, arguments, and output, describe what the function does\n\n\n\n\n\n\n\n\n\nYou may have noticed (and been confused by) the [1] at the beginning of each output, when we’re expecting just a single number. Think of this like the row numbers in an Excel spreadsheet–while it may seem like a nuisance at first, these indices can be super helpful when we need to visually parse output consisting of longer lists. The print() function below gives us a useful example:\n\n\n\n\n\n\n\n\n…here, the bracketed indices can help us quickly identify the 20th letter of the alphabet, for instance. Now try the print() function with a second argument, quote=FALSE:\n\n\n\n\n\n\n\n\nWhat do you notice is different?\n\n\nExercise 3: Documentation\nWhat else can the print() function do? Are there other arguments we can play with?\nIf you want to know how a function works and what arguments it takes, you can use the ? command followed by the name of a function to pull its built-in documentation! For example, try the following to learn more about the print function:\n\n\n\n\n\n\n\n\nNow try pulling up the documentation for the sqrt function:\n\n\n\n\n\n\n\n\n\n\nExercise 4: Save it for later\nFor reasons that will quickly become clear, we’ll often want to store some R output for later use. In R this is done with the following convention:\nname &lt;- output\nwhere\n\nname is the name under which to store a result.\noutput is the result we wish to store\n&lt;- is the assignment operator. I think of this as an arrow pointing the output into the name.\n\nAnything that we have stored in this way is called an object.\nNOTE: While there are technically other ways to assign results to an object with other assignment operators (e.g., name = output or output -&gt; name), the &lt;- operator is considered the standard convention in R. Many people in computer science despise R for this rather clunky syntax, but it is what it is 🙃.\nTry out each of the code chunks below. One of these will give you an error – why? Another does something, but won’t show any output – why?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s now use what you stored! Here you can see how objects can be incorporated into more complex operations to obtain new objects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunks above, we’ve also introduced the concept of a comment. A comment is any line that starts with the # character, which means that line will not get evaluated, regardless of what comes after the comment. Comments are a great way to briefly document and describe what a particular line of code is doing, which is essential if someone else (or future you!) is trying to understand and run the code.\nThe other main use case for comments is to preserve lines of code that you’ve written, but you don’t want R to try evaluating because they’re buggy or nonessential in the moment. For example:\n\n\n\n\n\n\n\n\nFinally, try to print degrees_f_tomorrow. Take time to read the error message. You will experience this type of error message a lot! It will happen when you either haven’t yet defined the object you’re trying to use, or you’ve misspelled its name (among other reasons we’ll experience later).\n\n\n\n\n\n\n\n\n\n\nExercise 5: Loading Packages\nIn R, collections of related functions are often bundled together in a package. Many packages are loaded by default when you start R/RStudio (such as the base package, which includes many of the most common and basic functions needed to do anything at all in R), but often we need to load certain packages before we can use the functions we want.\nTo load a package, it must first be installed on your computer! You typically only need to install a package once, but you’ll have to load it every time you start a new session in R. We’ll go through how to install packages on your own computer in the next class, but for now we’ll get some exposure to the steps for loading a library. Run the code chunk below to load the tidyverse package, which we will use extensively in this course:\n\n\n\n\n\n\n\n\nOops, we got an error message! Try to figure out what happened and edit the code chunk below to try and fix it.\n\nExerciseHintsSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead closely!\n\n\n\n\nThere was a typo in the library name–using tidyverse instead of tidvyerse fixes it!\nlibrary(tidyverse)\n\n\n\n\nOften you will see some informational output when loading a package. This output varies from package to package and can occasionally look like an error message at first. For example, loading the tidyverse package will give output like so:\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nThis looks like an error message, but it’s not–the package still loaded successfully. Discuss with your group what you think this message means, and when it might cause issues.\nIf you’re not sure if a package was loaded correctly, there are a few ways to confirm. First, you can try pulling up the documentation for that package. Try doing so in the code chunk below, and if you’re able to see the documentation, it worked!\n\nExerciseHintsSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\nLook back at exercise 3\n\n\n\n\n?tidyverse\n\n\n\n\n\n\nExercise 6: Using functions from the package you loaded\nAnother way to confirm if a package is loaded is to simply try using any of the functions that are contained in that package. In general, if the function works, you know the package is loaded, and if not, you need to troubleshoot how you were trying to load the package.\nFor example, the %&gt;% in the code chunk below is a special tidyverse function known as a pipe, that takes the output from the preceding function, and passes it as an argument to the next function. Pipes allow you to string together output from multiple functions into a more complex sequence (a pipeline!), which helps keep your code tidy and avoid creating an object for each intermediate step of that sequence.\n\n\n\n\n\n\n\n\nCompare this to the following:\n\n\n\n\n\n\n\n\nor\n\n\n\n\n\n\n\n\nor\n\n\n\n\n\n\n\n\n…as you can see, there are many ways to do the same thing in R (as in any programming language). There are pros and cons to every approach, but in this class, we’ll prioritize the “if it works, it works!” philosophy. Don’t stress too much about doing something the “right” way, as long as you’re confident that the output is what you actually want and you understand what each function is doing.\nIf you’re feeling overwhelmed by all of these coding concepts on the first day, that’s ok! (my goal is to make you less overwhelmed than my students in previous semesters before I wrote this intro activity). We’ll introduce RStudio next time and gradually build your proficiency with using these tools over the next few weeks.\nIf you want some more introduction/practice with the basics before next class, check out Chapters 1-2 of YaRrr! The Pirate’s Guide to R",
    "crumbs": [
      "Data Collection Activity and Intro to R"
    ]
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#learning-goals",
    "href": "activities/L07-slr-cat-predictor.html#learning-goals",
    "title": "Simple linear regression: categorical predictor",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nWrite a model formula for a simple linear regression model with a categorical predictor using indicator variables\nInterpret the intercept and slope coefficients in a simple linear regression model with a categorical predictor"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#readings-and-videos",
    "href": "activities/L07-slr-cat-predictor.html#readings-and-videos",
    "title": "Simple linear regression: categorical predictor",
    "section": "Readings and videos",
    "text": "Readings and videos\nComplete both the reading and the videos to go through before class.\n\nReading: Section 3.9 in the STAT 155 Notes only up through section 3.9.1 Indicator Variables\nVideos:\n\nSimple linear regression: categorical predictor (slides)\nR Code for Categorical Predictors\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-1-get-to-know-the-data",
    "href": "activities/L07-slr-cat-predictor.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nWrite R code to answer the following:\n\nHow many cases and variables do we have? What does a case represent?\nWhat do the first few rows of the data look like?\nConstruct and interpret two different visualizations of the price variable.\nConstruct and interpret a visualization of the cut variable."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-2-visualizations",
    "href": "activities/L07-slr-cat-predictor.html#exercise-2-visualizations",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 2: Visualizations",
    "text": "Exercise 2: Visualizations\nStart by visualizing this relationship of interest, that between price and cut.\n\nThe appropriate plot depends upon the type of variables we’re plotting. When exploring the relationship between a quantitative response (price) and a quantitative predictor (cut), a scatterplot was an effective choice. After running the code below, explain why a scatterplot is not effective for exploring the relationship between ridership and our categorical cut predictor.\n\n\n# Try a scatterplot\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_point()\n\n\nSeparately run each chunk below, with two plots. Comment (#) on what changes in the code / output.\n\n\n# Univariate boxplot\nggplot(diamonds, aes(y = price)) + \n    geom_boxplot()\n\n\n# ???\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_boxplot()\n\n\n# Univariate density plot\nggplot(diamonds, aes(x = price)) + \n    geom_density()\n\n\n# ???\nggplot(diamonds, aes(x = price, color = cut)) + \n    geom_density()\n\n\n# Univariate histogram\nggplot(diamonds, aes(x = price)) + \n    geom_histogram()\n\n\n# ???\nggplot(diamonds, aes(x = price)) + \n    geom_histogram() + \n    facet_wrap(~ cut)\n\n\nDo you notice anything interesting about the relationship between price and cut? What do you think might be happening here?"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-3-numerical-summaries",
    "href": "activities/L07-slr-cat-predictor.html#exercise-3-numerical-summaries",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 3: Numerical summaries",
    "text": "Exercise 3: Numerical summaries\nLet’s follow up our plots with some numerical summaries.\n\nTo warm up, first calculate the mean price across all diamonds.\n\n\ndiamonds %&gt;% \n    ___(mean(___))\n\n\nTo summarize the trends we observed in the grouped plots above, we can calculate the mean price for each type of cut. This requires the inclusion of the group_by() function:\n\n\n# Calculate mean price by cut\ndiamonds %&gt;% \n    group_by(cut) %&gt;% \n    ___(mean(___))\n\n\nExamine the group mean measurements, and make sure that you can match these numbers up with what you see in the plots.\nBased on the results above, we can see that, on average, diamonds with a “Fair” cut tend to cost more than higher-quality cuts. Let’s construct a new variable named cutFair, using on the following criteria:\n\n\ncutFair = 1 if the diamond is of Fair cut\ncutFair = 0 otherwise (any other value of cut (Good, Very Good, Premium, Ideal))\n\nThe ifelse function allows to create a new variable from an existing one, based on whether or not the values in that variable meet a certain “condition” (remember, you can always look up function documentation in R by typing ?ifelse in the Console, and hitting enter!).\nFill in the following code to create cutFair. The condition was given to you already. Try to use this to complete the code.\n\n# In the first blank, put what value cutFair should have if the condition is \"met\", or TRUE\n# In the second blank, put what value cutFair should have if the condition is \"not met\", or FALSE\ndiamonds &lt;- diamonds %&gt;%\n  mutate(cutFair=ifelse(cut == \"Fair\", ___, ___))\n\nVariables like cutFair that are coded as 0/1 to numerically indicate if a categorical variable is at a particular state are known as an indicator variable. You will sometimes see these referred to as a “binary variable” or “dichotomous variable”; you may also encounter the term “dummy variable” in older statistical literature.\n\nNow, let’s calculate the group means based on the new cutFair indicator variable:\n\n\ndiamonds %&gt;% \n    group_by(cutFair) %&gt;% \n    summarize(mean(price))"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories",
    "href": "activities/L07-slr-cat-predictor.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories",
    "text": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories\nNext, let’s model the trend in the relationship between the cutFair and price variables using a simple linear regression model:\n\n# Construct the model\ndiamond_mod0 &lt;- lm(price ~ cutFair, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod0))\n\nCompare these results to the output of exercise 3e. What do you notice? How do you interpret the intercept and cutFair coefficient terms from this model?\n\nyour answer here"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories",
    "href": "activities/L07-slr-cat-predictor.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 5: Modeling trend using a categorical predictor with >2 categories",
    "text": "Exercise 5: Modeling trend using a categorical predictor with &gt;2 categories\nUsing a single binary predictor like the cutFair indicator variable is useful when there are two clearly delineated categories. However, the cut variable actually contains 5 categories! Because we’ve collapsed all non-Fair classifications into a single category (i.e. cutFair = 0), the model above can’t tell us anything about the difference in expected price between, say, Premium and Ideal cuts. The good news is that it is very straightforward to model categorical predictors with &gt;2 categories. We can do this by using the cut variable as our predictor:\n\n# Construct the model\ndiamond_mod &lt;- lm(price ~ cut, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod))\n\n\nEven though we specified a single predictor variable in the model, we are seeing 4 coefficient estimates–why do you think this is the case?\n\n\nyour answer here\n\n\nNOTE: We see 4 indicator variables (for Good, Very Good, Premium, and Ideal), but we do not see cutFair in the model output. This is because Fair is the reference level of the cut variable (it’s first alphabetically). You’ll see below that it is, indeed, still in the model. You’ll also see why the term “reference level” makes sense!\n\n\nAfter examining the summary table output from the code chunk above, complete the model formula:\n\n\n\nE[price | cut] = ___ +/- ___ cutGood +/- ___ cutVery Good +/- ___ cutPremium +/- ___ cutIdeal"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-6-making-sense-of-the-model",
    "href": "activities/L07-slr-cat-predictor.html#exercise-6-making-sense-of-the-model",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 6: Making sense of the model",
    "text": "Exercise 6: Making sense of the model\nRecall our model: E[price | cut] = 4358.7578 - 429.8933 cutGood - 376.9979 cutVery Good + 225.4999 cutPremium - 901.2158 cutIdeal\n\nUse the model formula to calculate the expected/typical price for diamonds of Good cut.\nSimilarly, calculate the expected/typical price for diamonds of Fair cut.\nRe-examine these 2 calculations. Where have you seen these numbers before?!"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-7-interpreting-coefficients",
    "href": "activities/L07-slr-cat-predictor.html#exercise-7-interpreting-coefficients",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 7: Interpreting coefficients",
    "text": "Exercise 7: Interpreting coefficients\nRecall that our model formula is not a formula for a line. Thus we can’t interpret the coefficients as “slopes” as we have before. Taking this into account and reflecting upon your calculations above…\n\nInterpret the intercept coefficient (4358.7578) in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\nInterpret the cutGood and cutVery Good coefficients (-429.8933 and -376.9979) in terms of the data context. Hint: where did you use these value in the prediction calculations above?"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-8-modeling-choices-challenge",
    "href": "activities/L07-slr-cat-predictor.html#exercise-8-modeling-choices-challenge",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 8: Modeling choices (CHALLENGE)",
    "text": "Exercise 8: Modeling choices (CHALLENGE)\nWhy do we fit this model in this way (using 4 indicator variables cutGood, cutVery Good, cutPremium, cutIdeal)? Instead, suppose that we created a single variable cutCat that gave each category a numerical value: 0 for Fair, 1 for Good, 2 for Very Good, 3 for Premium, and 4 for Ideal.\nHow would this change things? What are the pros and cons of each approach?"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#reflection",
    "href": "activities/L07-slr-cat-predictor.html#reflection",
    "title": "Simple linear regression: categorical predictor",
    "section": "Reflection",
    "text": "Reflection\nThrough the exercises above, you learned how to build and interpret models that incorporate a categorical predictor variable. For the benefit of your future self, summarize how one can interpret the coefficients for a categorical predictor.\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#render-your-work",
    "href": "activities/L07-slr-cat-predictor.html#render-your-work",
    "title": "Simple linear regression: categorical predictor",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-9-diamond-color",
    "href": "activities/L07-slr-cat-predictor.html#exercise-9-diamond-color",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 9: Diamond color",
    "text": "Exercise 9: Diamond color\nConsider modeling price by color.\n\nBefore creating a visualization that shows the relationship between price and color, write down what you expect the plot to look like. Then construct and interpret an apporpriate plot.\nCompute the average price for each color.\nFit an appropriate linear model with lm() and display a short summary of the model.\nWrite out the model formula from the above summary.\nWhich color is the reference level? How can you tell from the model summary?\nInterpret the intercept and two other coefficients from the model in terms of the data context."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-10-diamond-clarity",
    "href": "activities/L07-slr-cat-predictor.html#exercise-10-diamond-clarity",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 10: Diamond clarity",
    "text": "Exercise 10: Diamond clarity\nIf you want more practice, repeat the steps from Exercise 8 for the clarity variable."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-1-get-to-know-the-data-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-1-get-to-know-the-data-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nA case represents a single diamond.\nThe distribution of price is right skewed with considerable high outliers. The right skew is evidenced by the mean price ($3932) being much higher than the median price ($2401).\nMost diamonds in this data are of Good cut or better. Ideal cut diamonds are the most common with each succesive grade being the next most common.\n\n\ndim(diamonds)\n## [1] 53940    10\n\nhead(diamonds)\n## # A tibble: 6 × 10\n##   carat cut       color clarity depth table price     x     y     z\n##   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n## 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n## 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n## 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n## 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n## 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n# Visualize price (outcome variable)\nggplot(diamonds, aes(x = price)) +\n    geom_histogram()\n\n\n\n\n\n\n\nggplot(diamonds, aes(y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\ndiamonds %&gt;%\n    summarize(mean(price), median(price), sd(price))\n## # A tibble: 1 × 3\n##   `mean(price)` `median(price)` `sd(price)`\n##           &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n## 1         3933.            2401       3989.\n\n# Visualize cut (predictor variable)\nggplot(diamonds, aes(x = cut)) +\n    geom_bar()\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    count(cut)\n## # A tibble: 5 × 2\n##   cut           n\n##   &lt;ord&gt;     &lt;int&gt;\n## 1 Fair       1610\n## 2 Good       4906\n## 3 Very Good 12082\n## 4 Premium   13791\n## 5 Ideal     21551"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-2-visualizations-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-2-visualizations-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 2: Visualizations",
    "text": "Exercise 2: Visualizations\nStart by visualizing this relationship of interest, that between price and cut.\n\nWe just don’t see anything clearly on a scatterplot. With the small number of unique values of the predictor variable, all of the points are bunched up on each other.\n\n\n# Try a scatterplot\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_point()\n\n\n\n\n\n\n\n\n\nSeparately run each chunk below, with two plots. Comment (#) on what changes in the code / output.\n\n\n# Univariate boxplot\nggplot(diamonds, aes(y = price)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n# Separate boxes by category\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n# Univariate density plot\nggplot(diamonds, aes(x = price)) + \n    geom_density()\n\n\n\n\n\n\n\n\n\n# Separate density plots by category\nggplot(diamonds, aes(x = price, color = cut)) + \n    geom_density()\n\n\n\n\n\n\n\n\n\n# Univariate histogram\nggplot(diamonds, aes(x = price)) + \n    geom_histogram()\n\n\n\n\n\n\n\n\n\n# Separate histograms by category\nggplot(diamonds, aes(x = price)) + \n    geom_histogram() + \n    facet_wrap(~ cut)\n\n\n\n\n\n\n\n\n\nThe relationship between price and cut seems to be opposite what we would expect. The diamonds with the best cut (Ideal) have the lowest average price, and the ones with the worst cut (Fair) are woth the most. Maybe something else is different between the diamonds with the best and worst cuts…size maybe?"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-3-numerical-summaries-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-3-numerical-summaries-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 3: Numerical summaries",
    "text": "Exercise 3: Numerical summaries\nLet’s follow up our plots with some numerical summaries.\n\nMean price across all diamonds:\n\n\ndiamonds %&gt;% \n    summarize(mean(price))\n## # A tibble: 1 × 1\n##   `mean(price)`\n##           &lt;dbl&gt;\n## 1         3933.\n\n\nMean price for each type of cut:\n\n\ndiamonds %&gt;% \n    group_by(cut) %&gt;% \n    summarize(mean(price))\n## # A tibble: 5 × 2\n##   cut       `mean(price)`\n##   &lt;ord&gt;             &lt;dbl&gt;\n## 1 Fair              4359.\n## 2 Good              3929.\n## 3 Very Good         3982.\n## 4 Premium           4584.\n## 5 Ideal             3458.\n\n\nGroup means should reflect what you see in the plots (easiest to see in the boxplots)\nCreate our new cutFair variable:\n\n\ndiamonds &lt;- diamonds %&gt;%\n  mutate(cutFair=ifelse(cut == \"Fair\", 1, 0))\n\n\nCalculate the group means based on this new variable\n\n\ndiamonds %&gt;% \n    group_by(cutFair) %&gt;% \n    summarize(mean(price))\n## # A tibble: 2 × 2\n##   cutFair `mean(price)`\n##     &lt;dbl&gt;         &lt;dbl&gt;\n## 1       0         3920.\n## 2       1         4359."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories",
    "text": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories\n\n# Construct the model\ndiamond_mod0 &lt;- lm(price ~ cutFair, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod0))\n##              Estimate Std. Error    t value     Pr(&gt;|t|)\n## (Intercept) 3919.6946    17.4367 224.795616 0.000000e+00\n## cutFair      439.0632   100.9269   4.350309 1.361951e-05\n\nThe intercept is the expected value (mean) of the price for all diamonds with a cut quality that isn’t Fair (Good, Very Good, Premium, or Ideal, i.e. when cutFair = 0)–the same as we saw in exercise 3e.\n\nWhen we add the intercept and coefficient for cutFair, we get 3919.69 + 439.06 = 4358.75–this is the mean price for all diamonds with a Fair cut quality that we saw in exercise 3e! Therefore, the coefficient of cutFair (439.06) is interpreted as the difference between the mean value of diamonds with a Fair cut quality and the mean value of diamonds with a higher cut quality."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 5: Modeling trend using a categorical predictor with >2 categories",
    "text": "Exercise 5: Modeling trend using a categorical predictor with &gt;2 categories\n\n# Construct the model\ndiamond_mod &lt;- lm(price ~ cut, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod))\n##              Estimate Std. Error    t value     Pr(&gt;|t|)\n## (Intercept) 4062.2364   25.40119 159.923098 0.000000e+00\n## cut.L       -362.7254   68.04001  -5.331060 9.803272e-08\n## cut.Q       -225.5798   60.64902  -3.719431 1.998742e-04\n## cut.C       -699.4965   52.77862 -13.253406 4.981260e-40\n## cut^4       -280.3564   42.55674  -6.587826 4.504051e-11\n\n\nWe are seeing 4 coefficient estimates because each category is being assigned to a separate indicator variable–cutGood = 1 when cut == \"Good\" and 0 otherwise, cutVery Good = 1 when `cut == “Very Good” and 0 otherwise, and so on.\nE[price | cut] = 4358.7578 - 429.8933 cutGood - 376.9979 cutVery Good + 225.4999 cutPremium - 901.2158 cutIdeal"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-6-making-sense-of-the-model-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-6-making-sense-of-the-model-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 6: Making sense of the model",
    "text": "Exercise 6: Making sense of the model\n\nExpected/typical price for diamonds of Good cut:\n\nE[price | cut] = 4358.7578 - 429.8933 * 1 - 376.9979 * 0 + 225.4999 * 0 - 901.2158 * 0 = 4358.7578 - 429.8933 = $3928.865\n\npredict(diamond_mod, newdata = data.frame(cut = \"Good\"))\n##        1 \n## 3928.864\n\n\nExpected/typical price for diamonds of Fair cut:\n\nE[price | cut] = 4358.7578 - 429.8933 * 0 - 376.9979 * 0 + 225.4999 * 0 - 901.2158 * 0 = $4358.7578\n\npredict(diamond_mod, newdata = data.frame(cut = \"Fair\"))\n##        1 \n## 4358.758\n\n\nThese come from our group mean calculations in Exercise 3b! The predicted value for diamonds of Fair cut is also the same as what we obtained using the SLR model in exercise 4 with only a single cutFair indicator variable."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-7-interpreting-coefficients-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-7-interpreting-coefficients-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 7: Interpreting coefficients",
    "text": "Exercise 7: Interpreting coefficients\nRecall that our model formula is not a formula for a line. Thus we can’t interpret the coefficients as “slopes” as we have before. Taking this into account and reflecting upon your calculations above…\n\nThe average price of a Fair cut diamonds is $4358.7578.\n\nInterpretation of cutGood coefficient: On average, Good cut diamonds are worth $429.89 less than Fair cut diamonds.\nInterpretation of cutVery Good coefficient: On average, Very Good cut diamonds are worth $377.00 less than Fair cut diamonds."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-8-modeling-choices-challenge-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-8-modeling-choices-challenge-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 8: Modeling choices (CHALLENGE)",
    "text": "Exercise 8: Modeling choices (CHALLENGE)\nWhy do we fit this model in this way (using 4 indicator variables cutGood, cutVery Good, cutPremium, cutIdeal)? Instead, suppose that we created a single variable cutCat that gave each category a numerical value: 0 for Fair, 1 for Good, 2 for Very Good, 3 for Premium, and 4 for Ideal.\n\nIf we used 0-4 instead of creating indicator variables, we would be constraining the change from 0 to 1, from 1 to 2, etc. to always be of the same magnitude. That is, a 1 unit change in the cut variable would always have the same change in price in our model.\nUsing separate indicator variables allows the difference between subsequent categories to be different, which allows our model to be a bit more nuanced. It is possible to take nuance too far though. For example, in our previous investigations of bikeshare data, we modeled ridership versus temperature. We treated temperature as a quantitative predictor. Imagine if we had created an indicator variable for each unique temperature in the data—that would be so many variables! Having so many variables creates a very complex model which can be hard to make sense of. (These ideas are addressed further in STAT 253: Statistical Machine Learning!)"
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-9-diamond-color-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-9-diamond-color-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 9: Diamond color",
    "text": "Exercise 9: Diamond color\nConsider modeling price by color.\n\nThe best color diamonds are J, and worst are D. We would expect D diamonds to have the lowest price and increase steadily as we get to J. This is in fact what we see in the boxplots.\n\n\nggplot(diamonds, aes(x = color, y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    group_by(color) %&gt;% \n    summarize(mean(price))\n## # A tibble: 7 × 2\n##   color `mean(price)`\n##   &lt;ord&gt;         &lt;dbl&gt;\n## 1 D             3170.\n## 2 E             3077.\n## 3 F             3725.\n## 4 G             3999.\n## 5 H             4487.\n## 6 I             5092.\n## 7 J             5324.\n\n\nWe fit a linear model and obtain the model formula: E[price | color] = 3169.95 - 93.20 colorE + 554.93 colorF + 829.18 colorG + 1316.72 colorH + 1921.92 colorI + 2153.86 colorJ\n\n\ndiamond_mod2 &lt;- lm(price ~ color, data = diamonds)\n\ncoef(summary(diamond_mod2))\n##               Estimate Std. Error     t value      Pr(&gt;|t|)\n## (Intercept) 4124.72726   18.63913 221.2939947  0.000000e+00\n## color.L     2126.73419   57.02422  37.2952761 1.337640e-300\n## color.Q      200.50417   54.25749   3.6954191  2.197414e-04\n## color.C     -254.35557   51.08475  -4.9790903  6.408052e-07\n## color^4       40.87891   46.91865   0.8712721  3.836095e-01\n## color^5     -228.87914   44.35697  -5.1599368  2.479063e-07\n## color^6       87.92301   40.21604   2.1862672  2.880034e-02\n\n\nColor D is the reference level because we don’t see its indicator variable in the model output.\nInterpretation of the intercept: Diamonds with D color cost $3169.95 on average.\nInterpretation of the colorE coefficient: Diamonds with E color cost $93.20 less than D color diamonds on average.\nInterpretation of the colorF coefficient: Diamonds with F color cost $554.93 more than D color diamonds on average."
  },
  {
    "objectID": "activities/L07-slr-cat-predictor.html#exercise-10-diamond-clarity-1",
    "href": "activities/L07-slr-cat-predictor.html#exercise-10-diamond-clarity-1",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 10: Diamond clarity",
    "text": "Exercise 10: Diamond clarity\nWe see the unexpected result that diamonds of better clarity (VS1 and higher) have lower average prices. In fact the best clarity diamonds (VVS1 and IF) have the lowest average prices. What might be going on? What if the most clear diamonds were also quite small…\n\nggplot(diamonds, aes(x = clarity, y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    group_by(clarity) %&gt;% \n    summarize(mean(price))\n## # A tibble: 8 × 2\n##   clarity `mean(price)`\n##   &lt;ord&gt;           &lt;dbl&gt;\n## 1 I1              3924.\n## 2 SI2             5063.\n## 3 SI1             3996.\n## 4 VS2             3925.\n## 5 VS1             3839.\n## 6 VVS2            3284.\n## 7 VVS1            2523.\n## 8 IF              2865.\n\ndiamond_mod3 &lt;- lm(price ~ clarity, data = diamonds)\n\ncoef(summary(diamond_mod3))\n##                Estimate Std. Error    t value     Pr(&gt;|t|)\n## (Intercept)  3677.41676   25.88161 142.086092 0.000000e+00\n## clarity.L   -1723.35264   98.72036 -17.456913 4.696367e-68\n## clarity.Q    -428.36467   96.70081  -4.429794 9.450847e-06\n## clarity.C     647.87442   83.30820   7.776838 7.567234e-15\n## clarity^4    -123.13052   66.72533  -1.845334 6.499443e-02\n## clarity^5     804.80570   54.62487  14.733320 4.907171e-49\n## clarity^6    -273.65013   47.67881  -5.739449 9.549240e-09\n## clarity^7      81.18721   42.01910   1.932150 5.334619e-02"
  },
  {
    "objectID": "activities/L06-slr-transformations.html#learning-goals",
    "href": "activities/L06-slr-transformations.html#learning-goals",
    "title": "Simple linear regression: Transformations",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nDistinguish between the different motivations for transformations of variables (interpretation, regression assumptions, etc.)\nDetermine when a particular transformation (center, scale, or log) may be appropriate\nInterpret regression coefficients after a transformation has taken place"
  },
  {
    "objectID": "activities/L06-slr-transformations.html#readings-and-videos",
    "href": "activities/L06-slr-transformations.html#readings-and-videos",
    "title": "Simple linear regression: Transformations",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease watch the following video before class.\n\nVideo: Simple Linear Regression: Transformations\n\nThe following reading is optional.\n\nSection 3.8.4 in the STAT 155 Notes covers log transformations, and the “ladder of power,” which we will not cover in class.\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L06-slr-transformations.html#exercise-1-location-transformations",
    "href": "activities/L06-slr-transformations.html#exercise-1-location-transformations",
    "title": "Simple linear regression: Transformations",
    "section": "Exercise 1: Location transformations",
    "text": "Exercise 1: Location transformations\nLocation transformations are ones that shift a predictor variable up or down by a fixed amount. Using a location transformation is sometimes also called centering a predictor.\nWe’ll use the homes data in this exercise.\n\nFit a linear regression model of Price as a function of Living.Area, and call this model home_mod.\n\n\n# Fit the model\n\n\n# Display model summary output\n\n\nInterpret the intercept and the coefficient for Living.Area. Is the interpretation of the intercept meaningful?\nWe can use a location transformation on Living.Area to “start” it at a more reasonable value. We can see from the summarize() code below that the smallest house is 616 quare feet, so let’s center this predictor at 600 square feet. There is no code to fill in here, but make note of the mutate() syntax.\n\n\nhomes %&gt;% \n    summarize(min(Living.Area))\n\n# What is mutate() doing???\nhomes &lt;- homes %&gt;%\n    mutate(Living.Area.Shifted = Living.Area-600)\n\n\nWe can actually determine the coefficients of the Price ~ Living.Area.Shifted model by hand.\n\nFirst, write out in general terms (without specific numbers) how we would interpret the intercept and slope in this model.\nUse these general interpretations as well as the summary output of home_mod to determine what these new coefficients should be.\n\nNow check your answer to part d by fitting the model.\n\n\n# Fit a model of Price vs. Living.Area.Shifted\n\n\n# Display model summary output"
  },
  {
    "objectID": "activities/L06-slr-transformations.html#exercise-2-scale-transformations",
    "href": "activities/L06-slr-transformations.html#exercise-2-scale-transformations",
    "title": "Simple linear regression: Transformations",
    "section": "Exercise 2: Scale transformations",
    "text": "Exercise 2: Scale transformations\nIn this exercise, we’ll explore the relationship between four-year graduation rate and admissions rate of colleges.\nIn the code chunk below, construct a visualization comparing graduation rate (our outcome variable) and admissions rate (our predictor of interest). Remember that your outcome variable should be on the y-axis, in general!\n\n# Scatterplot of graduation rate vs. admissions rate\n\n\nDescribe the relationship you observe between the two quantitative variables, in terms of correlation (weak/strong, positive/negative). Does the relationship appear to be roughly linear?\nWrite a linear regression model formula of the form E[Y | X] = … (filling in Y and X appropriately).\nFit this model in R, and report (don’t interpret yet!) the slope coefficient and intercept coefficient estimates.\n\n\n# Linear regression model with GradRate as the outcome, AdmisRate as predictor of interest\n\n\nIntercept Estimate: Your response here\n\n\nSlope Estimate: Your response here\n\n\nConsidering the units of AdmisRate, what does it mean for AdmisRate to change by one unit? What are the units for AdmisRate (and GradRate, for that matter!)?\nSuppose I want the interpretation of my slope coefficient for AdmisRate in my linear model to be in terms a “1% increase in admissions rate.” To achieve this, we could mutate our AdmisRate variable to range from 0 to 100. Let’s do that for GradRate too (just because!):\n\n\n# Mutate\ncollege &lt;- college %&gt;%\n  mutate(AdmisRate = AdmisRate * ___,\n         GradRate = ___ * ___)\n\n\nFit a new linear regression model with the updated AdmisRate and GradRate variables as your predictor of interest and outcome, respectively. Again, report the intercept and slope estimate from your model.\n\n\n# Linear regression model with updated GradRate as the outcome, updated AdmisRate as predictor of interest\n\n\nIntercept Estimate: Your response here\n\n\nSlope Estimate: Your response here\n\nHow have your intercept and slope estimates changed from the previous model, if at all?\n\nInterpret the regression coefficient that corresponds to the estimated linear relationship between admissions and graduation rates, in the context of the problem. Make sure to use non-causal language, include units, and talk about averages rather than individual cases."
  },
  {
    "objectID": "activities/L06-slr-transformations.html#exercise-3-log-transformations",
    "href": "activities/L06-slr-transformations.html#exercise-3-log-transformations",
    "title": "Simple linear regression: Transformations",
    "section": "Exercise 3: Log transformations",
    "text": "Exercise 3: Log transformations\nThe Big Mac Index has been published by The Economist since 1986 as a metric for comparing purchasing power between countries, giving rise to the phrase Burgernomics. It was developed (sort of jokingly) as a way to explain exchange rates in digestible terms.\nAs an example, suppose a Big Mac in Switzerland costs 6.70 Swiss franc, and in the U.S. a Big Mac costs 5.58 USD. Then the Big Mac Index is 6.70/5.58 = 1.20, and is the implied exchange rate between Swiss franc and USD.\nIf you’d like to read more about the Big Mac index, here’s an article in The Economist (this may be behind a pay-wall for you, you can read up to 5 free articles in the Economist per month).\nFor this exercise, we’ll explore the relationship between average teaching salary in a country and the amount of time someone needs to work to be able to afford a Big Mac. The variables we’ll consider are:\n\nbigmac_mins: average minutes to earn 1 Big Mac\ngross_annual_teacher_income: average gross teacher salary in 1 year (USD)\n\n\nCreate an appropriate visualization that displays the relationship between average minutes to earn a Big Mac and gross annual, average teaching salary, and describe what you observe.\n\n\n# Visualization: Big Mac minutes vs. gross annual teacher income\n\n\nExplain why correlation might not be an appropriate numerical summary for the relationship between the two variables you plotted above.\nFit a linear regression model with bigmac_mins as the outcome and gross_annual_teacher_income as the predictor of interest, and interpret the coefficient for gross_annual_teacher_income, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\n\n\n# Linear regression code\n\n\nPlot residuals vs. fitted values for the model you fit, and describe what you observe. Are there any noticeable patterns in the residuals? Describe them!\n\n\n# Residuals vs. fitted values plot\n\n\nFor which observations do the residuals from the linear regression model appear to be relatively large (i.e. for which observations would predictions fall farthest from observed outcomes)? What possible consequences would this have for people using this model to predict the amount of time it takes for them to earn enough money to afford a Big Mac?\n\nWe’ll now consider a log transformation of teaching salary. In the code chunk below, create a new variable called log_sal that contains the logged values of gross_annual_teacher_income.\n\n# Creating new variable log_sal\nbigmac &lt;- bigmac %&gt;%\n  mutate(log_sal = log(___))\n\n\nCreate an appropriate visualization that displays the relationship between average minutes to earn a Big Mac and logged gross annual, average teaching salary, and describe what you observe. Does correlation seem like it may be an appropriate numerical summary for the relationship between these two variables? Explain why or why not.\nFit a linear regression model with bigmac_mins as the outcome and log_sal as the predictor of interest, and interpret the coefficient for log_sal, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\nPlot residuals vs. fitted values for the model you fit, and describe what you observe. Are there any noticeable patterns in the residuals? Describe them!\n\n\n# Residuals vs. fitted values plot"
  },
  {
    "objectID": "activities/L06-slr-transformations.html#reflection",
    "href": "activities/L06-slr-transformations.html#reflection",
    "title": "Simple linear regression: Transformations",
    "section": "Reflection",
    "text": "Reflection\nTwo of the main motivations for transforming variables in our regression models is to (1) intentionally change the interpretation of regression coefficients, and (2) to better satisfy linear regression assumptions (e.g. remove “patterns” from our residual plots). The first is nearly always justified by the scientific context of the research questions you are trying to answer, while the second is a bit more muddy.\nThink about the pros and cons of transforming your variables to satisfy linear regression assumptions. Is there a limit to how much you would be willing to transform your variables? Would transforming too much leave you with un-interpretable regression coefficients?\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L06-slr-transformations.html#exercise-1-location-transformations-1",
    "href": "activities/L06-slr-transformations.html#exercise-1-location-transformations-1",
    "title": "Simple linear regression: Transformations",
    "section": "Exercise 1: Location transformations",
    "text": "Exercise 1: Location transformations\nLocation transformations are ones that shift a predictor variable up or down by a fixed amount. Using a location transformation is sometimes also called centering a predictor.\nWe’ll use the homes data in this exercise.\n\nFit a linear regression model of Price as a function of Living.Area, and call this model home_mod.\n\n\n# Fit the model\nhome_mod &lt;- lm(Price ~ Living.Area, data = homes)\n\n# Display model summary output\ncoef(summary(home_mod))\n##               Estimate  Std. Error   t value      Pr(&gt;|t|)\n## (Intercept) 13439.3940 4992.352849  2.691996  7.171207e-03\n## Living.Area   113.1225    2.682341 42.173065 9.486240e-268\n\n\n\nInterpretation of slope: Every 1 square foot increase in living area is associated with an expected / average increase in house price of $113.12.\nInterpretation of intercept: The average/expected house price for a house with zero square feet is $13,439.39. Can a house ever be zero square feet??? Nope! The intercept is meaningless in this case.\n\n\n\n\nhomes %&gt;% \n    summarize(min(Living.Area))\n## # A tibble: 1 × 1\n##   `min(Living.Area)`\n##                &lt;dbl&gt;\n## 1                616\n\n# mutate() creates a new variable called Living.Area.Shifted that is equal to Living.Area - 600\nhomes &lt;- homes %&gt;%\n    mutate(Living.Area.Shifted = Living.Area-600)\n\n\n\nIn general terms, the intercept in this model should represent the average house price when Living.Area.Shifted is 0—in other words when Living.Area is 600 square feet. From the coefficient estimates in home_mod, we can calculate the expected / predicted house price for 600 square foot homes: 13439.394 + (113.123*600) = 81312.89. So we’re expecting the new intercept to be $81312.89.\nThe slope in this model represents the average price change for each unit change in Living.Area.Shifted (which is the same as a unit change in Living.Area). Based on this, the slope should be the same as in home_mod ($113.12 per square foot).\n\nLines up with work in part d!\n\n\n# Fit a model of Price vs. Living.Area.Shifted\nhome_mod_centered &lt;- lm(Price ~ Living.Area.Shifted, data = homes)\n\n# Display model summary output\ncoef(summary(home_mod_centered))\n##                       Estimate  Std. Error  t value      Pr(&gt;|t|)\n## (Intercept)         81312.9191 3515.879467 23.12733 2.638371e-103\n## Living.Area.Shifted   113.1225    2.682341 42.17307 9.486240e-268"
  },
  {
    "objectID": "activities/L06-slr-transformations.html#exercise-2-scale-transformations-1",
    "href": "activities/L06-slr-transformations.html#exercise-2-scale-transformations-1",
    "title": "Simple linear regression: Transformations",
    "section": "Exercise 2: Scale transformations",
    "text": "Exercise 2: Scale transformations\nIn the code chunk below, construct a visualization comparing graduation rate (our outcome variable) and admissions rate (our predictor of interest). Remember that your outcome variable should be on the y-axis, in general!\n\n# Scatterplot of graduation rate vs. admissions rate\ncollege %&gt;%\n  ggplot(aes(x = AdmisRate, y = GradRate)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe correlation between admissions and graduation rates appears to be weakly negative. Notably, there are hard boundaries to admissions and graduation rates, since both must fall between 0 and 100%! A few colleges hit up against these boundaries. I would say that, with the exception of the observations that have either 0% graduation rates or 0% admission rates, the relationship does appear to be roughly linear.\nE[GradRate | AdmisRate] = \\(\\beta_0\\) + \\(\\beta_1\\) AdmisRate\n\n\n\n# Linear regression model with GradRate as the outcome, AdmisRate as predictor of interest\nmod &lt;- lm(GradRate ~ AdmisRate, data = college)\nsummary(mod)\n## \n## Call:\n## lm(formula = GradRate ~ AdmisRate, data = college)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.68409 -0.13681  0.01296  0.15550  0.66204 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.68409    0.01759   38.89   &lt;2e-16 ***\n## AdmisRate   -0.34613    0.02330  -14.85   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.2088 on 1649 degrees of freedom\n## Multiple R-squared:  0.118,  Adjusted R-squared:  0.1175 \n## F-statistic: 220.6 on 1 and 1649 DF,  p-value: &lt; 2.2e-16\n\n\nIntercept Estimate: 0.68409\n\n\nSlope Estimate: -0.34613\n\n\nOne unit of AdmisRate corresponds to a 100% change in admissions rates! The same goes for graduation rate. This is a huge change (in fact, the largest change possible).\nSuppose I want the interpretation of my slope coefficient for AdmisRate in my linear model to be in terms a “1% increase in admissions rate.” To achieve this, we could mutate our AdmisRate variable to range from 0 to 100. Let’s do that for GradRate too (just because!):\n\n\n# Mutate\ncollege &lt;- college %&gt;%\n  mutate(AdmisRate = AdmisRate * 100,\n         GradRate = GradRate * 100)\n\n\nFit a new linear regression model with the updated AdmisRate and GradRate variables as your predictor of interest and outcome, respectively. Again, report the intercept and slope estimate from your model.\n\n\n# Linear regression model with updated GradRate as the outcome, updated AdmisRate as predictor of interest\nmod_new &lt;- lm(GradRate ~ AdmisRate, data = college)\nsummary(mod_new)\n## \n## Call:\n## lm(formula = GradRate ~ AdmisRate, data = college)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -68.409 -13.681   1.296  15.550  66.204 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  68.4088     1.7592   38.89   &lt;2e-16 ***\n## AdmisRate    -0.3461     0.0233  -14.85   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 20.88 on 1649 degrees of freedom\n## Multiple R-squared:  0.118,  Adjusted R-squared:  0.1175 \n## F-statistic: 220.6 on 1 and 1649 DF,  p-value: &lt; 2.2e-16\n\n\nIntercept Estimate: 68.4088\n\n\nSlope Estimate: -0.3461\n\nOur intercept estimate is now 100x larger, and our slope estimate has remained the same! The slope remained the same because we multiplied our outcome and our predictor of interest by the same value, and the intercept is 100x larger because we multiplied our outcome by 100 (recall that the intercept is the average expected outcome when “x” is zero).\n\nOn average, we expect colleges that differ in admissions rate by 1% to have 0.35% different graduation rates, with colleges with higher admissions rates having lower graduation rates."
  },
  {
    "objectID": "activities/L06-slr-transformations.html#exercise-3-log-transformations-1",
    "href": "activities/L06-slr-transformations.html#exercise-3-log-transformations-1",
    "title": "Simple linear regression: Transformations",
    "section": "Exercise 3: Log transformations",
    "text": "Exercise 3: Log transformations\n\n\n\n\n# Visualization: Big Mac minutes vs. gross annual teacher income\nbigmac %&gt;%\n  ggplot(aes(x = gross_annual_teacher_income, y = bigmac_mins)) +\n  geom_point() \n\n\n\n\n\n\n\n\nAs annual teacher income gets higher, time it takes in minutes to earn a Big Mac decreases, though the relationship does not appear linear. The amount of time it takes to earn a Big Mac is very high when income is below about 10,000 where it sharply decreases, and then decreases at a much lower rate when income is above around 20,000.\n\nCorrelation is a summary of the linear relationship between two quantitative variables, and this relationship does not appear to be linear!\n\n\n\n# Linear regression code\nmod &lt;- lm(bigmac_mins ~ gross_annual_teacher_income, data = bigmac)\nsummary(mod)\n## \n## Call:\n## lm(formula = bigmac_mins ~ gross_annual_teacher_income, data = bigmac)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -29.649  -9.556  -1.784   4.512  43.715 \n## \n## Coefficients:\n##                               Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)                  5.801e+01  3.104e+00   18.69  &lt; 2e-16 ***\n## gross_annual_teacher_income -9.092e-04  9.591e-05   -9.48 6.16e-14 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 15.4 on 66 degrees of freedom\n##   (2 observations deleted due to missingness)\n## Multiple R-squared:  0.5766, Adjusted R-squared:  0.5701 \n## F-statistic: 89.86 on 1 and 66 DF,  p-value: 6.164e-14\n\nOn average, we expect a one dollar increase in gross annual teacher income to be associated with a decrease in the number of minutes it takes to earn a Big Mac by 9 x 10^(-4) minutes. Stated differently, we expect a ten-thousand dollar increase in gross annual teacher income to be associated with a decrease in the number of minutes it takes to earn a Big Mac by 9 minutes (note that here I did a scale transformation of gross annual teacher income to get this interpretation, which might make more sense when looking at the scale of salary!).\n\n\n\n\n# Residuals vs. fitted values plot\nggplot(mod, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\nThe residuals vs. fitted values plot shows a very clear, nonlinear pattern! As fitted values increase, residuals decrease for a while, and then sharply increase once fitted values are higher than around 40 minutes. The spread of residuals around zero also varies, with greater spread for higher fitted values.\n\nThe residuals appear to be large for people with negative fitted values and those with very high fitted values. Recall that a linear model does not “know” that number of minutes to earn a Big Mac can’t be negative, in context. If we look at the fitted line from our linear model on a scatterplot (see below)…\n\n\nbigmac %&gt;%\n  ggplot(aes(x = gross_annual_teacher_income, y = bigmac_mins)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\nWe observe that negative fitted values and very large fitted values occur when annual teacher income is greater than around 70,000 and less than 10,000, respectively. This implies that the model does a worse job at predicting the number of minutes to earn a Big Mac in countries where annual teacher income is either very high or very low.\nWe’ll now consider a log transformation of teaching salary. In the code chunk below, create a new variable called log_sal that contains the logged values of gross_annual_teacher_income.\n\n# Creating new variable log_sal\nbigmac &lt;- bigmac %&gt;%\n  mutate(log_sal = log(gross_annual_teacher_income))\n\n\n\n\n\nbigmac %&gt;%\n  ggplot(aes(log_sal, bigmac_mins)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThe relationship between logged annual teaching salary and minutes to earn a Big Mac appears roughly linear, with a weakly negative relationship. Correlation is likely an appropriate numerical summary for the relationship between these two quantitative variables, as the relationship is roughly linear!\n\n\n\n\nmod_log &lt;- lm(bigmac_mins ~ log_sal, data = bigmac)\nsummary(mod_log)\n## \n## Call:\n## lm(formula = bigmac_mins ~ log_sal, data = bigmac)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -36.817  -6.951  -1.241   6.032  41.357 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  210.875     14.687   14.36   &lt;2e-16 ***\n## log_sal      -18.142      1.502  -12.08   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 13.21 on 66 degrees of freedom\n##   (2 observations deleted due to missingness)\n## Multiple R-squared:  0.6886, Adjusted R-squared:  0.6838 \n## F-statistic: 145.9 on 1 and 66 DF,  p-value: &lt; 2.2e-16\n\nEach 1 unit increase in logged salary is associated with a 18.14 minute decrease in time to earn a Big Mac on average.\nWe can also use a property of logarithms to interpret the slope of -18.14 in a different way. Suppose we have two salaries: Salary1 and Salary2. If Salary2 is 10% higher than Salary1, then Salary2/Salary1 = 1.1. It is a property of logarithms that log(Salary2/Salary1) = log(Salary2) - log(Salary1). In this case log(Salary2/Salary1) = log(Salary2) - log(Salary1) = log(1.1) = 0.09531018. So a 10% increase in salary is a 0.09 unit increase in the log scale:\n\n# Multiplicative difference of 1.1, or 10% between salaries gives us the \nlog(1.1) * -18.142\n## [1] -1.729117\n\nWhile a 1 unit increase in log salary is associated with an average decrease of 18 Big Mac minutes, a 0.0953 unit increase in log salary (which corresponds to a 10% multiplicative increase), is associated with a 1.7 minute decrease in Big Mac minutes.\nUnderlying math:\nCase 1: Salary = x\n   E[bigmacmin_1] = beta0 + beta1 log(x)\nCase 2: Salary = m*x\n   E[bigmacmin_2] = beta0 + beta1 log(m*x)\n\nE[bigmacmin_2] - E[bigmacmin_1] = beta1 log(m)\n\n\n\n\n# Residuals vs. fitted values plot\nggplot(mod_log, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\nThe residuals seem to lie roughly around zero for all possible fitted values, though the spread is still noticably larger for larger fitted values compared to smaller ones. This implies that the linearity assumption is likely satisfied for this model, but equal variance may be a concern."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#learning-goals",
    "href": "activities/L10-mlr-confounding.html#learning-goals",
    "title": "Confounding variables",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be familiar with:\n\nconfounding variables\nhow to control for confounding variables in our models\nhow to represent the role of confounding variables using causal diagrams"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#readings-and-videos",
    "href": "activities/L10-mlr-confounding.html#readings-and-videos",
    "title": "Confounding variables",
    "section": "Readings and videos",
    "text": "Readings and videos\nBefore class you should have read and watched:\n\nSections 3.9.2 in the STAT 155 Notes\nConfounding (and other causal diagrams)\n\nWatch from 0:00 - 6:54"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-1-review",
    "href": "activities/L10-mlr-confounding.html#exercise-1-review",
    "title": "Confounding variables",
    "section": "Exercise 1: Review",
    "text": "Exercise 1: Review\nThe peaks data includes information on hiking trails in the 46 “high peaks” in the Adirondack mountains of northern New York state:\n\n# Load useful packages and data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\npeaks &lt;- read_csv(\"https://mac-stat.github.io/data/high_peaks.csv\") %&gt;%\n    mutate(ascent = ascent / 1000)\n\n# Check it out \nhead(peaks)\n\nBelow is a model of the time (in hours) that it takes to complete a hike by the hike’s length (in miles), vertical ascent(in 1000s of feet), and rating (easy, moderate, or difficult):\n\npeaks_model &lt;- lm(time ~ length + ascent + rating, data = peaks)\ncoef(summary(peaks_model))\n\nInterpret the length and ratingeasy coefficients in the model formula below by using our strategy:\n\nStrategy: When interpreting a coefficient for a variable x, compare two units whose values of x differ by 1 but who are identical for all other variables.\n\nE[time | length, ascent, rating] = 6.511 + 0.459 length + 0.187 ascent - 3.169 ratingeasy - 2.477 ratingmoderate\n\nSynthesis:\n\nInterpreting the coefficient \\(\\beta_Q\\) for a quantitative variable Q:\n\nHolding all other variables constant, each unit increase in Q is associated with \\(\\beta_Q\\) change (note if it’s an increase or decrease) in Y on average.\n\nInterpreting the coefficient \\(\\beta_C\\) for an indicator variable:\n\nHolding all other variables constant, the average outcome for the group referenced by this indicator (group for whom indicator = 1), is \\(\\beta_C\\) higher/lower than that of the reference group."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-2-confounders",
    "href": "activities/L10-mlr-confounding.html#exercise-2-confounders",
    "title": "Confounding variables",
    "section": "Exercise 2: Confounders",
    "text": "Exercise 2: Confounders\n\nResearch question: Is there a wage gap, hence possibly discrimination, by marital status among 18-34 year olds?\n\nTo explore, we can revisit the cps data with employment information collected by the U.S. Current Population Survey (CPS) in 2018. View the codebook here.\n\n# Import data\ncps &lt;- read_csv(\"https://mac-stat.github.io/data/cps_2018.csv\") %&gt;% \n    filter(age &gt;= 18, age &lt;= 34) %&gt;% \n    filter(wage &lt; 250000)\n\n# Check it out\nhead(cps)\n\nRecall that a simple linear regression model of wage by marital suggests that single workers make $17,052 less than married workers:\n\nwage_model_1 &lt;- lm(wage ~ marital, data = cps)\ncoef(summary(wage_model_1))\n\nThat’s a big gap!!\nBUT this model ignores important confounding variables that might help explain this gap.\nA confounding variable is a cause of both the predictor of interest (marital) and of the response variable (wage).\nWe can represent this idea with a causal diagram:\nAnother definition of a confounding variable is one that\n\nis a cause of the outcome (wage)\nis associated with the main variable of interest (marital status)\nNOT caused by the variable of interest\n\nWe can represent this on the causal diagram with a line from the confounder to the variable of interest (instead of an arrow):\nName at least 2 potential confounders."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-2b-how-why-do-confounders-bias-results",
    "href": "activities/L10-mlr-confounding.html#exercise-2b-how-why-do-confounders-bias-results",
    "title": "Confounding variables",
    "section": "Exercise 2b: How & why do confounders bias results?",
    "text": "Exercise 2b: How & why do confounders bias results?\nUnaccounted-for confounders are often a source of bias in our models, meaning that when we ignore them, we often over- or under-estimate the true underlying relationship between a predictor and response variable. To explore why this is important, let’s first look at how our focal predictor marital is associated with our response variable, wage:\n\ncps %&gt;%\n  ggplot(aes(x=marital, y=wage))+\n  geom_boxplot()+\n  theme_classic()\n\nNow, let’s consider age as a potential confounder. The following plot shows how age is associated with marital status:\n\ncps %&gt;%\n  ggplot(aes(x=age, y=marital))+\n  geom_boxplot()+\n  theme_classic()\n\n…this should make sense, because the older a person is, the more likely they are to be married. Similarly, we can show how age is associated with wage:\n\ncps %&gt;%\n  ggplot(aes(x=age, y=wage))+\n  geom_point()+\n  geom_smooth(method=\"lm\", se=F)+\n  theme_classic()\n\nHere we see that there is a positive correlation between age and wages (which again makes sense, because people who have been in the workforce longer typically earn more).\nLet’s revisit our initial plot showing the relationship between marital status and wages:\n\ncps %&gt;%\n  ggplot(aes(x=marital, y=wage))+\n  geom_boxplot()+\n  theme_classic()\n\nSince we now know that age is associated with both being married and higher wages, this plot doesn’t tell the full story–people who are married could simply be earning higher wages because they tend to be older, not necessarily because they are married! Age is therefore a confounder in the relationship between marital status and wages."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-3-controlling-for-confounders",
    "href": "activities/L10-mlr-confounding.html#exercise-3-controlling-for-confounders",
    "title": "Confounding variables",
    "section": "Exercise 3: Controlling for confounders",
    "text": "Exercise 3: Controlling for confounders\nThe exercise above illustrates that it is important to control or adjust for confounding variables when trying to understand the actual causal relationship between a predictor (e.g. marital) and response (e.g. wage).\n\nSometimes, we can control (adjust) for confounding variables through a carefully designed experiment. For example, in comparing the effectiveness (y) of 2 different cold remedies (x), we might want to control for the age, general health, and severity of symptoms among the participants. How might we do that?\nBUT we’re often working with observational, not experimental, data. Why? Well, explain what an experiment might look like if we wanted to explore the relationship between wage (y) and marital status (x) while controlling for age."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-4-age",
    "href": "activities/L10-mlr-confounding.html#exercise-4-age",
    "title": "Confounding variables",
    "section": "Exercise 4: Age",
    "text": "Exercise 4: Age\nWe’re in luck.\nWe can control (adjust) for confounding variables by including them in our model!\nThat’s one of the superpowers of multiple linear regression.\nLet’s start simple, by controlling for age in our model of wages by marital status:\n\n# Construct the model\nwage_model_2 &lt;- lm(wage ~ marital + age, cps)\ncoef(summary(wage_model_2))\n\n\nVisualize this model by modifying the code below.\n\n(Note: The last line where we add a geom_line layer adds in trendlines similar to what we might obtain using geom_smooth, but it uses the exact fitted values from our model. geom_smooth, on the other hand, adds in trendlines based on fitting two separate models to the married and single subsets of the data. Tray adding geom_smooth(method=\"lm\", se=F, linetype=\"dashed\") to the plot to see how they compare).\n\nggplot(cps, aes(y = ___, x = ___, color = ___)) +\n    geom____(size = 0.1, alpha = 0.5) +\n    geom_line(aes(y = wage_model_2$fitted.values), linewidth = 0.5)\n\n\nSuppose 2 workers are the same age, but one is married and one is single. By how much do we expect the single worker’s wage to differ from the married worker’s wage? (How does this compare to the $17,052 marital gap among all workers?)\nHow can we interpret the maritalsingle coefficient?"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-5-more-confounders",
    "href": "activities/L10-mlr-confounding.html#exercise-5-more-confounders",
    "title": "Confounding variables",
    "section": "Exercise 5: More confounders",
    "text": "Exercise 5: More confounders\nLet’s control for even more potential confounders!\nModel wages by marital status while controlling for age and years of education:\n\nwage_model_3 &lt;- lm(wage ~ marital + age + education, cps)\ncoef(summary(wage_model_3))\n\n\nWith so many variables, this is a tough model to visualize. If you had to draw it, how would the model trend appear: 1 point, 2 points, 2 lines, 1 plane, or 2 planes? Explain your rationale. Hint: pay attention to whether your predictors are quantitative or categorical.\nGiven our research question, which coefficient is of primary interest? Interpret this coefficient.\nInterpret the two other coefficients in this model."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-6-even-more",
    "href": "activities/L10-mlr-confounding.html#exercise-6-even-more",
    "title": "Confounding variables",
    "section": "Exercise 6: Even more",
    "text": "Exercise 6: Even more\nLet’s control for another potential confounder, the job industry in which one works (categorical):\n\nwage_model_4 &lt;- lm(wage ~ marital + age + education + industry, cps)\ncoef(summary(wage_model_4))\n\nIf we had to draw it, this model would appear as 12 planes.\nThe original plane explains the relationship between wage and the 2 quantitative predictors, age and education.\nThen this plane is split into 12 (2*6) individual planes, 1 for each possible combination of marital status (2 possibilities) and industry (6 possibilities).\n\nInterpret the main coefficient of interest for our research question.\nWhen controlling for a worker’s age, marital status, and education level, which industry tends to have the highest wages? The lowest? Note: the following table shows the 6 industries:\n\n\ncps %&gt;% count(industry)"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-7-biggest-model-yet",
    "href": "activities/L10-mlr-confounding.html#exercise-7-biggest-model-yet",
    "title": "Confounding variables",
    "section": "Exercise 7: Biggest model yet",
    "text": "Exercise 7: Biggest model yet\nBuild a model that helps us explore wage by marital status while controlling for: age, education, job industry, typical number of work hours, and health status.\nStore this model as wage_model_5."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-8-reflection",
    "href": "activities/L10-mlr-confounding.html#exercise-8-reflection",
    "title": "Confounding variables",
    "section": "Exercise 8: Reflection",
    "text": "Exercise 8: Reflection\nTake two workers – one is married and the other is single.\nThe models above provided the following insights into the typical difference in wages for these two groups:\n\n\n\nModel\nAssume the two people have the same…\nWage difference\n\n\n\n\nwage_model_1\nNA\n-$17,052\n\n\nwage_model_2\nage\n-$7,500\n\n\nwage_model_3\nage, education\n-$6,478\n\n\nwage_model_4\nage, education, industry\n-$5,893\n\n\nwage_model_5\nage, education, industry, hours, health\n-$4,993\n\n\n\n\nThough not the case in every analysis, the marital coefficient got closer and closer to 0 as we controlled for more confounders. Explain the significance of this phenomenon, in context - what does it mean?\nDo you still find the wage gap for single vs married people to be meaningfully “large”? Can you think of any remaining factors that might explain part of this remaining gap? Or do you think we’ve found evidence of inequitable wage practices for single vs married workers?"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-9-a-new-extreme-example",
    "href": "activities/L10-mlr-confounding.html#exercise-9-a-new-extreme-example",
    "title": "Confounding variables",
    "section": "Exercise 9: A new (extreme) example",
    "text": "Exercise 9: A new (extreme) example\nFor a more extreme example of why it’s important to control for confounding variables, let’s return to the diamonds data:\n\n# Import and wrangle the data\ndata(diamonds)\ndiamonds &lt;- diamonds %&gt;% \n    mutate(\n        cut = factor(cut, ordered = FALSE),\n        color = factor(color, ordered = FALSE),\n        clarity = factor(clarity, ordered = FALSE)\n    ) %&gt;% \n    select(price, clarity, cut, color, carat)\n\nOur goal is to explore how the price of a diamond depends upon its clarity (a measure of quality).\nClarity is classified as follows, in order from best to worst:\n\n\n\nclarity\ndescription\n\n\n\n\nIF\nflawless (no internal imperfections)\n\n\nVVS1\nvery very slightly imperfect\n\n\nVVS2\n” ”\n\n\nVS1\nvery slightly imperfect\n\n\nVS2\n” ”\n\n\nSI1\nslightly imperfect\n\n\nSI2\n” ”\n\n\nI1\nimperfect\n\n\n\n\nCheck out a model of price by clarity. What clarity has the highest average price? The lowest? (This is surprising!)\n\n\ndiamond_model_1 &lt;- lm(price ~ clarity, data = diamonds)\n\n# Get a model summary\ncoef(summary(diamond_model_1))\n\n\nWhat confounding variable might explain these results? What’s your rationale?"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-10-size",
    "href": "activities/L10-mlr-confounding.html#exercise-10-size",
    "title": "Confounding variables",
    "section": "Exercise 10: Size",
    "text": "Exercise 10: Size\nIt turns out that carat, the size of a diamond, is an important confounding variable.\nLet’s explore what happens when we control for this in our model:\n\ndiamond_model_2 &lt;- lm(price ~ clarity + carat, data = diamonds)\n\n# Get a model summary\ncoef(summary(diamond_model_2))\n\n# Plot the model\ndiamonds %&gt;% \n    ggplot(aes(y = price, x = carat, color = clarity)) + \n    geom_line(aes(y = diamond_model_2$fitted.values))\n\nWhat do you think now?\nWhich clarity has the highest expected price?\nThe lowest?\nProvide numerical evidence from the model."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-11-simpsons-paradox",
    "href": "activities/L10-mlr-confounding.html#exercise-11-simpsons-paradox",
    "title": "Confounding variables",
    "section": "Exercise 11: Simpson’s Paradox",
    "text": "Exercise 11: Simpson’s Paradox\nControlling for carat didn’t just change the clarity coefficients, hence our understanding of the relationship between price and clarity… It flipped the signs of many of these coefficients.\nThis extreme scenario has a name: Simpson’s paradox.\nCHALLENGE: Explain why this happened and support your argument with graphical evidence.\nHINTS: Think about the causal diagram below. How do you think carat influences clarity? How do you think carat influences price? Make 2 ggplot() that support your answers."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-12-final-conclusion",
    "href": "activities/L10-mlr-confounding.html#exercise-12-final-conclusion",
    "title": "Confounding variables",
    "section": "Exercise 12: Final conclusion",
    "text": "Exercise 12: Final conclusion\nWhat’s your final conclusion about diamond prices?\nWhich diamonds are more expensive: flawed ones or flawless ones?"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#reflection",
    "href": "activities/L10-mlr-confounding.html#reflection",
    "title": "Confounding variables",
    "section": "Reflection",
    "text": "Reflection\nWrite a one-sentence warning label for what might happen if we do not control for confounding variables in our model.\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-1-review-1",
    "href": "activities/L10-mlr-confounding.html#exercise-1-review-1",
    "title": "Confounding variables",
    "section": "Exercise 1: Review",
    "text": "Exercise 1: Review\n\npeaks_model &lt;- lm(time ~ length + ascent + rating, data = peaks)\ncoef(summary(peaks_model))\n##                  Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept)     6.5106514 1.62983740  3.994663 2.627176e-04\n## length          0.4590819 0.08158314  5.627166 1.465288e-06\n## ascent          0.1874830 0.34215350  0.547950 5.866973e-01\n## ratingeasy     -3.1685224 0.86219113 -3.674965 6.827232e-04\n## ratingmoderate -2.4767827 0.61058560 -4.056405 2.177589e-04\n\n\nlength coefficient:\n\nAmong hikes with the same vertical ascent and challenge rating, each additional mile of the hike is associated with a 0.46 hour increase in completion time on average.\nHolding vertical ascent and challenge rating constant (fixed), each additional mile of the hike is associated with a 0.46 hour increase in completion time on average.\n\nratingeasy coefficient:\n\nAmong hikes with the same length and vertical ascent, the average completion time of easy hikes is 3.2 hours less than that of difficult hikes (reference category).\nHolding constant hike length and vertical ascent, the average completion time of easy hikes is 3.2 hours less than that of difficult hikes."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-2-confounders-1",
    "href": "activities/L10-mlr-confounding.html#exercise-2-confounders-1",
    "title": "Confounding variables",
    "section": "Exercise 2: Confounders",
    "text": "Exercise 2: Confounders\nage, education, job industry, …\nmarital vs wage:\n\ncps %&gt;%\n  ggplot(aes(x=marital, y=wage))+\n  geom_boxplot()+\n  theme_classic()\n\n\n\n\n\n\n\n\nage vs marital:\n\ncps %&gt;%\n  ggplot(aes(x=age, y=marital))+\n  geom_boxplot()+\n  theme_classic()\n\n\n\n\n\n\n\n\nage vs wage:\n\ncps %&gt;%\n  ggplot(aes(x=age, y=wage))+\n  geom_point()+\n  geom_smooth(method=\"lm\", se=F)+\n  theme_classic()"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-3-controlling-for-confounders-1",
    "href": "activities/L10-mlr-confounding.html#exercise-3-controlling-for-confounders-1",
    "title": "Confounding variables",
    "section": "Exercise 3: Controlling for confounders",
    "text": "Exercise 3: Controlling for confounders\n\ncreate 2 separate groups that are as similar as possible with respect to these variables. give the groups different remedies.\nwe’d have to get 2 groups that are similar with respect to age, and assign 1 group to get married and 1 group to be single. that would be weird (and unethical)."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-4-age-1",
    "href": "activities/L10-mlr-confounding.html#exercise-4-age-1",
    "title": "Confounding variables",
    "section": "Exercise 4: Age",
    "text": "Exercise 4: Age\n\n# Construct the model\nwage_model_2 &lt;- lm(wage ~ marital + age, cps)\ncoef(summary(wage_model_2))\n##                 Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept)   -19595.948  3691.6998 -5.308110 1.184066e-07\n## maritalsingle  -7500.146  1191.8526 -6.292847 3.545964e-10\n## age             2213.869   120.7701 18.331265 2.035782e-71\n\n\n.\n\n\ncps %&gt;%\nggplot(aes(y = wage, x = age, color = marital)) +\n    geom_point(size = 0.1, alpha = 0.5) +\n    geom_line(aes(y = wage_model_2$fitted.values), size = 0.5)\n\n\n\n\n\n\n\n\nbonus! adding in the geom_smooth layer:\n\ncps %&gt;%\nggplot(aes(y = wage, x = age, color = marital)) +\n  geom_point(size = 0.1, alpha = 0.5) +\n  geom_line(aes(y = wage_model_2$fitted.values), size = 0.5)+\n  geom_smooth(method=\"lm\", se=F, linetype=\"dashed\")\n\n\n\n\n\n\n\n\n\n-$7500\n\nWhen controlling for (“holding constant”) age, single workers make $7500 less than married workers on average.\nAmong workers of the same age, single workers make $7500 less than married workers on average."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-5-more-confounders-1",
    "href": "activities/L10-mlr-confounding.html#exercise-5-more-confounders-1",
    "title": "Confounding variables",
    "section": "Exercise 5: More confounders",
    "text": "Exercise 5: More confounders\n\nwage_model_3 &lt;- lm(wage ~ marital + age + education, cps)\ncoef(summary(wage_model_3))\n##                 Estimate Std. Error    t value     Pr(&gt;|t|)\n## (Intercept)   -64898.607  4099.8737 -15.829416 2.254709e-54\n## maritalsingle  -6478.094  1119.9345  -5.784351 7.988760e-09\n## age             1676.796   116.3086  14.416777 1.102113e-45\n## education       4285.259   207.2158  20.680173 3.209448e-89\n\n\n2 planes: There are 2 quantitative predictors which form the dimensions of the plane. The marital status categorical predictor creates 2 planes.\nThe maritalsingle coefficient is of main interest:\n\nAmong workers of the same age and years of education, single workers earn $6478 less than married workers.\n\n\nage coefficient: Among workers of the same marital status and years of education, each additional year of age is associated with a $1677 increase in salary on average.\neducation coefficient: Among workers of the same marital status and age, each additional year of education is associated with a $4285 increase in salary on average."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-6-even-more-1",
    "href": "activities/L10-mlr-confounding.html#exercise-6-even-more-1",
    "title": "Confounding variables",
    "section": "Exercise 6: Even more",
    "text": "Exercise 6: Even more\n\nwage_model_4 &lt;- lm(wage ~ marital + age + education + industry, cps)\ncoef(summary(wage_model_4))\n##                                   Estimate Std. Error    t value     Pr(&gt;|t|)\n## (Intercept)                     -52498.857  7143.8481 -7.3488206 2.533275e-13\n## maritalsingle                    -5892.842  1105.6898 -5.3295615 1.053631e-07\n## age                               1493.360   116.1673 12.8552586 6.651441e-37\n## education                         3911.117   243.0192 16.0938565 4.500408e-56\n## industryconstruction              5659.082  6218.5649  0.9100302 3.628760e-01\n## industryinstallation_production   1865.650  6109.2613  0.3053806 7.600964e-01\n## industrymanagement                1476.884  6031.2901  0.2448704 8.065727e-01\n## industryservice                  -7930.403  5945.6509 -1.3338158 1.823603e-01\n## industrytransportation           -1084.176  6197.2462 -0.1749448 8.611342e-01\n\n\nAmong workers of the same job industry, education, and age, single workers make $5893 less than a married worker on average.\nhighest = construction (because it has the highest positive coefficient), lowest = service (because it has the most negative coefficient)"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-7-biggest-model-yet-1",
    "href": "activities/L10-mlr-confounding.html#exercise-7-biggest-model-yet-1",
    "title": "Confounding variables",
    "section": "Exercise 7: Biggest model yet",
    "text": "Exercise 7: Biggest model yet\n\nwage_model_5 &lt;- lm(wage ~ marital + age + education + industry + hours + health, cps)\ncoef(summary(wage_model_5))\n##                                    Estimate Std. Error     t value     Pr(&gt;|t|)\n## (Intercept)                     -64886.5747 6914.18198 -9.38456275 1.171028e-20\n## maritalsingle                    -4992.7685 1061.84882 -4.70195794 2.687274e-06\n## age                               1061.1410  115.83503  9.16079518 9.031462e-20\n## education                         3443.7625  236.12723 14.58435151 1.128646e-46\n## industryconstruction              5381.3857 5959.05620  0.90306007 3.665630e-01\n## industryinstallation_production   2951.0372 5854.23981  0.50408547 6.142365e-01\n## industrymanagement                5107.6364 5782.95334  0.88322283 3.771832e-01\n## industryservice                  -3074.5127 5705.56537 -0.53886207 5.900201e-01\n## industrytransportation            -207.3439 5940.02074 -0.03490626 9.721567e-01\n## hours                              732.1340   43.72488 16.74410733 2.340115e-60\n## healthfair                       -7407.7981 2901.71339 -2.55290483 1.072955e-02\n## healthgood                       -2470.8096 1259.44276 -1.96182766 4.987035e-02\n## healthpoor                       -9086.9110 7657.43781 -1.18667774 2.354441e-01\n## healthvery_good                    292.5278 1020.89213  0.28654136 7.744823e-01"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-8-reflection-1",
    "href": "activities/L10-mlr-confounding.html#exercise-8-reflection-1",
    "title": "Confounding variables",
    "section": "Exercise 8: Reflection",
    "text": "Exercise 8: Reflection\n\nThese confounders explained away more and more of the wage gap between single and married workers.\nAnswers will vary. A potential factor that we haven’t considered is a worker’s role within a given industry."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-9-a-new-extreme-example-1",
    "href": "activities/L10-mlr-confounding.html#exercise-9-a-new-extreme-example-1",
    "title": "Confounding variables",
    "section": "Exercise 9: A new (extreme) example",
    "text": "Exercise 9: A new (extreme) example\n\n\n\nclarity\ndescription\n\n\n\n\nIF\nflawless (no internal imperfections)\n\n\nVVS1\nvery very slightly imperfect\n\n\nVVS2\n” ”\n\n\nVS1\nvery slightly imperfect\n\n\nVS2\n” ”\n\n\nSI1\nslightly imperfect\n\n\nSI2\n” ”\n\n\nI1\nimperfect\n\n\n\n\ndiamond_model_1 &lt;- lm(price ~ clarity, data = diamonds)\n\n# Get a model summary\ncoef(summary(diamond_model_1))\n##                Estimate Std. Error    t value     Pr(&gt;|t|)\n## (Intercept)  3677.41676   25.88161 142.086092 0.000000e+00\n## clarity.L   -1723.35264   98.72036 -17.456913 4.696367e-68\n## clarity.Q    -428.36467   96.70081  -4.429794 9.450847e-06\n## clarity.C     647.87442   83.30820   7.776838 7.567234e-15\n## clarity^4    -123.13052   66.72533  -1.845334 6.499443e-02\n## clarity^5     804.80570   54.62487  14.733320 4.907171e-49\n## clarity^6    -273.65013   47.67881  -5.739449 9.549240e-09\n## clarity^7      81.18721   42.01910   1.932150 5.334619e-02\n\n\nhighest = SI2, lowest = VVS1\nwill vary."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-10-size-1",
    "href": "activities/L10-mlr-confounding.html#exercise-10-size-1",
    "title": "Confounding variables",
    "section": "Exercise 10: Size",
    "text": "Exercise 10: Size\n\ndiamond_model_2 &lt;- lm(price ~ clarity + carat, data = diamonds)\n\n# Get a model summary\ncoef(summary(diamond_model_2))\n##                Estimate Std. Error      t value      Pr(&gt;|t|)\n## (Intercept) -2977.26896   13.11110 -227.0799509  0.000000e+00\n## clarity.L    4216.77507   33.65424  125.2969766  0.000000e+00\n## clarity.Q   -1931.40632   31.87080  -60.6011296  0.000000e+00\n## clarity.C    1005.84704   27.39341   36.7185805 1.486332e-291\n## clarity^4    -480.17830   21.94294  -21.8830399 1.089041e-105\n## clarity^5     283.94435   17.97527   15.7963882  4.403172e-56\n## clarity^6      12.66308   15.68062    0.8075624  4.193461e-01\n## clarity^7     198.04828   13.81518   14.3355543  1.597902e-46\n## carat        8440.05729   12.65126  667.1315412  0.000000e+00\n\n# Plot the model\ndiamonds %&gt;% \n    ggplot(aes(y = price, x = carat, color = clarity)) + \n    geom_line(aes(y = diamond_model_2$fitted.values))\n\n\n\n\n\n\n\n\nhighest = IF, lowest = I1 (reference category)\nThis is what we would have expected!"
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-11-simpsons-paradox-1",
    "href": "activities/L10-mlr-confounding.html#exercise-11-simpsons-paradox-1",
    "title": "Confounding variables",
    "section": "Exercise 11: Simpson’s Paradox",
    "text": "Exercise 11: Simpson’s Paradox\nThe bigger the diamond the bigger the price:\n\ndiamonds %&gt;% \n    ggplot(aes(y = price, x = carat)) + \n    geom_point()\n\n\n\n\n\n\n\n\nBUT the bigger the diamond, the more flawed it tends to be:\n\ndiamonds %&gt;% \n    ggplot(aes(y = carat, x = clarity)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\nThus flawed diamonds looked more expensive, but only because they also tend to be bigger (and size is a bigger driver of price)."
  },
  {
    "objectID": "activities/L10-mlr-confounding.html#exercise-12-final-conclusion-1",
    "href": "activities/L10-mlr-confounding.html#exercise-12-final-conclusion-1",
    "title": "Confounding variables",
    "section": "Exercise 12: Final conclusion",
    "text": "Exercise 12: Final conclusion\nFlawless diamonds are more expensive."
  },
  {
    "objectID": "activities/L23-hypothesis-testing-details.html#learning-goals",
    "href": "activities/L23-hypothesis-testing-details.html#learning-goals",
    "title": "23. Hypothesis testing details and practice",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nApply the procedure for a formal hypothesis test\nArticulate how we can formalize a research question as a testable, statistical hypothesis"
  },
  {
    "objectID": "activities/L23-hypothesis-testing-details.html#readings-and-videos",
    "href": "activities/L23-hypothesis-testing-details.html#readings-and-videos",
    "title": "23. Hypothesis testing details and practice",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease complete the following reading or videos before class:\n\nReading: Section 7.3 (stop when you get to Section 7.3.4) in the STAT 155 Notes\nVideo 1: Introduction to Statistical Inference\nVideo 2: Hypothesis Testing Framework\nVideo 3: Hypothesis Testing Procedure"
  },
  {
    "objectID": "activities/L23-hypothesis-testing-details.html#exercise-1",
    "href": "activities/L23-hypothesis-testing-details.html#exercise-1",
    "title": "23. Hypothesis testing details and practice",
    "section": "Exercise 1",
    "text": "Exercise 1\nResearch Question: Can we predict whether or not a mushroom is poisonous based on the shape of its cap?\nFor this exercise, we will look at data from various species of gilled mushrooms in the Agaricus and Lepiota Family. We have information on whether a mushroom is poisonous (TRUE if it is, FALSE if it’s edible), the shape of its cap (cap_shape, a categorical variable with 6 categories), the texture of its cap surface (cap_surface, a categorical variable with 4 categories), and the size of its gills (gill_size, a categorical variable with two categories)\n\n# Load the data & packages\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(broom)\n\nmushrooms &lt;- read_csv(\"https://Mac-STAT.github.io/data/mushrooms.csv\")\n\nmushrooms &lt;- mushrooms %&gt;%\n  mutate(cap_shape = relevel(as.factor(cap_shape), ref=\"flat\")) %&gt;%\n  dplyr::select(poisonous, cap_shape)\n\nhead(mushrooms)\n\n\nPart a\nOne of the most poisonous species of mushrooms is the Amanita phalloides or “Death Cap” mushroom, which typically has a flat cap shape when mature. Based on this anecdote, we hypothesize that species of mushrooms with flat caps in general may be more likely to be poisonous than edible.\nFirst, let’s translate this question to an appropriate null and alternative hypothesis that we can compare with a formal hypothesis test. Remember that poisonous is a binary outcome, so we need to frame our null and alternative hypotheses in terms of odds (i.e., Odds(poisionous | flat cap) = P(poisonous|flat cap)/P(edible | flat cap)).\n\nYour answer\n\n\n\nPart b\n\nFit a logistic regression model to investigate whether cap_shape is associated with a mushroom being poisonous. (Note that in the setup code above, we have forced the reference category for the cap_shape predictor to be flat; without this, the reference category by default would be set as bell, which is the first category when sorted alphabetically).\n\n\nmushroom_mod1 &lt;- ()\n\ncoef(mushroom_mod1)\n\n\n\nPart c\nProvide an appropriate interpretation of the intercept coefficient on the odds scale. Based on this interpretation, do you believe mushrooms with flat caps are more likely to be poisonous, or more likely to be edible?\n\nYour answer here\n\n\n\nPart d\nLet’s look at the full model summary:\n\nsummary(mushroom_mod1)\n\nReport and interpret the test statistic for the intercept term (our coefficient of interest):\n\nYour answer\n\n\n\nPart e\n\nReport and interpret the p-value for the intercept term.\nBased on this p-value and a significance level of 0.05, do we have evidence that mushrooms with flat caps are more likely to be poisonous than edible?\n\n\nYour answer\n\n\n\nPart f\nNow suppose we are interested in whether the odds of being poisonous are different for mushrooms with other cap shapes.\nBy hand, calculate the odds of being poisonous for mushrooms with knobbed caps, conical caps, and sunken caps (remember that the non-exponentiated coefficients represent a difference in log-odds compared to the reference category):\n\nodds(poisonous | knobbed cap) =\n\n\nodds(poisonous | conical cap) =\n\n\nodds(poisonous | sunken cap) =\n\n\n\nPart g\nBased on these odds, which of the 4 mushroom cap shapes we’ve investigated (flat, knobbed, conical, and sunken) do you believe is the best indicator that it’s edible? Which cap shape do you expect is most likely to be poisonous?\n\nYour answer\n\n\n\nPart h\nLet’s get the full model summary again:\n\ntidy(mushroom_mod1) %&gt;% \n    mutate(exp_estimate = exp(estimate)) %&gt;% \n    select(term, estimate, exp_estimate, everything())\n\nNow report and interpret the p-values for the coefficients corresponding to cap_shapeknobbed, cap_shapeconical, and cap_shapesunken:\n\nYour answer\n\n\n\nPart i\nBased on the model summary output in part h above, if you were given a plate of mushrooms with different cap shapes and had to pick one to eat, which one would you choose? Which cap shape would you absolutely avoid at all costs? Are your decisions guided by the coefficient estimates, the p-values, or both?\n\nYour answer\n\n\n\nPart j\nLet’s look at the data a slightly different way, using a 6x2 table of counts:\n\nmushrooms %&gt;% \n  mutate(cap_shape=as.factor(cap_shape),\n         poisonous=as.factor(poisonous)) %&gt;%\n  dplyr::count(cap_shape, poisonous, .drop=FALSE) %&gt;% \n  pivot_wider(names_from=poisonous, values_from=n, names_prefix=\"Poisonous = \")\n\nNow, if you were given a plate of mushrooms with different cap shapes and had to pick one shape to eat and one to absolutely avoid, would you choose the same shapes? Why or why not?\n\nYour answer"
  },
  {
    "objectID": "activities/L23-hypothesis-testing-details.html#exercise-2",
    "href": "activities/L23-hypothesis-testing-details.html#exercise-2",
    "title": "23. Hypothesis testing details and practice",
    "section": "Exercise 2",
    "text": "Exercise 2\nFor this exercise, let’s return to the fish dataset from a previous activity.\n\nfish &lt;- read_csv(\"https://Mac-STAT.github.io/data/Mercury.csv\")\n\nhead(fish)\n\nResearch question: We believe the length of a fish (measured in centimeters) is causally associated with its mercury concentration (measured in parts per million [ppm]). We suspect that the river a fish is sampled from may be a confounder, since differences in the river environment may causally influence both the average length of fish (e.g. due to differences in water temperature or food availability) as well as mercury concentration (e.g. due to differences between the two rivers in mercury pollution levels).\n\nPart a\nFit a linear regression model that can be used to answer our research question.\n\nmod_fish1 &lt;- ___\nsummary(mod_fish1)\n\n\n\nPart b\nInterpret the coefficient estimate, test statistic, and p-value for the RiverWacamaw coefficient. Assume we have specified a significance level of 0.05.\n\nResponse\n\n\n\nPart c\nSuppose we now want to determine if the causal effect of fish length on mercury concentration differs according to the river a fish was sampled from.\nFirst, modify the code chunk below to visualize the 3-way relationship between the Concen, Length, and River variables.\n\nfish %&gt;% \n  ggplot(aes(x = ___, y = ___, colour = ___)) + \n  # [ADDITIONAL GGPLOT LAYER(S)]\n\nNext, fit an appropriate linear regression model with an interaction term to investigate this question.\n\nmod_fish2 &lt;- ___\nsummary(mod_fish2)\n\n\n\nPart d\nInterpret the coefficient estimate, test statistic, and p-value for the RiverWacamaw:Length interaction term in this revised model (mod_fish2). Assume we’ve set a significance level of 0.05.\n\nResponse\n\n\n\nPart e\nInterpret the coefficient estimate, test statistic, and p-value for the RiverWacamaw coefficient in this revised model (mod_fish2). (again, you can assume we’ve set a significance level of 0.05).\n\n\nPart f (CHALLENGE)\nSuppose another researcher runs the same model we fit in part c above (mod_fish2), but they claim that a more appropriate alternative hypothesis should be Beta_1 &lt; 0, (and not Beta_1 ≠ 0, as is assumed by default when running a regression model). Because of this, they reported a smaller p-value for the coefficient, and claim that the Wacamaw River has a lower baseline mercury concentration (i.e., when Length = 0cm).\nWhat is the p-value they would have reported for the RiverWacamaw coefficient in mod_fish2?\n\nResponse\n\nWhat is a potential ethical problem with the other researcher’s claim that the alternative hypothesis should be Beta_1 &lt; 0?\n\nResponse\n\n\n\nPart g (CHALLENGE)\nYou point out to the other researcher that the intercept and RiverWacamaw coefficients are both negative, so whatever difference in mercury concentration between the two rivers your model predicts “at baseline” is not useful or meaningful–you cannot have a fish that is 0cm long, nor a mercury concentration &lt;0ppm.\nYou propose that a more appropriate model should transform the Length variable in some way to make the intercept more interpretable. Create a new variable named Length_adj with this transformation and use it to re-fit the model:\n\nmod_fish3 &lt;- lm(Concen ~ Length_adj*River, data=fish)\nsummary(mod_fish3)\n\nCompare the output of this model to that of mod_fish2. What happened to the estimate, test statistic, and p-value for the RiverWacamaw coefficient? How does this affect your conclusion? How about the other researcher’s conclusion?\n\nResponse"
  },
  {
    "objectID": "activities/L23-hypothesis-testing-details.html#exercise-1-1",
    "href": "activities/L23-hypothesis-testing-details.html#exercise-1-1",
    "title": "23. Hypothesis testing details and practice",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nPart a\nOne of the most poisonous species of mushrooms is the Amanita phalloides or “Death Cap” mushroom, which typically has a flat cap shape when mature. Based on this anecdote, we hypothesize that species of mushrooms with flat caps in general may be more likely to be poisonous than edible.\nFirst, let’s translate this question to an appropriate null and alternative hypothesis that we can compare with a formal hypothesis test. Remember that poisonous is a binary outcome, so we need to frame our null and alternative hypotheses in terms of odds (i.e., Odds(poisonous | flat cap) = P(poisonous|flat cap)/P(edible | flat cap)).\n\n\\(H_0\\): Odds(poisonous | flat cap) = 1\n\\(H_a\\): Odds(poisonous | flat cap) ≠ 1\n\n\n\nPart b\n\nFit a logistic regression model to investigate whether cap_shape is associated with a mushroom being poisonous. (Note that in the setup code chunk above, we have forced the reference category for the cap_shape predictor to be flat; otherwise, the reference category by default would be set as bell, which is the first category when sorted alphabetically).\n\n\nmushroom_mod1 &lt;- glm(poisonous ~ cap_shape, data=mushrooms, family=\"binomial\")\n\ncoef(mushroom_mod1)\n##      (Intercept)    cap_shapebell cap_shapeconical  cap_shapeconvex \n##      -0.02538207      -2.10483179      14.59144985      -0.10609804 \n## cap_shapeknobbed  cap_shapesunken \n##       0.99296610     -14.54068570\n\n\n\nPart c\nProvide an appropriate interpretation of the intercept coefficient on the odds scale. Based on this interpretation, do you believe mushrooms with flat caps are more likely to be poisonous, or more likely to be edible?\n\nexp(coef(mushroom_mod1))\n##      (Intercept)    cap_shapebell cap_shapeconical  cap_shapeconvex \n##     9.749373e-01     1.218662e-01     2.172632e+06     8.993365e-01 \n## cap_shapeknobbed  cap_shapesunken \n##     2.699229e+00     4.842397e-07\n\n\nThe odds of a flat-capped mushroom being poisonous are 0.975:1–that is, mushrooms with flat caps are very slightly less likely to be poisonous than they are edible.\n\n\n\nPart d\nLet’s look at the full model summary:\n\nsummary(mushroom_mod1)\n## \n## Call:\n## glm(formula = poisonous ~ cap_shape, family = \"binomial\", data = mushrooms)\n## \n## Coefficients:\n##                   Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept)       -0.02538    0.03563  -0.712   0.4762    \n## cap_shapebell     -2.10483    0.15677 -13.426   &lt;2e-16 ***\n## cap_shapeconical  14.59145  441.37169   0.033   0.9736    \n## cap_shapeconvex   -0.10610    0.04866  -2.180   0.0292 *  \n## cap_shapeknobbed   0.99297    0.08557  11.604   &lt;2e-16 ***\n## cap_shapesunken  -14.54069  156.04846  -0.093   0.9258    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 11252  on 8123  degrees of freedom\n## Residual deviance: 10702  on 8118  degrees of freedom\n## AIC: 10714\n## \n## Number of Fisher Scoring iterations: 13\n\nReport and interpret the test statistic for the intercept term (our coefficient of interest):\n\nThe test statistic is -0.712—this means that the coefficient estimate of interest is 0.712 standard errors away from (specifically, below) the null value of 0 (note that this is on the log-odds scale).\n\n\n\nPart e\n\nReport and interpret the p-value for the intercept term.\nBased on this p-value and a significance level of 0.05, do we have evidence that mushrooms with flat caps are more likely to be poisonous than edible?\n\n\nThe p-value for the intercept term is 0.4762.\n\n\nInterpretation: If the null hypothesis were true (i.e., the odds of being poisonous were 1), the probability of seeing a test statistic as or more extreme than |-0.712| is 0.4762. Because the p-value is greater than our significance level of 0.05, we have no evidence to suggest that a flat-capped mushroom is more or less likely to be poisonous.\n\n\n\nPart f\nNow suppose we are interested in whether the odds of being poisonous are different for mushrooms with other cap shapes.\nCalculate the odds of being poisonous for mushrooms with knobbed caps, conical caps, and sunken caps (remember that the non-exponentiated coefficients represent a difference in log-odds compared to the reference category):\n\n# knobbed\nexp(-0.025+0.992)\n## [1] 2.630042\n\n#conical\nexp(-0.025+14.59)\n## [1] 2115919\n\n#sunken\nexp(-0.025-14.54)\n## [1] 4.726078e-07\n\n\n\nPart g\nBased on these odds, which of the 4 mushroom cap shapes we’ve investigated (flat, knobbed, conical, and sunken) do you believe is the best indicator that it’s edible? Which cap shape do you expect is most likely to be poisonous?\n\nUsing only the coefficient estimates, it appears that mushrooms with a sunken cap shape appear to be most likely to be edible, as the odds they are poisonous are approximately \\(4.7 \\times 10^{-7}\\) to 1. Mushrooms with conical caps appear to be most likely to be poisonous (odds of being poisonous are &gt;2 million to 1).\n\n\n\nPart h\nLet’s get the full model summary again:\n\ntidy(mushroom_mod1) %&gt;% \n    mutate(exp_estimate = exp(estimate)) %&gt;% \n    select(term, estimate, exp_estimate, everything())\n## # A tibble: 6 × 6\n##   term             estimate exp_estimate std.error statistic  p.value\n##   &lt;chr&gt;               &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)       -0.0254      9.75e-1    0.0356   -0.712  4.76e- 1\n## 2 cap_shapebell     -2.10        1.22e-1    0.157   -13.4    4.26e-41\n## 3 cap_shapeconical  14.6         2.17e+6  441.        0.0331 9.74e- 1\n## 4 cap_shapeconvex   -0.106       8.99e-1    0.0487   -2.18   2.92e- 2\n## 5 cap_shapeknobbed   0.993       2.70e+0    0.0856   11.6    3.91e-31\n## 6 cap_shapesunken  -14.5         4.84e-7  156.       -0.0932 9.26e- 1\n\nNow report and interpret the p-values for the coefficients corresponding to cap_shapeknobbed, cap_shapeconical, and cap_shapesunken:\n\ncap_shapeknobbed: Our null hypothesis is that the odds ratio between flat-capped and knob-capped mushrooms is 1 (i.e., the odds of a knob-capped mushroom being poisonous are equal to the odds of a flat-capped mushroom being poisonous). If we assume the null hypothesis is true, then the probability of seeing a test statistic as or more extreme than |11.60| is 3.91e-31. Because the p-value is far below our significance level of 0.05, we take this as strong evidence that knob-capped mushrooms are much more likely to be poisonous than flat-capped mushrooms.\n\n\ncap_shapeconical: Our null hypothesis is that the odds ratio between flat-capped and cone-capped mushrooms is 1 (i.e., the odds of a cone-capped mushroom being poisonous are equal to the odds of a flat-capped mushroom being poisonous). If we assume the null hypothesis is true, then the probability of seeing a test statistic as or more extreme than |0.03| is 0.974 (i.e., we are very likely to see a test statistic more extreme than |-0.03| if in fact there were no difference between flat-capped and cone-cap mushrooms in odds of being poisonous). Because the p-value is far above our significance level of 0.05, we do not have evidence that the odds of a cone-capped mushroom being poisonous differ from the odds of a flat-capped mushroom being poisonous.\n\n\ncap_shapesunken: Our null hypothesis is that the odds ratio between flat-capped and sunken-cap mushrooms is 1 (i.e., the odds of a sunken-cap mushroom being poisonous are equal to the odds of a flat-capped mushroom being poisonous). If we assume the null hypothesis is true, then the probability of seeing a test statistic as or more extreme than |-0.09| is 0.926 (i.e., we are very likely to see a test statistic more extreme than |-0.09| if in fact there were no difference between flat-capped and sunken-cap mushrooms in odds of being poisonous). Because the p-value is far above our significance level of 0.05, we do not have evidence that the odds of a sunken-capped mushroom being poisonous differ from the odds of a flat-capped mushroom being poisonous.\n\n\n\nPart i\nBased on the model summary output in part h above, if you were given a plate of mushrooms with different cap shapes and had to pick one to eat, which one would you choose? Which cap shape would you absolutely avoid at all costs? Are your decisions guided by the coefficient estimates, the p-values, or both?\n\nAnswers may vary–if only considering coefficient estimates, then cone-shaped caps are most likely to be poisonous and sunken-shaped caps are most likely to be edible. But if we only look at p-values, then knob-shaped caps have the strongest evidence that they are more likely to be poisonous, and bell-shaped caps have the strongest evidence that they are more likely to be edible.\n\n\n\nPart j\nLet’s look at the data a slightly different way, using a 6x2 table of counts:\n\nmushrooms %&gt;% \n  mutate(cap_shape=as.factor(cap_shape),\n         poisonous=as.factor(poisonous)) %&gt;%\n  dplyr::count(cap_shape, poisonous, .drop=FALSE) %&gt;% \n  pivot_wider(names_from=poisonous, values_from=n, names_prefix=\"Poisonous = \")\n## # A tibble: 6 × 3\n##   cap_shape `Poisonous = FALSE` `Poisonous = TRUE`\n##   &lt;fct&gt;                   &lt;int&gt;              &lt;int&gt;\n## 1 flat                     1596               1556\n## 2 bell                      404                 48\n## 3 conical                     0                  4\n## 4 convex                   1948               1708\n## 5 knobbed                   228                600\n## 6 sunken                     32                  0\n\nNow, if you were given a plate of mushrooms with different cap shapes and had to pick one shape to eat and one to absolutely avoid, would you choose the same shapes? Why or why not?\n\nPersonally, I’d stick with the sunken-shaped caps for eating. Even though our model suggests there’s no evidence to believe they are less likely to be poisonous, 0 out of 32 in the sample are poisonous, which seems like the least risky choice. However, I’d tend to avoid the knob-capped mushrooms more than the cone-capped mushrooms—even though the latter are all poisonous in the sample, there were only 4 observations, so it’s possible that due to sampling variation, the odds of being poisonous for cone-capped mushrooms is lower than that of knob-capped mushrooms (where we have many more observations)."
  },
  {
    "objectID": "activities/L23-hypothesis-testing-details.html#exercise-2-1",
    "href": "activities/L23-hypothesis-testing-details.html#exercise-2-1",
    "title": "23. Hypothesis testing details and practice",
    "section": "Exercise 2",
    "text": "Exercise 2\nFor this exercise, let’s return to the fish dataset from the previous activity (Activity 22).\n\nfish &lt;- read_csv(\"https://Mac-STAT.github.io/data/Mercury.csv\")\n\nhead(fish)\n## # A tibble: 6 × 5\n##   River  Station Length Weight Concen\n##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1 Lumber       0   47     1616   1.6 \n## 2 Lumber       0   48.7   1862   1.5 \n## 3 Lumber       0   55.7   2855   1.7 \n## 4 Lumber       0   45.2   1199   0.73\n## 5 Lumber       0   44.7   1320   0.56\n## 6 Lumber       0   43.8   1225   0.51\n\nResearch question: We believe the length of a fish (measured in centimeters) is causally associated with its mercury concentration (measured in parts per million [ppm]). We suspect that the river a fish is sampled from may be a confounder, since differences in the river environment may causally influence both the average length of fish (e.g. due to differences in water temperature or food availability) as well as mercury concentration (e.g. due to differences between the two rivers in mercury pollution levels).\n\nPart a\nFit a linear regression model that can be used to answer our research question.\n\nmod_fish1 &lt;- lm(Concen ~ Length + River, data=fish)\nsummary(mod_fish1)\n## \n## Call:\n## lm(formula = Concen ~ Length + River, data = fish)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.19298 -0.36849 -0.07677  0.30905  1.84773 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  -1.194229   0.216287  -5.521 1.26e-07 ***\n## Length        0.057657   0.005213  11.061  &lt; 2e-16 ***\n## RiverWacamaw  0.142027   0.089496   1.587    0.114    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.5779 on 168 degrees of freedom\n## Multiple R-squared:  0.431,  Adjusted R-squared:  0.4243 \n## F-statistic: 63.63 on 2 and 168 DF,  p-value: &lt; 2.2e-16\n\n\n\nPart b\nInterpret the coefficient estimate, test statistic, and p-value for the RiverWacamaw coefficient. Assume we have specified a significance level of 0.05.\n\ncoefficient: Holding fish length constant, we estimate the average mercury concentration among fish in the Wacamaw River to be 0.14ppm higher than fish in the Lumber River.\n\n\nTest statistic: The estimate we observe (0.14) is 1.587 standard errors higher than the null value of a 0ppm difference in mercury concentration.\n\n\np-value: Assuming the null hypothesis is true and there is no actual difference in mercury concentration among the two fish populations (adjusting for fish length), the probability of observing a test statistic as or more extreme than |1.587| is 0.114. Because 0.114 &gt; 0.05, we do not have sufficient evidence to reject the null hypothesis, and conclude that the average mercury concentration does not differ between the two rivers.\n\n\n\nPart c\nSuppose we now want to determine if the causal effect of fish length on mercury concentration differs according to the river a fish was sampled from.\nFirst, modify the code chunk below to visualize the 3-way relationship between the Concen, Length, and River variables.\n\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen, colour = River)) + \n  geom_point()+\n  geom_smooth(method=\"lm\", se=F)\n\n\n\n\n\n\n\n\nNext, fit an appropriate linear regression model with an interaction term to investigate this question.\n\nmod_fish2 &lt;- lm(Concen ~ Length * River, data=fish)\nsummary(mod_fish2)\n## \n## Call:\n## lm(formula = Concen ~ Length * River, data = fish)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.27784 -0.35402 -0.08314  0.30650  1.94304 \n## \n## Coefficients:\n##                      Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)         -0.623875   0.325576  -1.916   0.0570 .  \n## Length               0.043185   0.008085   5.341 2.99e-07 ***\n## RiverWacamaw        -0.826291   0.426529  -1.937   0.0544 .  \n## Length:RiverWacamaw  0.024326   0.010483   2.321   0.0215 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.5705 on 167 degrees of freedom\n## Multiple R-squared:  0.4488, Adjusted R-squared:  0.4389 \n## F-statistic: 45.33 on 3 and 167 DF,  p-value: &lt; 2.2e-16\n\n\n\nPart d\nInterpret the coefficient estimate, test statistic, and p-value for the RiverWacamaw:Length interaction term in this revised model (mod_fish2). Assume we’ve set a significance level of 0.05.\n\ncoefficient: First, we interpret the Length coefficient–that is, among fish in the Lumber river, we expect that a 1cm increase in length is associated with a 0.043ppm increase in mercury concentration. The interaction coefficient tells us the expected change in that relationship when considering fish in the Wacamaw River instead: we expect an additional 0.024ppm increase in mercury concentration associated with a 1cm increase in length (i.e., in the Wacamaw River, we expect mercury concentration to increase by 0.067ppm per 1cm increase in fish length).\n\n\nTest statistic: The estimate we observe (0.024326) is 2.321 standard errors higher than the null value of zero.\n\n\np-value: Assuming the null hypothesis is true and there is no difference in the relationship between fish length and mercury between the 2 rivers, the probability of observing a test statistic as or more extreme than |2.321| is 0.02. Because 0.02 &lt; 0.05, we take this as evidence to reject the null hypothesis, and conclude that the effect of fish length on mercury concentration does differ slightly between the two rivers.\n\n\n\nPart e\nInterpret the coefficient estimate, test statistic, and p-value for the RiverWacamaw coefficient in this revised model (mod_fish2). (again, you can assume we’ve set a significance level of 0.05).\n\ncoefficient: Visully, the RiverWacamaw coefficient represents the difference in the y-intercepts for the best fit lines for the Lumber and Wacamaw Rivers in the part d plot. Interpretation: Among fish that are 0cm long, average fish mercury concentrations are 0.826ppm lower in the Wacamaw River than in the Lumber River.\n\n\nTest statistic: The estimate we observe (-0.826291) is 1.937 standard errors lower than the null value of 0.\n\n\np-value: Assuming the null hypothesis is true, the probability of observing a test statistic as or more extreme than |-1.937| is 0.0544. Because 0.0544 &gt; 0.05, we do not have evidence to reject the null.\n\n\n\nPart f (CHALLENGE)\nSuppose another researcher runs the same model we fit in part c above (mod_fish2), but they claim that a more appropriate alternative hypothesis should be Beta_1 &lt; 0, (and not Beta_1 ≠ 0, as is assumed by default when running a regression model). Because of this, they reported a smaller p-value for the coefficient, and claim that the Wacamaw River has a lower baseline mercury concentration (i.e., when Length = 0cm).\nWhat is the p-value they would have reported for the RiverWacamaw coefficient in mod_fish2?\n\n0.0544/2 = 0.0272 (we divide the “two-tailed” p-value in half to obtain the p-value for a “one-tailed” test)\n\nWhat is a potential ethical problem with the other researcher’s claim that the alternative hypothesis should be Beta_1 &lt; 0?\n\nIt is possible that the researchers had a particular reason or incentive to publish evidence in support of their hypothesis (some potential reasons are that scientific journals are generally less interested in publishing results, a financial conflict of interests, or favoring a pet hypothesis). They could have first looked at the results of a “two-tailed” statistical test and since the p-value is very close to the traditional significance threshold of 0.05, come up with a post-hoc rationalization to perform a hypothesis test resulting in a “statistically significant” p-value. This unethical practice is known in the field as “p-hacking.”\n\n\n\nPart g (CHALLENGE)\nYou point out to the other researcher that the intercept and RiverWacamaw coefficients are both negative, so whatever difference in mercury concentration between the two rivers your model predicts “at baseline” is not useful or meaningful–you cannot have a fish that is 0cm long, nor a mercury concentration &lt;0ppm.\nYou propose that a more appropriate model should transform the Length variable in some way to make the intercept more interpretable. Create a new variable named Length_adj with this transformation and use it to re-fit the model:\n\nfish &lt;- fish %&gt;%\n  mutate(Length_adj=Length-min(Length))\n\nmod_fish3 &lt;- lm(Concen ~ Length_adj*River, data=fish)\nsummary(mod_fish3)\n## \n## Call:\n## lm(formula = Concen ~ Length_adj * River, data = fish)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.27784 -0.35402 -0.08314  0.30650  1.94304 \n## \n## Coefficients:\n##                          Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)              0.464384   0.132896   3.494 0.000609 ***\n## Length_adj               0.043185   0.008085   5.341 2.99e-07 ***\n## RiverWacamaw            -0.213287   0.176778  -1.207 0.229321    \n## Length_adj:RiverWacamaw  0.024326   0.010483   2.321 0.021520 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.5705 on 167 degrees of freedom\n## Multiple R-squared:  0.4488, Adjusted R-squared:  0.4389 \n## F-statistic: 45.33 on 3 and 167 DF,  p-value: &lt; 2.2e-16\n\nCompare the output of this model to that of mod_fish2. What happened to the estimate, standard error, test statistic, and p-value for the RiverWacamaw coefficient? How does this affect your conclusion? How about the other researcher’s conclusion?\n\nThe RiverWacamaw coefficient increased (and became closer to 0). The standard error decreased, but the test statistic decreased in magnitude and the p-value increased.\n\n\nWhat happened with this transformation is that the vertical axis got shifted so that the new “zero” was at 25.2cm (the minimum fish length in the data). At this point there is a smaller difference between the Lumber and Wacamaw River lines. However, as we saw above, there does seem to be a true modest difference in the slopes of these lines so there are larger differences between the 2 rivers at larger fish lengths."
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#learning-goals",
    "href": "activities/L16-logistic-univariate.html#learning-goals",
    "title": "Simple logistic regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nExplain the differences between linear regression and logistic regression for modeling binary outcomes\nConstruct simple logistic regression models in R\nInterpret coefficients in simple logistic regression models\nUse simple logistic regression models to make predictions\nDescribe the form (shape) of relationships on the log odds, odds, and probability scales"
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#readings-and-videos",
    "href": "activities/L16-logistic-univariate.html#readings-and-videos",
    "title": "Simple logistic regression",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 4.1-4.3 in the STAT 155 Notes\nVideo: Logistic regression (slides)\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-1-exploring-age",
    "href": "activities/L16-logistic-univariate.html#exercise-1-exploring-age",
    "title": "Simple logistic regression",
    "section": "Exercise 1: Exploring age",
    "text": "Exercise 1: Exploring age\nDid younger passengers tend to have higher survival rates than older passengers?\nVisualizing the relationship between a binary response and a quantitative predictor can be tricky. We will take a few approaches here.\n\nCreate a boxplot where one box corresponds to the age distribution of survivors and the second to that of non-survivors.\nCreate density plots with separate colors for the survivors and non-survivors.\nThe remainder of the code below creates a plot of the fraction who survived at each age. (Since we have a large data set and multiple (though sometimes not many) observations at most ages, we can manually calculate the survival fraction.\n\nAfter inspecting the plots, summarize what you learn.\n\n# Create a boxplot\n# Note that you'll need to force R to view Survived as a binary categorical variable by using x = factor(Survived) instead of just x = Survived in the aes() part of your plot\n\n\n# Create a density plot (you'll need to use factor(Survived) again)\n\n\n# Use the code below to create a plot of the fraction who survived at each age\ntitanic_summ &lt;- titanic %&gt;% \n    group_by(Age) %&gt;%\n    summarize(frac_survived = mean(Survived))\n\nggplot(titanic_summ, aes(x = Age, y = frac_survived)) +\n    geom_point() +\n    geom_smooth(se = FALSE)"
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-2-exploring-sex-and-ticket-class",
    "href": "activities/L16-logistic-univariate.html#exercise-2-exploring-sex-and-ticket-class",
    "title": "Simple logistic regression",
    "section": "Exercise 2: Exploring sex and ticket class",
    "text": "Exercise 2: Exploring sex and ticket class\nWere males or females more likely to survive? Did 1st class passengers tend to survive more than 2nd and 3rd class passengers?\nThe code below creates plots that allow us to explore how Sex and PClass relate to survival. The first two plots are standard bar plots that use color to indicate what fraction of each group survived. The last two plots are mosaic plots that are much like the standard bar plots, but the width of the bars reflects the distribution of the x-axis variable. (The widest bar is the most prevalent category.)\nSummarize what you learn about the relationship between sex, ticket class, and survival.\n\n# Standard bar plots\nggplot(titanic, aes(x = Sex, fill = factor(Survived))) +\n    geom_bar(position = \"fill\")\n\nggplot(titanic, aes(x = PClass, fill = factor(Survived))) +\n    geom_bar(position = \"fill\")\n\n# Mosaic plots\nggplot(data = titanic %&gt;% mutate(Survived = as.factor(Survived))) +\n    geom_mosaic(aes(x = product(Sex), fill = Survived))\n\nggplot(data = titanic %&gt;% mutate(Survived = as.factor(Survived))) +\n    geom_mosaic(aes(x = product(PClass), fill = Survived))"
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-3-linear-regression-model",
    "href": "activities/L16-logistic-univariate.html#exercise-3-linear-regression-model",
    "title": "Simple logistic regression",
    "section": "Exercise 3: Linear regression model",
    "text": "Exercise 3: Linear regression model\nFor now we will focus on exploring the relationship between (ticket) class and survival.\nLet’s tabulate survival across classes. We can tabulate across two variables by providing both variables to count():\n\ntitanic %&gt;% \n    count(PClass, Survived)\n\n\nUse the count() output to fill in the following contingency table:\n\n\n\n\nClass\nDied\nSurvived\nTotal\n\n\n\n\n1st Class\n___\n___\n___\n\n\n2nd Class\n___\n___\n___\n\n\n3rd Class\n___\n___\n___\n\n\nTotal\n___\n___\n___\n\n\n\n\nUsing your table, estimate the following:\n\nthe probability of surviving among 1st class passengers\nthe probability of surviving among 2nd class passengers\nthe probability of surviving among 3rd class passengers\nthe difference in the probability of surviving, comparing 2nd class passengers to 1st class passengers (i.e., how much lower is the probability of 2nd class passengers as compared to 1st class passengers?)\nthe difference in the probability of surviving, comparing 3rd class passengers to 1st class passengers (i.e., how much lower is the probability of 3rd class passengers as compared to 1st class passengers?)\n\nAfter fitting the linear regression model below, write out the model formula using correct notation. Explain carefully what it means to talk about the expected/average value of a binary variable.\n\n\nlin_mod &lt;- lm(Survived ~ PClass, data = titanic)\nsummary(lin_mod)\n\n\nWrite an interpretation of each of the coefficients in your linear regression model. How do your coefficient estimates compare to your answers in part b?"
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-4-logistic-regression-model-categorical-predictor",
    "href": "activities/L16-logistic-univariate.html#exercise-4-logistic-regression-model-categorical-predictor",
    "title": "Simple logistic regression",
    "section": "Exercise 4: Logistic regression model (categorical predictor)",
    "text": "Exercise 4: Logistic regression model (categorical predictor)\n\nRefer back to your contingency table from Exercise 3a. Using your table, estimate the following:\n\nthe odds of surviving among 1st class passengers\nthe odds of surviving among 2nd class passengers\nthe odds of surviving among 3rd class passengers\nthe ratio of the odds of surviving, comparing 2nd class passengers to 1st class passengers (i.e., how many times higher/lower is the odds of survival among 2nd class passengers as compared to 1st class passengers?)\nthe ratio of the odds of surviving, comparing 3rd class passengers to 1st class passengers\n\nAfter fitting the logistic regression model below, write out the model formula using correct notation.\n\n\nlog_mod &lt;- glm(Survived ~ PClass, data = titanic, family = \"binomial\")\ncoef(summary(log_mod))\n\n\nWrite an interpretation of each of the exponentiated coefficients in your logistic regression model. Think carefully about what we are modeling when we fit a logistic regression model. How do these exponentiated coefficient estimates compare to your answers in part a?"
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-5-logistic-regression-model-quantitative-predictor",
    "href": "activities/L16-logistic-univariate.html#exercise-5-logistic-regression-model-quantitative-predictor",
    "title": "Simple logistic regression",
    "section": "Exercise 5: Logistic regression model (quantitative predictor)",
    "text": "Exercise 5: Logistic regression model (quantitative predictor)\nNow we will explore how to interpret a quantitative predictor in a logistic regression model.\n\nAfter fitting the logistic regression model below, write out the model formula using correct notation.\n\n\nlog_mod &lt;- glm(Survived ~ Age, data = titanic, family = \"binomial\")\ncoef(summary(log_mod))\n\n\nWrite an interpretation of each of the exponentiated coefficients in this logistic regression model."
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-6-linear-vs.-logistic-modeling",
    "href": "activities/L16-logistic-univariate.html#exercise-6-linear-vs.-logistic-modeling",
    "title": "Simple logistic regression",
    "section": "Exercise 6: Linear vs. logistic modeling",
    "text": "Exercise 6: Linear vs. logistic modeling\nTo highlight a key difference between linear vs. logistic modeling, consider the following linear and logistic regression models of survival with sex and age as predictors in addition to ticket class.\n\nlin_mod2 &lt;- lm(Survived ~ PClass + Sex + Age, data = titanic)\ncoef(summary(lin_mod2))\n\nlog_mod2 &lt;- glm(Survived ~ PClass + Sex + Age, data = titanic, family = \"binomial\")\ncoef(summary(log_mod2))\n\n\nUse the linear regression model to predict the probability of survival for Rose (a 17 year old female in 1st class) and Jack (a 20 year old male in 3rd class). Show your work.\nNow use the logistic regression model to predict the survival probability for Rose and Jack. Show your work. (Hint: use the logistic regression model to obtain the predicted log odds, exponentiate to get the odds, and then convert to probability.)\nComment on differences that you notice in the predictions from parts a and b."
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#reflection",
    "href": "activities/L16-logistic-univariate.html#reflection",
    "title": "Simple logistic regression",
    "section": "Reflection",
    "text": "Reflection\nWhat binary outcomes might be relevant in your project? What predictor(s) could be relevant in a logistic regression model for that outcome?\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-1-exploring-age-1",
    "href": "activities/L16-logistic-univariate.html#exercise-1-exploring-age-1",
    "title": "Simple logistic regression",
    "section": "Exercise 1: Exploring age",
    "text": "Exercise 1: Exploring age\nThe boxplot doesn’t clearly indicate a difference in the age distributions across survivors and non-survivors, but we do notice from the density plot that there is a greater density of younger passengers among the survivors. We also see from the last plot that younger passengers tend to have a higher survival chance.\n\n# Create a boxplot\nggplot(titanic, aes(x = factor(Survived), y = Age)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n# Can flip the boxplot on its side too\nggplot(titanic, aes(y = factor(Survived), x = Age)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n# Create a density plot\nggplot(titanic, aes(x = Age, color = factor(Survived))) +\n    geom_density()\n\n\n\n\n\n\n\n\n# Use the code below to create a plot of the fraction who survived at each age\ntitanic_summ &lt;- titanic %&gt;% \n    group_by(Age) %&gt;%\n    summarize(frac_survived = mean(Survived))\n\nggplot(titanic_summ, aes(x = Age, y = frac_survived)) +\n    geom_point() +\n    geom_smooth(se = FALSE)"
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-2-exploring-sex-and-ticket-class-1",
    "href": "activities/L16-logistic-univariate.html#exercise-2-exploring-sex-and-ticket-class-1",
    "title": "Simple logistic regression",
    "section": "Exercise 2: Exploring sex and ticket class",
    "text": "Exercise 2: Exploring sex and ticket class\n\nFemales were more likely to survive than males.\n1st class was most likely to survive, followed by 2nd then 3rd class.\n\n\n# Standard bar plots\nggplot(titanic, aes(x = Sex, fill = factor(Survived))) +\n    geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nggplot(titanic, aes(x = PClass, fill = factor(Survived))) +\n    geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n# Mosaic plots\nggplot(data = titanic %&gt;% mutate(Survived = as.factor(Survived))) +\n    geom_mosaic(aes(x = product(Sex), fill = Survived))\n\n\n\n\n\n\n\n\nggplot(data = titanic %&gt;% mutate(Survived = as.factor(Survived))) +\n    geom_mosaic(aes(x = product(PClass), fill = Survived))"
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-3-linear-regression-model-1",
    "href": "activities/L16-logistic-univariate.html#exercise-3-linear-regression-model-1",
    "title": "Simple logistic regression",
    "section": "Exercise 3: Linear regression model",
    "text": "Exercise 3: Linear regression model\n\ntitanic %&gt;% \n    count(PClass, Survived)\n## # A tibble: 7 × 3\n##   PClass Survived     n\n##   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n## 1 1st           0   129\n## 2 1st           1   193\n## 3 2nd           0   160\n## 4 2nd           1   119\n## 5 3rd           0   573\n## 6 3rd           1   138\n## 7 &lt;NA&gt;          0     1\n\n\n\n\n\n\n\nClass\nDied\nSurvived\nTotal\n\n\n\n\n1st Class\n129\n193\n322\n\n\n2nd Class\n160\n119\n279\n\n\n3rd Class\n573\n138\n711\n\n\nTotal\n862\n450\n1312\n\n\n\n\n\nthe probability of surviving among 1st class passengers: 193/322 = 0.599\nthe probability of surviving among 2nd class passengers: 119/279 = 0.427\nthe probability of surviving among 3rd class passengers: 138/711 = 0.194\nthe difference in the probability of surviving, comparing 2nd class passengers to 1st class passengers (i.e., how much lower is the probability of 2nd class passengers as compared to 1st class passengers?): 119/279 - 193/322 = -0.173\nthe difference in the probability of surviving, comparing 3rd class passengers to 1st class passengers (i.e., how much lower is the probability of 3rd class passengers as compared to 1st class passengers?): 138/711 - 193/322 = -0.405\n\nThis model can be written as: \\(E[Survived | PClass] = \\beta_0 + \\beta_1 PClass2nd + \\beta_2 PClass3rd\\).\n\nIn the context of a binary variable, the expected value/average is the same as the probability that the variable equals one. To see an example of this, calculate the average of this list of 0’s and 1’s: (0,0,1,1,0,1,0,1). Now calculate the proportion of 1’s. What do you notice?\nThis means that we can also write this model as follows: \\(P[Survived = 1 | PClass] = \\beta_0 + \\beta_1 PClass2nd + \\beta_2 PClass3rd\\)\n\n\n\nlin_mod &lt;- lm(Survived ~ PClass, data = titanic)\nsummary(lin_mod)\n## \n## Call:\n## lm(formula = Survived ~ PClass, data = titanic)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -0.5994 -0.1941 -0.1941  0.4006  0.8059 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.59938    0.02468  24.284  &lt; 2e-16 ***\n## PClass2nd   -0.17286    0.03623  -4.772 2.03e-06 ***\n## PClass3rd   -0.40529    0.02975 -13.623  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4429 on 1309 degrees of freedom\n##   (1 observation deleted due to missingness)\n## Multiple R-squared:  0.1315, Adjusted R-squared:  0.1302 \n## F-statistic: 99.09 on 2 and 1309 DF,  p-value: &lt; 2.2e-16\n\n\nThe coefficient estimates are the differences in probability from part b!\n\n(Intercept): the estimated probability of survival for passengers in 1st class is 0.599 (59.9%)\nPClass2nd: the difference in the estimated probability of survival comparing passengers in 1st class to passengers in 2nd class is 0.173 (17.3%), where passengers in 1st class have the higher estimated survival probability\n\nOR… comparing passengers in 1st class to passengers in 2nd class, the difference in the proportion of passengers that survived is 0.173 (17.3%), with 1st class having a higher proportion of passengers that survived\nOR… the probability of survival is 17.3% lower among passengers in 2nd class than it is among passengers in 1st class\n\nPClass3rd: the difference in the estimated probability of survival comparing passengers in 1st class to passengers in 3rd class is 0.405 (40.5%), where passengers in 1st class have the higher estimated survival probability"
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-4-logistic-regression-model-categorical-predictor-1",
    "href": "activities/L16-logistic-univariate.html#exercise-4-logistic-regression-model-categorical-predictor-1",
    "title": "Simple logistic regression",
    "section": "Exercise 4: Logistic regression model (categorical predictor)",
    "text": "Exercise 4: Logistic regression model (categorical predictor)\n\n\nthe odds of surviving among 1st class passengers: 193/129 = 1.496\nthe odds of surviving among 2nd class passengers: 119/160 = 0.744\nthe odds of surviving among 3rd class passengers: 138/573 = 0.241\nthe ratio of the odds of surviving, comparing 2nd class passengers to 1st class passengers (i.e., how many times higher/lower is the odds of survival among 2nd class passengers as compared to 1st class passengers?): (119/160)/(193/129) = 0.497\nthe ratio of the odds of surviving, comparing 3rd class passengers to 1st class passengers: (138/573)/(193/129) = 0.161\n\n\\(\\log(Odds[Survived = 1 | PClass]) = \\beta_0 + \\beta_1 PClass2nd + \\beta_2 PClass3rd\\)\n\n\nlog_mod &lt;- glm(Survived ~ PClass, data = titanic, family = \"binomial\")\n\n# These logistic coefficient estimates are NOT exponentiated\ncoef(summary(log_mod))\n##               Estimate Std. Error    z value     Pr(&gt;|z|)\n## (Intercept)  0.4028778  0.1137246   3.542574 3.962427e-04\n## PClass2nd   -0.6989281  0.1660923  -4.208071 2.575600e-05\n## PClass3rd   -1.8265098  0.1480705 -12.335410 5.839072e-35\n\n\n# Calculations for exponentiating coefficients\nexp(0.4028778)\n## [1] 1.496124\nexp(-0.6989281)\n## [1] 0.4971179\nexp(-1.8265098)\n## [1] 0.1609744\n\n\nThese exponentiated coefficient estimates compare to your the odds and odds ratios in part a!\n\nexp(Intercept): the estimated odds of survival among passengers in first class is 1.496 (i.e., passengers in first class are 1.496 times more likely to survive than they are to die)\nexp(PClass2nd): we estimate that the odds of survival for passengers in 2nd class are only 0.50 times as high as the odds of survival among passengers in 1st class (i.e., the odds of survival are 2 times higher among passengers in 1st class than they are among passengers in 2nd class)\nexp(PClass3rd): we estimate that the odds of survival for passengers in 3rd class are only 0.16 times as high as the odds of survival among passengers in 1st class (i.e., the odds of survival are 1/0.16 = 6.21 times higher among passengers in 1st class than they are among passengers in 3rd class)"
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-5-logistic-regression-model-quantitative-predictor-1",
    "href": "activities/L16-logistic-univariate.html#exercise-5-logistic-regression-model-quantitative-predictor-1",
    "title": "Simple logistic regression",
    "section": "Exercise 5: Logistic regression model (quantitative predictor)",
    "text": "Exercise 5: Logistic regression model (quantitative predictor)\n\nAfter fitting the logistic regression model below, write out the model formula using correct notation.\n\n\nlog_mod &lt;- glm(Survived ~ Age, data = titanic, family = \"binomial\")\ncoef(summary(log_mod))\n##                Estimate Std. Error    z value   Pr(&gt;|z|)\n## (Intercept) -0.08142783 0.17386170 -0.4683483 0.63953556\n## Age         -0.00879462 0.00523158 -1.6810637 0.09275054\n\n\\(\\log(Odds[Survived = 1 | Age]) = \\beta_0 + \\beta_1 Age\\)\n\nWrite an interpretation of each of the exponentiated coefficients in this logistic regression model.\n\n\nexp(Intercept): \\(exp(-0.0814)=0.92\\) –&gt; the estimated odds of survival among passengers who are 0 years old is 0.92 (i.e., passengers who are 0 years old are 0.92 times more likely to survive than they are to die–so very slightly more likely to die)\nexp(Age): \\(exp(-0.0088)=0.99\\) –&gt; For every 1-year increase in a passenger’s age, the estimated odds of survival decrease by about 1%."
  },
  {
    "objectID": "activities/L16-logistic-univariate.html#exercise-6-linear-vs.-logistic-modeling-1",
    "href": "activities/L16-logistic-univariate.html#exercise-6-linear-vs.-logistic-modeling-1",
    "title": "Simple logistic regression",
    "section": "Exercise 6: Linear vs. logistic modeling",
    "text": "Exercise 6: Linear vs. logistic modeling\nTo highlight a key difference between linear vs. logistic modeling, consider the following linear and logistic regression models of survival with sex and age as predictors in addition to ticket class.\n\nlin_mod2 &lt;- lm(Survived ~ PClass + Sex + Age, data = titanic)\ncoef(summary(lin_mod2))\n##                 Estimate  Std. Error    t value     Pr(&gt;|t|)\n## (Intercept)  1.130522829 0.051940872  21.765573 8.158449e-82\n## PClass2nd   -0.207433817 0.039239825  -5.286308 1.637737e-07\n## PClass3rd   -0.393344488 0.037709874 -10.430809 7.001373e-24\n## Sexmale     -0.501325667 0.029419802 -17.040416 2.697807e-55\n## Age         -0.006004789 0.001105949  -5.429536 7.633977e-08\n\nlog_mod2 &lt;- glm(Survived ~ PClass + Sex + Age, data = titanic, family = \"binomial\")\ncoef(summary(log_mod2))\n##                Estimate  Std. Error    z value     Pr(&gt;|z|)\n## (Intercept)  3.75966210 0.397567324   9.456668 3.179129e-21\n## PClass2nd   -1.29196240 0.260075781  -4.967638 6.777324e-07\n## PClass3rd   -2.52141915 0.276656805  -9.113888 7.948131e-20\n## Sexmale     -2.63135683 0.201505379 -13.058494 5.684093e-39\n## Age         -0.03917681 0.007616218  -5.143868 2.691392e-07\n\n\n\n\n\n## predict for Rose\n## (by hand)\n1.130523 + (-0.207434)*0 + (-0.393344)*0 + (-0.501326)*0 + (-0.006005)*17\n## [1] 1.028438\n\n## (using predict)\npredict(lin_mod2, newdata = data.frame(PClass = \"1st\", Sex = \"female\", Age = 17))\n##        1 \n## 1.028441\n\n## predict for Jack\n## (by hand)\n1.130523 + (-0.207434)*0 + (-0.393344)*1 + (-0.501326)*1 + (-0.006005)*20\n## [1] 0.115753\n\n## (using predict)\npredict(lin_mod2, newdata = data.frame(PClass = \"3rd\", Sex = \"male\", Age = 20))\n##         1 \n## 0.1157569\n\n\n\n\n\n## predict for Rose\n## (by hand)\nlog_odds_rose &lt;- 3.75966210 + (-1.29196240)*0 + (-2.52141915)*0 + (-2.63135683)*0 + (-0.03917681)*17\nodds_rose &lt;- exp(log_odds_rose)\nodds_rose/(1+odds_rose)\n## [1] 0.9566303\n\n## (using predict)\npredict(log_mod2, newdata = data.frame(PClass = \"1st\", Sex = \"female\", Age = 17), type = \"response\")\n##         1 \n## 0.9566303\n\n## predict for Jack\n## (by hand)\nlog_odds_jack &lt;- 3.75966210 + (-1.29196240)*0 + (-2.52141915)*1 + (-2.63135683)*1 + (-0.03917681)*20\nodds_jack &lt;- exp(log_odds_jack)\nodds_jack/(1+odds_jack)\n## [1] 0.101867\n\n## (using predict)\npredict(log_mod2, newdata = data.frame(PClass = \"3rd\", Sex = \"male\", Age = 20), type = \"response\")\n##        1 \n## 0.101867\n\n\nOur linear model predicted that Rose’s probability of survival was over 100% (which doesn’t make sense). The predictions for Jack are fairly similar: 10.2% based on our logistic model and 11.6% based on our linear model."
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#learning-goals",
    "href": "activities/L12-mlr-interaction-practice.html#learning-goals",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nVisualize interactions between categorical and quantitative predictors using scatterplots and side-by-side or boxplots\nCritically think through whether an interaction term makes sense, or should be included in a multiple linear regression model\nWrite a model formula for a multiple linear regression model with an interaction term between two quantitative predictors, two categorical predictors, or one quantitative and one categorical predictor\nInterpret the intercept and slope coefficients in a multiple linear regression model with an interaction term"
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#readings-and-videos",
    "href": "activities/L12-mlr-interaction-practice.html#readings-and-videos",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Section 3.9.3 in the STAT 155 Notes\nVideo:\n\nInteraction variables\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-1-translating-scientific-questions-into-statistical-questions",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-1-translating-scientific-questions-into-statistical-questions",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 1: Translating scientific questions into statistical questions",
    "text": "Exercise 1: Translating scientific questions into statistical questions\n\nLook at the variables we have access to in the cleaned version of the data we read into R, and consider our first research question. How might we translate this question into a statistical one, that we could answer using the data we have available?\n\nThere is no one right answer to this! Brainstorm with your group.\n\nhead(campaigns)\n\n\nQuestion 2 (a) is a bit more specific than Question 1. Translate this question into a statistical one that can be answered using a simple linear regression model. Write out the model statement in \\(E[Y | X] = ...\\) notation that would answer this question, and note which regression coefficient you would interpret to provide you with an answer.\n\n\\[\nE[___ | ___] = ...\n\\]\n\nQuestion 2 (b) is also specific, and builds on Question 2 (a). Translate this question into a statistical one that can be answered using a multiple linear regression model. Write out the model statement in \\(E[Y | X] = ...\\) notation that would answer this question, and note which regression coefficient you would interpret to provide you with an answer.\n\n\\[\nE[___ | ___] = ...\n\\]"
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-2-visualizing-interaction",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-2-visualizing-interaction",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 2: Visualizing Interaction",
    "text": "Exercise 2: Visualizing Interaction\n\nWrite R code to visualize the relationship between campaign spending and number of votes a candidate received. Include an aesthetic to distinguish this relationship between incumbents and challengers. Do not include lines of best fit from any statistical model on your plot at this point!\n\n\n# Visualization\n\n\nBased on your visualization from part (a), what are your answers to research questions 2 (a) and 2 (b)? Write your answer in 2-3 sentences, describing general trends you notice, suitable for a general audience.\nAdd lines of best fit from a statistical model that includes an interaction term between incumbent status and spending to your plot from part (a), using geom_smooth. Based on your updated plot, do you think including an interaction between incumbent status and spending in a multiple linear regression model would be meaningful in this context? Why or why not?\n\n\n# Visualization with lines of best fit"
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-3-fitting-and-interpreting-models-with-interaction-terms",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-3-fitting-and-interpreting-models-with-interaction-terms",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 3: Fitting and interpreting models with interaction terms",
    "text": "Exercise 3: Fitting and interpreting models with interaction terms\n\nFit the regression model you wrote out in Exercise 1 (c). Report (do not interpret yet!) the regression coefficients below.\n\n\n# Model with interaction term\n\n\n(Intercept):\n\n\nincumbentYes:\n\n\nspending:\n\n\nincumbentYes:spending:\n\n\nUsing the coefficient estimates from part (a), write out two separate model statements, one for incumbents and one for challengers. Combine terms (using algebra) when you can! Hint: remember the indicator variables video!\n\n\nFor incumbents:\n\n\\[\nE[votes | spending] =\n\\]\n\nFor challengers:\n\n\\[\nE[votes | spending] =\n\\]\n\nInterpret the coefficient for incumbent in your interaction model, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Is this coefficient scientifically meaningful?\nWhen interpreting an interaction coefficient where one of the variables interacting is quantitative and one is categorical, it is often convenient to do so in separate sentences: interpret the slope for each category separately!\n\nInterpret the coefficient for the interaction term in your model, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\n\nBased on your interpretation in part (d), and the visualization you made including lines of best fit, do you think that including an interaction term for incumbent status and spending is meaningful, when predicting number of votes? Explain why or why not."
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-4-interactions-between-two-categorical-variables",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-4-interactions-between-two-categorical-variables",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 4: Interactions between two categorical variables",
    "text": "Exercise 4: Interactions between two categorical variables\nLet’s return to our data on bike ridership. Suppose we are interested in the relationship between daily ridership (our response variable) and whether a user is a casual or registered rider and whether the day falls on a weekend. First, we need to create a binary variable indicating whether a user is a casual or registered rider.\n\n# Creating user variable, don't worry about syntax!\nnew_bikes &lt;- bikes %&gt;%\n  dplyr::select(riders_casual, riders_registered, weekend, temp_actual) %&gt;%\n  pivot_longer(cols = riders_casual:riders_registered, names_to = \"user\",\n               names_prefix = \"riders_\", values_to = \"rides\") %&gt;%\n  mutate(weekend = factor(weekend))\n\n\nFor each of our three relevant variables, weekend, user, and rides, classify them as quantitative or categorical.\n\n\nweekend:\n\n\nuser:\n\n\nrides:\n\n\nMake an appropriate visualization to explore the relationship between these three variables.\n\n\n# Visualization\n\n\nIs the relationship between ridership and weekend status the same for both registered and casual users? Explain why or why not, referencing the visualization you made in part (b).\nTo reflect what you observed in your visualization, fit a multiple linear regression model with an interaction term between weekend and user in our model of ridership.\n\n\n# Multiple linear regression model\n\n\nInterpret the interaction term from your model, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Just as in Exercise 3, you may find it useful to first write out multiple model statements for different categories defined by one of your categorical variables, and proceed from there!"
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-5-interactions-between-two-quantitative-variables",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-5-interactions-between-two-quantitative-variables",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 5: Interactions between two quantitative variables",
    "text": "Exercise 5: Interactions between two quantitative variables\nHere we’ll explore the relationship between price, milage, and age of a used car. Below is a scatterplot of mileage vs. price, colored by age:\n\ncars %&gt;% \n  ggplot(aes(x = milage, y = price, col = age)) +\n  geom_point(alpha = 0.5) + # make the points less opaque\n  scale_color_viridis_c(option = \"H\") + # a fun, colorblind-friendly palette!\n  theme_classic() # removes the gray background and grid\n\nIt’s a little difficult to tell what exactly is going on here. In particular, does the relationship between mileage and price vary with age of a used car? Let’s try adding some fitted lines for cars of different ages.\n\n# Ignore where the numbers in geom_abline() came from for now... we'll get there\ncars %&gt;% \n  ggplot(aes(x = milage, y = price, col = age)) +\n  geom_point(alpha = 0.5) + \n  scale_color_viridis_c(option = \"H\") + \n  theme_classic() +\n  geom_abline(slope = -6.558e-01 + 2.431e-02, intercept = 9.096e+04 -2.665e+03, col = \"black\") +\n  geom_abline(slope = -6.558e-01 + 10 * 2.431e-02, intercept = 9.096e+04 - 10 * 2.665e+03, col = \"blue\") +\n  geom_abline(slope = -6.558e-01 + 30 * 2.431e-02, intercept = 9.096e+04 - 30 * 2.665e+03, col = \"green\") +\n  ggtitle(\"Black: Age = 1yr, Blue: Age = 10yr, Green: Age = 30yr\")\n\n\nChallenge question: Based on the fitted lines in the plot above, anticipate what the signs (positive or negative) of the coefficients in the following interaction model will be:\n\n\\[\nE[price | age, milage] = \\beta_0 + \\beta_1 milage + \\beta_2 age + \\beta_3 milage:age\n\\] * \\(\\beta_0\\): Put your response here…\n\n\\(\\beta_1\\): Put your response here…\n\\(\\beta_2\\): Put your response here…\n\\(\\beta_3\\): Put your response here…\n\n\nFit a multiple linear regression model with an interaction term between milage and age in our model of used car price.\n\n\n# Multiple linear regression model\n\n\n\n# ... now do you see where the numbers in geom_abline() came from?\n\nAs before, we could choose distinct ages, and interpret the relationship between mileage and price for each of those groups separately. However, since age is quantitative and not categorical, this doesn’t quite give us the whole picture. Instead, we want to know how the relationship between mileage and price changes for each additional year old a car is. This is what the interaction coefficient estimates, when the interaction term is between two quantitative variables!\n\nInterpret the interaction term, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases."
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#reflection",
    "href": "activities/L12-mlr-interaction-practice.html#reflection",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Reflection",
    "text": "Reflection\nThrough the exercises above, you practiced visualizing, fitting, and interpreting multiple linear regression models with interaction terms between combinations of categorical and quantitative variables. Think about how the fitted lines looked in situations where you think there was a meaningful interaction taking place. How do you think the fitted lines would look if there was no meaningful interaction present? Explain your reasoning.\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-1-translating-scientific-questions-into-statistical-questions-1",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-1-translating-scientific-questions-into-statistical-questions-1",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 1: Translating scientific questions into statistical questions",
    "text": "Exercise 1: Translating scientific questions into statistical questions\n\nFrom this question, the only clear variable that should be involved in our analysis/exploration is spending. We could first begin by providing numerical and visual summaries of campaign spending. We could also look at whether spending varies by district, number of votes, or incumbency status. This would give us a broad idea of how campagin spending may vary across the variables we access to in our data.\nWe can estimate the average associated increase in number of votes per additional 1,000 Euros spent, via a simple linear regression model. The model statement that allows us to answer this question is given by\n\n\\[\nE[votes | spending] = \\beta_0 + \\beta_1 spending\n\\] The regression coefficient we would interpret to answer this question is the coefficient fpr spending, which in this case is \\(\\beta_1\\).\n\nWe are interested in the how the association between average number of votes and campaign spending varies by incumbency status. The model statement that allows us to answer this question is given by\n\n\\[\nE[votes | spending, incumbent] = \\beta_0 + \\beta_1 spending + \\beta_2 incumbent + \\beta_3 spending:incumbent\n\\]\n(note that the order in which you put spending and incumbent status does not matter!)\nThe regression coefficient we would interpret to answer this question is the interaction coefficient, which in this case is \\(\\beta_3\\)."
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-2-visualizing-interaction-1",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-2-visualizing-interaction-1",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 2: Visualizing Interaction",
    "text": "Exercise 2: Visualizing Interaction\n\n\n\n\n# Visualization\ncampaigns %&gt;%\n  ggplot(aes(spending, votes, col = incumbent)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nIn general, the more a candidate spends on their campaign, the more votes they receive. Incumbents appear to spend more than challengers on their campaigns, typically. The impact of spending on votes appears to be greater for challengers than for incumbents, in that more spending may lead to even more votes for challengers, than it would for incumbents.\nI think including an interaction term between incumbent status and spending would be meaningful, since the relationship between spending and votes does seem to vary by incumbent status. In particular, note that the lines on the visualization are not parallel. Parallel lines imply that there is no interaction present, so the further the lines are from parallel, the more intense (in some sense) the interaction term.\n\n\n# Visualization with lines of best fit\ncampaigns %&gt;%\n  ggplot(aes(spending, votes, col = incumbent)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-3-fitting-and-interpreting-models-with-interaction-terms-1",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-3-fitting-and-interpreting-models-with-interaction-terms-1",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 3: Fitting and interpreting models with interaction terms",
    "text": "Exercise 3: Fitting and interpreting models with interaction terms\n\n\n\n\n# Model with interaction term\nlm(data = campaigns, votes ~ spending*incumbent)\n## \n## Call:\n## lm(formula = votes ~ spending * incumbent, data = campaigns)\n## \n## Coefficients:\n##           (Intercept)               spending           incumbentYes  \n##                 690.5                  209.7                 4813.9  \n## spending:incumbentYes  \n##                -125.9\n\n\n(Intercept): 690.5\n\n\nincumbentYes: 4813.9\n\n\nspending: 209.7\n\n\nincumbentYes:spending: -125.9\n\n\n\n\n\nFor incumbents:\n\n\\[\nE[votes | spending] = 690 + 4813.9 + 209.7 * spending - 125.9 * spending = 5503.9 + 83.8 * spending\n\\]\n\nFor challengers:\n\n\\[\nE[votes | spending] = 690.5 + 209.7 * spending\n\\]\n\nOn average, we expect the difference in number of votes between incumbents and challengers to be 4813.9, for campaigns where no money is spent. This is likely not a scientifically meaningful estimate since there are very few campaigns where no money is spent. However, such campaigns do exist, so I would say this one could be meaningful in certain contexts, if not broadly!\nOn average, we expect an increase in spending by 1,000 euros to be associated with an increase in number of votes by 210, for challengers. On average, we expect an increase in spending by 1,000 euros to be associated with an increase in number of votes by 84, for incumbents.\nI think the interaction term is meaningful when predicting number of votes, since 84 and 210 are relatively different numbers! The interaction term gives us the additional information that spending has less of an effect on number of votes for incumbents than it does for challengers, which is particularly meaningful if you are a campaign manager!"
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-4-interactions-between-two-categorical-variables-1",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-4-interactions-between-two-categorical-variables-1",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 4: Interactions between two categorical variables",
    "text": "Exercise 4: Interactions between two categorical variables\n\n# Creating user variable, don't worry about syntax!\nnew_bikes &lt;- bikes %&gt;%\n  dplyr::select(riders_casual, riders_registered, weekend, temp_actual) %&gt;%\n  pivot_longer(cols = riders_casual:riders_registered, names_to = \"user\",\n               names_prefix = \"riders_\", values_to = \"rides\") %&gt;%\n  mutate(weekend = factor(weekend))\n\n\n\n\n\nweekend: categorical (binary)\n\n\nuser: categorical (binary)\n\n\nrides: quantitative\n\n\n\n\n\n# Visualization\nnew_bikes %&gt;%\n  ggplot(aes(y = rides, user, fill = weekend)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nThe relationship between ridership and weekend status does not appear to be the same for registered and casual users. Specifically, casual users have higher median riders on weekends, whereas the opposite is true for registered users.\n\n\n\n# Multiple linear regression model\nlm(data = new_bikes, rides ~ user * weekend)\n## \n## Call:\n## lm(formula = rides ~ user * weekend, data = new_bikes)\n## \n## Coefficients:\n##                (Intercept)              userregistered  \n##                      625.0                      3300.5  \n##                weekendTRUE  userregistered:weekendTRUE  \n##                      776.7                     -1714.4\n\n\nOn average, we expect there to be 777 more rides on weekends compared to non-weekends, for casual riders. On average, we expect there to be 938 (776.7 - 1714.4, rounded) less rides on weekends compared to non-weekends, for registered riders.\n\nNote: There are lots of ways you could correctly interpret the interaction term here! You could do it one sentence, you could do it in four (one for each unique group defined by the two categorical variables), or you could compare users and registered riders for weekends, and then separately for non-weekends! All are valid options."
  },
  {
    "objectID": "activities/L12-mlr-interaction-practice.html#exercise-5-interactions-between-two-quantitative-variables-1",
    "href": "activities/L12-mlr-interaction-practice.html#exercise-5-interactions-between-two-quantitative-variables-1",
    "title": "Multiple linear regression: interaction terms practice",
    "section": "Exercise 5: Interactions between two quantitative variables",
    "text": "Exercise 5: Interactions between two quantitative variables\nHere we’ll explore the relationship between price, milage, and age of a used car. Below is a scatterplot of mileage vs. price, colored by age:\n\ncars %&gt;% \n  ggplot(aes(x = milage, y = price, col = age)) +\n  geom_point(alpha = 0.5) + # make the points less opaque\n  scale_color_viridis_c(option = \"H\") + # a fun, colorblind-friendly palette!\n  theme_classic() # removes the gray background and grid\n\n\n\n\n\n\n\n\nIt’s a little difficult to tell what exactly is going on here. In particular, does the relationship between mileage and price vary with age of a used car? Let’s try adding some fitted lines for cars of different ages.\n\n# Ignore where the numbers in geom_abline() came from for now... we'll get there\ncars %&gt;% \n  ggplot(aes(x = milage, y = price, col = age)) +\n  geom_point(alpha = 0.5) + \n  scale_color_viridis_c(option = \"H\") + \n  theme_classic() +\n  geom_abline(slope = -6.558e-01 + 2.431e-02, intercept = 9.096e+04 -2.665e+03, col = \"black\") +\n  geom_abline(slope = -6.558e-01 + 10 * 2.431e-02, intercept = 9.096e+04 - 10 * 2.665e+03, col = \"blue\") +\n  geom_abline(slope = -6.558e-01 + 30 * 2.431e-02, intercept = 9.096e+04 - 30 * 2.665e+03, col = \"green\") +\n  ggtitle(\"Black: Age = 1yr, Blue: Age = 10yr, Green: Age = 30yr\")\n\n\n\n\n\n\n\n\n\n\n\n\\[\nE[price | age, milage] = \\beta_0 + \\beta_1 milage + \\beta_2 age + \\beta_3 milage:age\n\\] * \\(\\beta_0\\): positive, since the intercept is the average price for a car with zero miles that is brand new.\n\n\\(\\beta_1\\): negative, since the more miles a new car has, the cheaper it should be\n\\(\\beta_2\\): negative, since the intercept of the lines seems to decrease with age (black -&gt; blue -&gt; green)\n\\(\\beta_3\\): positive, since the slope of the lines seems to increase with age (black -&gt; blue -&gt; green)\n\n\n\n\n\n# Multiple linear regression model\n\nlm(data = cars, price ~ milage * age)\n## \n## Call:\n## lm(formula = price ~ milage * age, data = cars)\n## \n## Coefficients:\n## (Intercept)       milage          age   milage:age  \n##   9.096e+04   -6.558e-01   -2.665e+03    2.431e-02\n\n# ... now do you see where the numbers in geom_abline() came from?\n\nAs before, we could choose distinct ages, and interpret the relationship between mileage and price for each of those groups separately. However, since age is quantitative and not categorical, this doesn’t quite give us the whole picture. Instead, we want to know how the relationship between mileage and price changes for each additional year old a car is. This is what the interaction coefficient estimates, when the interaction term is between two quantitative variables!\n\nOn average, we expect that an increase in mileage by 1 mile is associated with an additional increase in price by $0.0243 for each additional year old the car is."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#learning-goals",
    "href": "activities/L09-mlr-principles.html#learning-goals",
    "title": "Multiple regression principles",
    "section": "Learning goals",
    "text": "Learning goals\nWorking with multiple predictors in our plots and models can get complicated!\nThere are no recipes for this process.\nBUT there are some guiding principles that assist in long-term retention, deeper understanding, and the ability to generalize our tools in new settings.\nBy the end of this lesson, you should be familiar with some general principles for…\n\nincorporating additional quantitative or categorical predictors in a visualization\nhow additional quantitative or categorical predictors impact the physical representation of a model\ninterpreting quantitative or categorical coefficients in a multiple regression model"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#readings-and-videos",
    "href": "activities/L09-mlr-principles.html#readings-and-videos",
    "title": "Multiple regression principles",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease watch the following video before class.\n\nInterpreting multivariate models (slides)"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-1-review-visualization",
    "href": "activities/L09-mlr-principles.html#exercise-1-review-visualization",
    "title": "Multiple regression principles",
    "section": "Exercise 1: Review visualization",
    "text": "Exercise 1: Review visualization\nLet’s build a model of rides by windspeed (quantitative) and weekend status (categorical).\n\nWrite a model statement for this regression model.\nPlot & describe, in words, the relationship between these 3 variables.\n\n\n# Plot of rides vs windspeed & weekend\n# HINT: Start with a plot of rides vs windspeed, then add an aesthetic for weekend!"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-2-review-model",
    "href": "activities/L09-mlr-principles.html#exercise-2-review-model",
    "title": "Multiple regression principles",
    "section": "Exercise 2: Review model",
    "text": "Exercise 2: Review model\nLet’s build the model. Run the following code:\n\nbike_model_1 &lt;- lm(rides ~ windspeed + weekend, data = bikes)\ncoef(summary(bike_model_1))\n\nThe model formula with our coefficient estimates filled in is therefore:\nE[rides | windspeed, weekendTRUE] = 4738.38 - 63.97 * windspeed - 925.16 * weekendTRUE\nThis model formula is represented by 2 lines, one corresponding to weekends and the other to weekdays. Simplify the model formula above for weekdays and weekends:\nweekdays: rides = ___ - ___ windspeed\nweekends: rides = ___ - ___ windspeed"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-3-review-coefficient-interpretation",
    "href": "activities/L09-mlr-principles.html#exercise-3-review-coefficient-interpretation",
    "title": "Multiple regression principles",
    "section": "Exercise 3: Review coefficient interpretation",
    "text": "Exercise 3: Review coefficient interpretation\n\nThe intercept coefficient, 4738.38, represents the intercept of the sub-model for weekdays, the reference category. What’s its contextual interpretation?\nThe windspeed coefficient, -63.97, represents the shared slope of the weekend and weekday sub-models. What’s its contextual interpretation?\nThe weekendTRUE coefficient, -925.16, represents the change in intercept for the weekend vs weekday sub-model. What’s its contextual interpretation?"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-4-2-categorical-predictors-visualization",
    "href": "activities/L09-mlr-principles.html#exercise-4-2-categorical-predictors-visualization",
    "title": "Multiple regression principles",
    "section": "Exercise 4: 2 categorical predictors – visualization",
    "text": "Exercise 4: 2 categorical predictors – visualization\nThus far, we’ve explored a couple examples of multiple regression models that have 2 predictors, 1 quantitative and 1 categorical.\nSo what happens when both predictors are categorical?!\nTo this end, let’s model rides by weekend status and season.\nThe below code plots rides vs season.\nModify this code to also include information about weekend.\nHINT: Remember the visualization principle that additional categorical predictors require some sort of grouping mechanism / mechanism that distinguishes between the 2 groups.\n\n# rides vs season\nbikes %&gt;% \n  ggplot(aes(y = rides, x = season)) + \n  geom_boxplot()\n\n# rides vs season AND weekend\nbikes %&gt;%\n  ggplot(aes(y = rides, x = season, ___ = ___)) +\n  geom_boxplot()"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-5-follow-up",
    "href": "activities/L09-mlr-principles.html#exercise-5-follow-up",
    "title": "Multiple regression principles",
    "section": "Exercise 5: follow-up",
    "text": "Exercise 5: follow-up\n\nDescribe (in words) the relationship of ridership with season & weekend status.\nA model of rides by season alone would be represented by only 4 expected outcomes, 1 for each season. Considering this and the plot above, how do you anticipate a model of rides by season and weekend status will be represented?\n\n2 lines, 1 for each weekend status\n8 lines, 1 for each possible combination of season & weekend\n2 expected outcomes, 1 for each weekend status\n8 expected outcomes, 1 for each possible combination of season & weekend"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-6-2-categorical-predictors-build-the-model",
    "href": "activities/L09-mlr-principles.html#exercise-6-2-categorical-predictors-build-the-model",
    "title": "Multiple regression principles",
    "section": "Exercise 6: 2 categorical predictors – build the model",
    "text": "Exercise 6: 2 categorical predictors – build the model\nLet’s build the multiple regression model of rides vs season and weekend:\n\nbike_model_2 &lt;- lm(rides ~ weekend + season, bikes)\ncoef(summary(bike_model_2))\n\nThus the model formula with coefficient estimates filled in is given by:\nE[rides | weekend, season] = 4260.45 - 912.33 weekendTRUE - 116.38 seasonspring + 438.44 seasonsummer - 1719.06 seasonwinter\n\nUse this model to predict the ridership on the following days:\n\n\n# a fall weekday\n4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___\n\n# a winter weekday    \n4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___\n\n# a fall weekend day        \n4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___\n\n# a winter weekend day\n4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___\n\n\nWe only made 4 predictions here. How many possible predictions does this model produce? Is this consistent with your intuition in the previous exercise?"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-7-2-categorical-predictors-interpret-the-model",
    "href": "activities/L09-mlr-principles.html#exercise-7-2-categorical-predictors-interpret-the-model",
    "title": "Multiple regression principles",
    "section": "Exercise 7: 2 categorical predictors – interpret the model",
    "text": "Exercise 7: 2 categorical predictors – interpret the model\nUse your above predictions and visualization to fill in the below interpretations of the model coefficients.\nHint: What is the consequence of plugging in 0 or 1 for the different weekend and season categories?\n\nInterpreting 4260: On average, we expect there to be 4260 riders on (weekdays/weekends) during the (fall/spring/summer/winter).\nInterpreting -912: On average, in any season, we expect there to be 912 (more/fewer) riders on weekends than on ___.\n\nAn alternative interpretation: On average, we expect there to be 912 (more/fewer) riders on weekends than on ___, adjusting for season.\n\nInterpreting -1719: On average, on both weekdays and weekends, we expect there to be 1719 (more/fewer) riders in winter than in ___.\n\nAn alternative interpretation: On average, we expect there to be 1719 (more/fewer) riders in winter than in ___, controlling for weekday status."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-8-2-quantitative-predictors-visualization",
    "href": "activities/L09-mlr-principles.html#exercise-8-2-quantitative-predictors-visualization",
    "title": "Multiple regression principles",
    "section": "Exercise 8: 2 quantitative predictors – visualization",
    "text": "Exercise 8: 2 quantitative predictors – visualization\nNext, consider the relationship between rides and 2 quantitative predictors: windspeed and temp_feel. Check out the plot of this relationship below.\nThis reflect the visualization principle that quantitative variables require some sort of numerical scaling mechanism – rides and windspeed get numerical axes, and temp_feel gets a color scale.\n\nModify the code below to recreate this plot.\n\nbikes %&gt;%\n  ggplot(aes(y = rides, x = windspeed, ___ = ___)) +\n  geom_point()"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-9-follow-up",
    "href": "activities/L09-mlr-principles.html#exercise-9-follow-up",
    "title": "Multiple regression principles",
    "section": "Exercise 9: follow-up",
    "text": "Exercise 9: follow-up\nDescribe (in words) the relationship of ridership with windspeed & temperature."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-10-2-quantitative-predictors-modeling",
    "href": "activities/L09-mlr-principles.html#exercise-10-2-quantitative-predictors-modeling",
    "title": "Multiple regression principles",
    "section": "Exercise 10: 2 quantitative predictors – modeling",
    "text": "Exercise 10: 2 quantitative predictors – modeling\nLet’s build the multiple regression model of rides vs windspeed and temp_feel:\n\nbike_model_3 &lt;- lm(rides ~ windspeed + temp_feel, data = bikes)\ncoef(summary(bike_model_3))\n\nThus the model formula with coefficient estimates filled in is given by,\nE[rides | windspeed, temp_feel] = -24.06 - 36.54 windspeed + 55.52 temp_feel\n\nInterpret the intercept coefficient, -24.06, in context.\nInterpret the windspeed coefficient, -36.54, in context.\nInterpret the temp_feel coefficient, 55.52, in context."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-11-which-is-best",
    "href": "activities/L09-mlr-principles.html#exercise-11-which-is-best",
    "title": "Multiple regression principles",
    "section": "Exercise 11: Which is “best”?",
    "text": "Exercise 11: Which is “best”?\nWe’ve now observed 3 different models of ridership, each having 2 predictors. The R-squared values of these models, along with those of the simple linear regression models with each predictor alone, are summarized below.\n\n\n\nmodel\npredictors\nR-squared\n\n\n\n\nbike_model_1\nwindspeed & weekend\n0.119\n\n\nbike_model_2\nweekend & season\n0.349\n\n\nbike_model_3\nwindspeed & temp_feel\n0.310\n\n\nbike_model_4\nwindspeed\n0.047\n\n\nbike_model_5\ntemp_feel\n0.296\n\n\nbike_model_6\nweekend\n0.074\n\n\nbike_model_7\nseason\n0.279\n\n\n\n\nWhich model does the best job of explaining the variability in ridership from day to day?\nIf you could only pick one predictor, which would it be?\nWhat happens to R-squared when we add a second predictor to our model, and why does this make sense? For example, how does the R-squared for model 1 (with both windspeed and weekend) compare to those of model 4 (only windspeed) and model 6 (only weekend)?\nAre 2 predictors always better than 1? Provide evidence and explain why this makes sense."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-12-principles-of-interpretation",
    "href": "activities/L09-mlr-principles.html#exercise-12-principles-of-interpretation",
    "title": "Multiple regression principles",
    "section": "Exercise 12: Principles of interpretation",
    "text": "Exercise 12: Principles of interpretation\nThese exercises have revealed some principles behind interpreting model coefficients, summarized below.\nReview and confirm that these make sense.\n\nPrinciples of interpretation\nConsider a multiple linear regression model:\n\\[E[Y | X_1, X_2, ..., X_p] = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\]\nWe can interpret the coefficients as follows:\n\n\\(\\beta_0\\) (“beta 0”) is the y-intercept. It describes the average value of \\(Y\\) when \\(X_1, X_2,..., X_k\\) are all 0, ie. when all quantitative predictors are set to 0 and the categorical predictors are set to their reference levels.\n\\(\\beta_i\\) (“beta i”) is the coefficient of \\(X_i\\).\n\nIf \\(X_i\\) is quantitative, \\(\\beta_i\\) describes the average change in \\(Y\\) associated with a 1-unit increase in \\(X_i\\) while at a fixed set of the other \\(X\\).\nIf \\(X_i\\) represents a category of a categorical variable, \\(\\beta_i\\) describes the average difference in \\(Y\\) between this category and the reference category, while at a fixed set of the other \\(X\\)."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-13-practice-1",
    "href": "activities/L09-mlr-principles.html#exercise-13-practice-1",
    "title": "Multiple regression principles",
    "section": "Exercise 13: Practice 1",
    "text": "Exercise 13: Practice 1\nConsider the relationship of rides vs weekend and weather_cat.\n\nConstruct a visualization of this relationship.\n\nConstruct a model of this relationship.\n\nInterpret the first 3 model coefficients."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-14-practice-2",
    "href": "activities/L09-mlr-principles.html#exercise-14-practice-2",
    "title": "Multiple regression principles",
    "section": "Exercise 14: Practice 2",
    "text": "Exercise 14: Practice 2\nConsider the relationship of rides vs temp_feel and humidity.\n\nConstruct a visualization of this relationship.\n\nConstruct a model of this relationship.\n\nInterpret the first 3 model coefficients."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-15-practice-3",
    "href": "activities/L09-mlr-principles.html#exercise-15-practice-3",
    "title": "Multiple regression principles",
    "section": "Exercise 15: Practice 3",
    "text": "Exercise 15: Practice 3\nConsider the relationship of rides vs temp_feel and weather_cat.\n\nConstruct a visualization of this relationship.\n\nConstruct a model of this relationship.\n\nInterpret the first 3 model coefficients."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-16-challenge",
    "href": "activities/L09-mlr-principles.html#exercise-16-challenge",
    "title": "Multiple regression principles",
    "section": "Exercise 16: CHALLENGE",
    "text": "Exercise 16: CHALLENGE\nWe’ve explored models with 2 predictors. What about 3 predictors?! Consider the relationship of rides vs temp_feel, humidity, AND weekend.\n\nConstruct a visualization of this relationship.\n\nConstruct a model of this relationship.\n\nInterpret each model coefficient."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-1-review-visualization-1",
    "href": "activities/L09-mlr-principles.html#exercise-1-review-visualization-1",
    "title": "Multiple regression principles",
    "section": "Exercise 1: Review visualization",
    "text": "Exercise 1: Review visualization\n\nbikes %&gt;% \n  ggplot(aes(y = rides, x = windspeed, color = weekend)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-2-review-model-1",
    "href": "activities/L09-mlr-principles.html#exercise-2-review-model-1",
    "title": "Multiple regression principles",
    "section": "Exercise 2: Review model",
    "text": "Exercise 2: Review model\nweekdays: rides = 4738.38 - 63.97 windspeed\nweekends: rides = 4738.38 - 63.97 windspeed - 925.16 = 3813.22 - 63.97 windspeed"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-3-review-coefficient-interpretation-1",
    "href": "activities/L09-mlr-principles.html#exercise-3-review-coefficient-interpretation-1",
    "title": "Multiple regression principles",
    "section": "Exercise 3: Review coefficient interpretation",
    "text": "Exercise 3: Review coefficient interpretation\n\nWe expect an average of 4738 riders on weekdays with 0 windspeed.\nOn average, we expect a 1mph increase in windspeed to be associated with 64 fewer riders, controlling for weekend status.\nOn average, we expect 925 fewer riders on weekend days than on weekends, controlling for windspeed."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-4-2-categorical-predictors-visualization-1",
    "href": "activities/L09-mlr-principles.html#exercise-4-2-categorical-predictors-visualization-1",
    "title": "Multiple regression principles",
    "section": "Exercise 4: 2 categorical predictors – visualization",
    "text": "Exercise 4: 2 categorical predictors – visualization\n\nbikes %&gt;% \n  ggplot(aes(y = rides, x = season, fill = weekend)) + \n  geom_boxplot()"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-5-follow-up-1",
    "href": "activities/L09-mlr-principles.html#exercise-5-follow-up-1",
    "title": "Multiple regression principles",
    "section": "Exercise 5: follow-up",
    "text": "Exercise 5: follow-up\n\nIn every season, ridership tends to be lower on weekends. Across weekend status, ridership tends to be highest in summer and lowest in winter.\n8 expected outcomes"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-6-2-categorical-predictors-build-the-model-1",
    "href": "activities/L09-mlr-principles.html#exercise-6-2-categorical-predictors-build-the-model-1",
    "title": "Multiple regression principles",
    "section": "Exercise 6: 2 categorical predictors – build the model",
    "text": "Exercise 6: 2 categorical predictors – build the model\n\n\n\n\n#fall weekday:    \n4260.45 - 912.33*0 - 116.38*0 + 438.44*0 - 1719.06*0\n## [1] 4260.45\n\n#winter weekday:\n4260.45 - 912.33*0 - 116.38*0 + 438.44*0 - 1719.06*1\n## [1] 2541.39\n\n#fall weekend:    \n4260.45 - 912.33*1 - 116.38*0 + 438.44*0 - 1719.06*0\n## [1] 3348.12\n\n#winter weekend:\n4260.45 - 912.33*1 - 116.38*0 + 438.44*0 - 1719.06*1\n## [1] 1629.06\n\n\n8: 2 weekend categories * 4 season categories"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-7-2-categorical-predictors-interpret-the-model-1",
    "href": "activities/L09-mlr-principles.html#exercise-7-2-categorical-predictors-interpret-the-model-1",
    "title": "Multiple regression principles",
    "section": "Exercise 7: 2 categorical predictors – interpret the model",
    "text": "Exercise 7: 2 categorical predictors – interpret the model\n\nWe expect there to be, on average, 4260 riders on weekdays during the fall.\nOn average, we expect there to be 912 fewer riders on weekends than on weekends, adjusting for season.\nOn average, we expect there to be 1719 fewer riders in winter than in fall, adjusting for weekday status."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-8-2-quantitative-predictors-visualization-1",
    "href": "activities/L09-mlr-principles.html#exercise-8-2-quantitative-predictors-visualization-1",
    "title": "Multiple regression principles",
    "section": "Exercise 8: 2 quantitative predictors – visualization",
    "text": "Exercise 8: 2 quantitative predictors – visualization\n\nbikes %&gt;% \n  ggplot(aes(y = rides, x = windspeed, color = temp_feel)) + \n  geom_point()"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-9-follow-up-1",
    "href": "activities/L09-mlr-principles.html#exercise-9-follow-up-1",
    "title": "Multiple regression principles",
    "section": "Exercise 9: follow-up",
    "text": "Exercise 9: follow-up\nRidership tends to increase with temperature (no matter the windspeed) and decrease with windspeed (no matter the temperature)."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-10-2-quantitative-predictors-modeling-1",
    "href": "activities/L09-mlr-principles.html#exercise-10-2-quantitative-predictors-modeling-1",
    "title": "Multiple regression principles",
    "section": "Exercise 10: 2 quantitative predictors – modeling",
    "text": "Exercise 10: 2 quantitative predictors – modeling\n\n-24.06 = average ridership on days with 0 windspeed and a 0 degree temperature. (Note: this is a correct interpretation, even though it doesn’t make conceptual sense! The model doesn’t know that ridership can’t be negative!)\nOn average, we expect a 1mph increase in windspeed to be associated with 37 fewer riders on a given day, adjusting for temperature.\nOn average, we expect a 1 degree increase in temperature to be associated with 56 more riders on a given day, adjusting for windspeed."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-11-which-is-best-1",
    "href": "activities/L09-mlr-principles.html#exercise-11-which-is-best-1",
    "title": "Multiple regression principles",
    "section": "Exercise 11: Which is best?",
    "text": "Exercise 11: Which is best?\n\nmodel 2\ntemperature\nR-squared increases (our model is stronger when we include another predictor)\nnope. model 1 (with windspeed and weekend) has a lower R-squared than model 5 (with only temperature)"
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-13-practice-1-1",
    "href": "activities/L09-mlr-principles.html#exercise-13-practice-1-1",
    "title": "Multiple regression principles",
    "section": "Exercise 13: Practice 1",
    "text": "Exercise 13: Practice 1\n\nbikes %&gt;% \n  ggplot(aes(y = rides, x = weekend, fill = weather_cat)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nnew_model_1 &lt;- lm(rides ~ weekend + weather_cat, bikes)\ncoef(summary(new_model_1))\n##                     Estimate Std. Error   t value      Pr(&gt;|t|)\n## (Intercept)        4211.8741   75.54724 55.751529 9.461947e-265\n## weekendTRUE        -982.2106  117.24719 -8.377264  2.786301e-16\n## weather_catcateg2  -608.8640  113.00211 -5.388077  9.628947e-08\n## weather_catcateg3 -2360.2049  319.71640 -7.382183  4.270163e-13\n\n\nThe average ridership on a weekday with nice weather (categ1) is 4212 rides.\nOn days with the same weather, we expect on average 982 rides less on a weekend than on a weekday.\nOn average, we expect ridership to be 609 rides less on dreary days than when the weather is nice, controlling for day of the week."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-14-practice-2-1",
    "href": "activities/L09-mlr-principles.html#exercise-14-practice-2-1",
    "title": "Multiple regression principles",
    "section": "Exercise 14: Practice 2",
    "text": "Exercise 14: Practice 2\n\nbikes %&gt;% \n  ggplot(aes(y = rides, x = temp_feel, color = humidity)) + \n    geom_point()\n\n\n\n\n\n\n\n\nnew_model_2 &lt;- lm(rides ~ temp_feel + humidity, bikes)\ncoef(summary(new_model_2))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept)   315.83704 303.777334  1.039699 2.988249e-01\n## temp_feel      60.43316   3.272315 18.468015 9.451345e-63\n## humidity    -1868.99356 336.963661 -5.546573 4.078901e-08\n\n\nOn average, we expect 316 riders on days that feel like 0 degrees with no humidity.\nOn average, we expect a 1 degree increase in ridership to be associated with a 60 ride increase in ridership, for days with the same humidity.\nOn average, we expect a 0.1 increase in humidity levels to be associated with a decrease in ridership by 187 rides, for days with the same temperature."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-15-practice-3-1",
    "href": "activities/L09-mlr-principles.html#exercise-15-practice-3-1",
    "title": "Multiple regression principles",
    "section": "Exercise 15: Practice 3",
    "text": "Exercise 15: Practice 3\n\nnew_model_3 &lt;- lm(rides ~ temp_feel + weather_cat, bikes)\ncoef(summary(new_model_3))\n##                      Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept)        -288.68840 251.264383 -1.148943 2.509574e-01\n## temp_feel            55.30133   3.215495 17.198387 7.082670e-56\n## weather_catcateg2  -386.42241 100.187725 -3.856984 1.249775e-04\n## weather_catcateg3 -1919.01375 283.022420 -6.780430 2.481218e-11\n\nbikes %&gt;% \n  ggplot(aes(y = rides, x = temp_feel, color = weather_cat)) + \n  geom_point() + \n  geom_line(aes(y = new_model_3$fitted.values), size = 1.5)\n\n\n\n\n\n\n\n\n\nWe expect an average of -289 riders on nice weather days that feel like 0 degrees. (Note: this is a correct interpretation, even though it doesn’t make conceptual sense!)\nOn average, we expect a 1 degree increase in temperature to be associated with a 55 ride increase, for days with the same weather.\nOn average, we expect the number of rides to be 386 rides lower on a dreary weather day compared to a nice weather day, for days with the same temperature."
  },
  {
    "objectID": "activities/L09-mlr-principles.html#exercise-16-challenge-1",
    "href": "activities/L09-mlr-principles.html#exercise-16-challenge-1",
    "title": "Multiple regression principles",
    "section": "Exercise 16: CHALLENGE",
    "text": "Exercise 16: CHALLENGE\n\nbikes %&gt;% \n  ggplot(aes(y = rides, x = temp_feel, color = humidity, size = weekend)) + \n  geom_point()\n\n\n\n\n\n\n\n\nnew_model_4 &lt;- lm(rides ~ temp_feel + humidity + weekend, bikes)\ncoef(summary(new_model_4))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept)   668.60236 292.181063  2.288315 2.240530e-02\n## temp_feel      59.36751   3.119256 19.032585 7.626695e-66\n## humidity    -1906.43437 320.982938 -5.939364 4.433789e-09\n## weekendTRUE  -869.05771 100.057822 -8.685555 2.471050e-17\n\n\nWe expect an average of 669 riders on weekdays that feel like 0 degrees, and have no humidity.\nOn average, we expect a 1 degree increase in temperature to be associated with a 59 ride increase in ridership, for days with the same humidity levels and time of the week.\nOn average, we expect a 0.1 point increase in humidity levels to be associated with a 190.6 ride decrease in ridership, for days with the same temperature and time of the week.\nOn average, we expect ridership to be 869 rides lower on weekends compared to weekdays, controlling for temperature and humidity."
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#learning-goals",
    "href": "activities/L17-logistic-multivariate-evaluation.html#learning-goals",
    "title": "Multiple logistic regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nConstruct multiple logistic regression models in R\nInterpret coefficients in multiple logistic regression models\nUse multiple logistic regression models to make predictions\nEvaluate the quality of logistic regression models by using predicted probability boxplots and by computing and interpreting accuracy, sensitivity, specificity, false positive rate, and false negative rate"
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#readings-and-videos",
    "href": "activities/L17-logistic-multivariate-evaluation.html#readings-and-videos",
    "title": "Multiple logistic regression",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease go through the following reading or videos before class.\n\nReading: Section 4.4 in the STAT 155 Notes\nVideos:\n\nPart 1: Concepts (script)\nPart 2: R Code (script)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-1-graphical-and-numerical-summaries",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-1-graphical-and-numerical-summaries",
    "title": "Multiple logistic regression",
    "section": "Exercise 1: Graphical and numerical summaries",
    "text": "Exercise 1: Graphical and numerical summaries\nOur research question involves three categorical variables: received_callback (1 = yes, 0 = no), gender (f = female, m = male), and race (Black, White). Let’s start by creating a mosaic plot to visually compare inferred binary gender and callbacks:\n\n# create mosaic plot of callback vs gender\nggplot(resume) + \n    geom_mosaic(aes(x = product(gender), fill = received_callback)) +\n    scale_fill_manual(\"Received Callback? \\n(1 = yes, 0 = no)\", values = c(\"lightblue\", \"steelblue\")) + \n    labs(x = \"Inferred Binary Gender (f = female, m = male)\", y = \"Received Callback? (1 = yes, 0 = no)\")\n\nIn this activity, we’re also interested in looking at the relationship between inferred race and callbacks. One way we can add a third variable to a plot is to use the facet_grid function, particularly when that third variable is categorical. Let’s try that now:\n\n# create mosaic plot of callback vs gender and race\nggplot(resume) + \n    geom_mosaic(aes(x = product(gender), fill = received_callback)) +\n    facet_grid(. ~ race) +\n    scale_fill_manual(\"Received Callback? \\n(1 = yes, 0 = no)\", values = c(\"lightblue\", \"steelblue\")) + \n    labs(x = \"Inferred Binary Gender (f = female, m = male)\", y = \"Received Callback? (1 = yes, 0 = no)\")\n\nHere’s another way of looking at the relationship between these three variables, switching the placement of gender and race in the mosaic plot:\n\n# create mosaic plot of callback vs gender and race\nggplot(resume) + \n    geom_mosaic(aes(x = product(received_callback, race), fill = received_callback)) +\n    facet_grid(. ~ gender) +\n    scale_fill_manual(\"Received Callback? \\n(1 = yes, 0 = no)\", values = c(\"lightblue\", \"steelblue\")) + \n    labs(x = \"Inferred Race\", y = \"Received Callback? (1 = yes, 0 = no)\")\n\nWhen we are comparing three categorical variables, a useful numerical summary is to calculate relative frequencies/proportions of cases falling into each category of the outcome variable, conditional on which categories of the explanatory variables they fall into. Run this code chunk to calculate the conditional proportion of resumes that did nor did not receive a callback, given the inferred gender and race of the applicant:\n\n# corresponding numerical summaries\nresume %&gt;%\n    group_by(race, gender) %&gt;%\n    count(received_callback) %&gt;%\n    group_by(race, gender) %&gt;%\n    mutate(condprop = n/sum(n))\n\nWrite a short description that summarizes the information you gain from these visualizations and numerical summaries. Write this summary using good sentences that tell a story and do not resemble a checklist. Don’t forget to consider the context of the data, and make sure that your summary addresses our research question: does an applicant’s inferred gender or race have an effect on the chance that they receive a callback?"
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-2-logistic-regression-modeling",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-2-logistic-regression-modeling",
    "title": "Multiple logistic regression",
    "section": "Exercise 2: Logistic regression modeling",
    "text": "Exercise 2: Logistic regression modeling\nNext, we’ll fit a logistic regression model to these data, modeling the log odds of receiving a callback as a function of the applicant’s inferred gender and race:\n\\[\\log(Odds[ReceivedCallback = 1 \\mid gender, race]) = \\beta_0 + \\beta_1 genderm + \\beta_2 racewhite\\]\nFill in the blanks in the code below to fit this logistic regression model.\n\n# fit logistic model and save it as object called \"mod1\"\nmod1 &lt;- glm(received_callback ~ gender + race, data = ___, family = ___)\n\nThen, run the code chunk below to get the coefficient estimates and exponentiated estimates, presented in a nicely formatted table:\n\n# print out tidy summary of mod, focusing on estimates & exponentiated estimates\ntidy(mod1) %&gt;%\n    select(term, estimate) %&gt;%\n    mutate(estimate_exp = exp(estimate))\n\nWrite an interpretation of each of the exponentiated coefficients in your logistic regression model."
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-3-interaction-terms",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-3-interaction-terms",
    "title": "Multiple logistic regression",
    "section": "Exercise 3: Interaction terms",
    "text": "Exercise 3: Interaction terms\n\nDo you think it would make sense to add an interaction term (between gender and race) to our logistic regression model? Why/why not?\nLet’s try adding an interaction between gender and race. Update the code below to fit this new interaction model.\n\n\n# fit logistic model and save it as object called \"mod2\"\nmod2 &lt;- glm(received_callback ~ ___, data = resume, family = ___)\n\nThen, run the code chunk below to get the coefficient estimates and exponentiated estimates for this interaction model, presented in a nicely formatted table:\n\n# print out tidy summary of mod, focusing on estimates & exponentiated estimates\ntidy(mod2) %&gt;%\n    select(term, estimate) %&gt;%\n    mutate(estimate_exp = exp(estimate))\n\n\n(CHALLENGE) Write out the logistic regression model formula separately for males and for females. Based on this how would we interpret the exponentiated coefficients in this model?"
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-4-prediction",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-4-prediction",
    "title": "Multiple logistic regression",
    "section": "Exercise 4: Prediction",
    "text": "Exercise 4: Prediction\nWe can use our models to predict whether or not a resume will receive a call back based on the inferred gender and race of the applicant. Run the code below to use the predict() function to predict the probability of getting a call back for four job applicants: a person inferred to be a black female, a person inferred to be black male, a person inferred to be a white female, and a person inferred to be a white male.\n\n# set up data frame with people we want to predict for\npredict_data &lt;- data.frame(\n    gender = c(\"f\", \"m\", \"f\", \"m\"),\n    race = c(\"black\", \"black\", \"white\", \"white\")\n)\nprint(predict_data)\n\n# prediction based on model without interaction\nmod1 %&gt;%\n    predict(newdata = predict_data, type = \"response\")\n\n# prediction based on model with interaction\nmod2 %&gt;%\n    predict(newdata = predict_data, type = \"response\")\n\nReport and compare the predictions we get from predict(). Do they make sense to you based on your understanding of the data? Combine insights from visualizations and modeling to write a few sentences summarizing findings for our research question: does an applicant’s inferred gender and race have an effect on the chance that they receive a callback after submitting their resume for an open job posting?"
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-5-evaluating-logistic-models-with-plots",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-5-evaluating-logistic-models-with-plots",
    "title": "Multiple logistic regression",
    "section": "Exercise 5: Evaluating logistic models with plots",
    "text": "Exercise 5: Evaluating logistic models with plots\nWe’ll fit one more model that adds on to the interaction model to also include years of college, years of work experience, and resume quality. The augment() code takes our fitted models and stores the predicted probabilities in a variable called .fitted. Then we use boxplots to show the predicted probabilities of receiving a callback in those who actually did and did not receive a callback.\n\nmod3 &lt;- glm(received_callback ~ gender*race + years_college + years_experience + resume_quality, data = resume, family = \"binomial\")\n\nmod1_output &lt;- augment(mod1, type.predict = \"response\") # Store predicted probabilities in a variable called .fitted\nmod2_output &lt;- augment(mod2, type.predict = \"response\")\nmod3_output &lt;- augment(mod3, type.predict = \"response\")\n\nggplot(mod1_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot()\nggplot(mod2_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot()\nggplot(mod3_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot()\n\n\nSummarize what you learn about the ability of the 3 models to differentiate those who actually did and did not receive a callback. What model seems best, and why?\nIf you had to draw a horizontal line across each of the boxplots that vertically separates the left and right boxplots well, where would you place them?"
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-6-evaluating-logistic-models-with-evaluation-metrics",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-6-evaluating-logistic-models-with-evaluation-metrics",
    "title": "Multiple logistic regression",
    "section": "Exercise 6: Evaluating logistic models with evaluation metrics",
    "text": "Exercise 6: Evaluating logistic models with evaluation metrics\nSometimes we may need to go beyond the predicted probabilities from our model and try to classify individuals into one of the two binary outcomes (received or did not receive a callback). How high of a predicted probability would we need from our model in order to be convinced that the person actually got a callback? This is the idea behind the horizontal lines that we drew in the previous exercise.\nLet’s explore using a probability threshold of 0.08 (8%) to make a binary prediction for each case:\n\nIf a model’s predicted probability of getting a callback is greater than or equal to 8.5%, we’ll predict they got a callback.\nIf the predicted probability is below 8%, we’ll predict they didn’t get a callback.\n\nWe can visualize this threshold on our predicted probability boxplots:\n\nggplot(mod1_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot() +\n    geom_hline(yintercept = 0.08, color = \"red\")\nggplot(mod2_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot() +\n    geom_hline(yintercept = 0.08, color = \"red\")\nggplot(mod3_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot() +\n    geom_hline(yintercept = 0.08, color = \"red\")\n\nNext, we can use our threshold to classify each person in our dataset based on their predicted probability of getting a callback: we’ll predict that everyone with a predicted probability higher than our threshold got a callback, and otherwise they did not. Then, we’ll compare our model’s prediction to the true outcome (whether or not they actually did get a callback).\n\n# get binary predictions for mod1 and compare to truth\nthreshold &lt;- 0.08\nmod1_output %&gt;%\n    mutate(predictCallback = .fitted &gt;= threshold) %&gt;% ## predict callback if probability greater than or equal to threshold\n    count(received_callback, predictCallback) ## compare actual and predicted callbacks\n\nmod2_output %&gt;%\n    mutate(predictCallback = .fitted &gt;= threshold) %&gt;%\n    count(received_callback, predictCallback)\n\nmod3_output %&gt;%\n    mutate(predictCallback = .fitted &gt;= threshold) %&gt;%\n    count(received_callback, predictCallback)\n\nWe can use the count() output to fill create contingency tables of the results. (These tables are also called confusion matrices.)\n\nFill in the confusion matrix for Model 3.\n\n\nModels 1 and 2: (Both models result in the same confusion matrix.)\n\n\n\n\n\nPredict callback\nPredict no callback\nTotal\n\n\n\n\nActually got callback\n235\n157\n392\n\n\nActually did not\n2200\n2278\n4478\n\n\nTotal\n2435\n2435\n4870\n\n\n\n\nModel 3:\n\n\n\n\n\nPredict callback\nPredict no callback\nTotal\n\n\n\n\nActually got callback\n____\n____\n____\n\n\nActually did not\n____\n____\n____\n\n\nTotal\n____\n____\n____\n\n\n\n\nNow compute the following evaluation metrics for the models:\n\nModels 1 and 2:\n\nAccuracy: P(Predict Y Correctly)\nSensitivity: P(Predict Y = 1 | Actual Y = 1)\nSpecificity: P(Predict Y = 0 | Actual Y = 0)\nFalse negative rate: P(Predict Y = 0 | Actual Y = 1)\nFalse positive rate: P(Predict Y = 1 | Actual Y = 0)\n\nModel 3:\n\nAccuracy: P(Predict Y Correctly)\nSensitivity: P(Predict Y = 1 | Actual Y = 1)\nSpecificity: P(Predict Y = 0 | Actual Y = 0)\nFalse negative rate: P(Predict Y = 0 | Actual Y = 1)\nFalse positive rate: P(Predict Y = 1 | Actual Y = 0)\n\n\nImagine that we are a career center on a college campus and we want to use this model to help students that are looking for jobs. Consider the consequences of incorrectly predicting whether or not an individual will get a callback. What are the consequences of a false negative? What about a false positive? Which one is worse?"
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#reflection",
    "href": "activities/L17-logistic-multivariate-evaluation.html#reflection",
    "title": "Multiple logistic regression",
    "section": "Reflection",
    "text": "Reflection\nWhat are some similarities and differences between how we interpret and evaluate linear and logistic regression models?\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-1-graphical-and-numerical-summaries-1",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-1-graphical-and-numerical-summaries-1",
    "title": "Multiple logistic regression",
    "section": "Exercise 1: Graphical and numerical summaries",
    "text": "Exercise 1: Graphical and numerical summaries\n\nggplot(resume) + \n    geom_mosaic(aes(x = product(gender), fill = received_callback)) +\n    scale_fill_manual(\"Received Callback? \\n(1 = yes, 0 = no)\", values = c(\"lightblue\", \"steelblue\")) + \n    labs(x = \"Inferred Binary Gender (f = female, m = male)\", y = \"Received Callback? (1 = yes, 0 = no)\")\n\n\n\n\n\n\n\n\nggplot(resume) + \n    geom_mosaic(aes(x = product(gender), fill = received_callback)) +\n    facet_grid(. ~ race) +\n    scale_fill_manual(\"Received Callback? \\n(1 = yes, 0 = no)\", values = c(\"lightblue\", \"steelblue\")) + \n    labs(x = \"Inferred Binary Gender (f = female, m = male)\", y = \"Received Callback? (1 = yes, 0 = no)\")\n\n\n\n\n\n\n\n\nggplot(resume) + \n    geom_mosaic(aes(x = product(received_callback, race), fill = received_callback)) +\n    facet_grid(. ~ gender) +\n    scale_fill_manual(\"Received Callback? \\n(1 = yes, 0 = no)\", values = c(\"lightblue\", \"steelblue\")) + \n    labs(x = \"Inferred Race\", y = \"Received Callback? (1 = yes, 0 = no)\")\n\n\n\n\n\n\n\n\nresume %&gt;%\n    group_by(race, gender) %&gt;%\n    count(received_callback) %&gt;%\n    group_by(race, gender) %&gt;%\n    mutate(condprop = n/sum(n))\n## # A tibble: 8 × 5\n## # Groups:   race, gender [4]\n##   race  gender received_callback     n condprop\n##   &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;\n## 1 black f                      0  1761   0.934 \n## 2 black f                      1   125   0.0663\n## 3 black m                      0   517   0.942 \n## 4 black m                      1    32   0.0583\n## 5 white f                      0  1676   0.901 \n## 6 white f                      1   184   0.0989\n## 7 white m                      0   524   0.911 \n## 8 white m                      1    51   0.0887\n\nOverall, a small proportion of applicants received a callback, with those who were inferred to be black males being least likely to get a callback (5.8%) and those inferred to be white females being most likely to get a callback (9.9%). In general, job applicants whose race was inferred to be white were more likely to receive a callback than those whose race was inferred to be black, regardless of their inferred gender. On the other hand, inferred gender does not seem to have as much of an effect on the chance of receiving a callback, with perhaps just a slight advantage for females."
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-2-logistic-regression-modeling-1",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-2-logistic-regression-modeling-1",
    "title": "Multiple logistic regression",
    "section": "Exercise 2: Logistic regression modeling",
    "text": "Exercise 2: Logistic regression modeling\n\nmod1 &lt;- glm(received_callback ~ gender + race, data = resume, family = \"binomial\")\n\ntidy(mod1) %&gt;%\n    select(term, estimate) %&gt;%\n    mutate(estimate_exp = exp(estimate))\n## # A tibble: 3 × 3\n##   term        estimate estimate_exp\n##   &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n## 1 (Intercept)   -2.65        0.0708\n## 2 genderm       -0.127       0.881 \n## 3 racewhite      0.440       1.55\n\n\nexp(Intercept): We estimate the odds of getting a callback among those inferred to be black females is only 0.07, meaning that the chance of getting a callback is 0.07 times as large as the chance of not getting a callback (or, inversely, the chance of not getting a callback is 1/0.07 = 14.29) times greater than the chance of getting a callback).\nexp(genderm): Comparing applicants of the same inferred race, we estimate that those inferred to be male have an odds of getting a callback that is 0.88 times as high as (or, equivalently, 12% lower than) the odds of getting a callback for those inferred to be female.\nexp(racewhite): We estimate that the odds of getting a callback are 1.55 times higher for applicants whose race was inferred to be white as compared to those who were inferred to be black but the same gender."
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-3-interaction-terms-1",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-3-interaction-terms-1",
    "title": "Multiple logistic regression",
    "section": "Exercise 3: Interaction terms",
    "text": "Exercise 3: Interaction terms\n\nIncluding an interaction term in our model would allow us to investigate whether the effect of race on getting a callback depends on your gender or, vice versa, if the effect of gender on getting a callback depends on a race. In other words, we could ask questions like: is there more of a discrepancy in callbacks between black and white males than there is among black and white females? Is there more of a discrepancy in callbacks between male and female blacks than there is among male and female whites?\nLet’s try adding an interaction between gender and race. Update the code below to fit this new interaction model.\n\n\nmod2 &lt;- glm(received_callback ~ gender * race, data = resume, family = \"binomial\")\n\ntidy(mod2) %&gt;%\n    select(term, estimate) %&gt;%\n    mutate(estimate_exp = exp(estimate))\n## # A tibble: 4 × 3\n##   term              estimate estimate_exp\n##   &lt;chr&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n## 1 (Intercept)        -2.65         0.0710\n## 2 genderm            -0.137        0.872 \n## 3 racewhite           0.436        1.55  \n## 4 genderm:racewhite   0.0165       1.02\n\n\nOverall logistic regression model formula in terms of beta coefficients:\n\n\\[\\log(Odds[ReceivedCallback = 1 \\mid gender, race]) = \\beta_0 + \\beta_1 genderm + \\beta_2 racewhite + \\beta_3 genderm \\times racewhite\\]\nThe model formula for males:\n\\[\\log(Odds[ReceivedCallback = 1 \\mid gender=m, race]) = (\\beta_0 + \\beta_1) + (\\beta_2 + \\beta_3) racewhite\\]\nThe model formula for females:\n\\[\\log(Odds[ReceivedCallback = 1 \\mid gender=f, race]) = \\beta_0 + \\beta_2 racewhite\\] Focusing first on the female model formula, we can see that this is a simple logistic regression model.\n\nexp(beta0): Odds of callback for black females\nexp(beta2): This is the odds ratio for race among females. That is, white females have exp(beta2) times the odds of callback than black females.\n\nThen focusing on the male model formula, we can see that this is also a simple logistic regression model.\n\nexp(beta0+beta1): Odds of callback for black males\nexp(beta2+beta3): This is the odds ratio for race among males. White males have exp(beta2+beta3) times the odds of callback than black males.\n\nComparing the male to the female model formula, we have:\n\nexp(beta1): Black males have exp(beta1) times the odds of a callback than black females\nexp(beta3): This tells us how many times higher the odds ratio for race is in males as compared to females."
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-4-prediction-1",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-4-prediction-1",
    "title": "Multiple logistic regression",
    "section": "Exercise 4: Prediction",
    "text": "Exercise 4: Prediction\n\n# set up data frame with people we want to predict for\npredict_data &lt;- data.frame(\n    gender = c(\"f\", \"m\", \"f\", \"m\"),\n    race = c(\"black\", \"black\", \"white\", \"white\")\n)\nprint(predict_data)\n##   gender  race\n## 1      f black\n## 2      m black\n## 3      f white\n## 4      m white\n\n# prediction based on model without interaction\nmod1 %&gt;%\n    predict(newdata = predict_data, type = \"response\")\n##          1          2          3          4 \n## 0.06615111 0.05872314 0.09905323 0.08828000\n\n# prediction based on model with interaction\nmod2 %&gt;%\n    predict(newdata = predict_data, type = \"response\")\n##          1          2          3          4 \n## 0.06627784 0.05828780 0.09892473 0.08869565\n\nThe predicted probabilities from our logistic regression models show that we estimate those inferred to be black males have the lowest chance of receiving a callback (5.87% based on mod1 and 5.83% based on mod2), followed by black females (6.62% and 6.63%), white males (8.83% and 8.87%), and then white females (9.91% and 9.89%). This matches the trend we observed that those inferred to be white have a greater chance of getting a callback, regardless of gender, and that those who are inferred to be female have a slightly higher chance of getting a callback than those inferred to be male."
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-5-evaluating-logistic-models-with-plots-1",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-5-evaluating-logistic-models-with-plots-1",
    "title": "Multiple logistic regression",
    "section": "Exercise 5: Evaluating logistic models with plots",
    "text": "Exercise 5: Evaluating logistic models with plots\n\nmod3 &lt;- glm(received_callback ~ gender*race + years_college + years_experience + resume_quality, data = resume, family = \"binomial\")\n\nmod1_output &lt;- augment(mod1, type.predict = \"response\")\nmod2_output &lt;- augment(mod2, type.predict = \"response\")\nmod3_output &lt;- augment(mod3, type.predict = \"response\")\n\nggplot(mod1_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot()\n\n\n\n\n\n\n\nggplot(mod2_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot()\n\n\n\n\n\n\n\nggplot(mod3_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\nAll 3 models show that those who actually received a callback had higher predicted probabilities of a callback. Models 1 and 2 are very similar–although predicted probabilites of callback are high for those who did actually receive a callback, there is substantial overlap in the boxplots. There is more separation between the boxplots in the third model, perhaps model 3 is best in terms of accuracy.\nWe would want to place the vertical lines such that as much of the left boxplot was below the line (low predicted probabilities for those with Y = 0) and as much of the right boxplot was above the line (high predicted probabilities for those with Y = 1)."
  },
  {
    "objectID": "activities/L17-logistic-multivariate-evaluation.html#exercise-6-evaluating-logistic-models-with-evaluation-metrics-1",
    "href": "activities/L17-logistic-multivariate-evaluation.html#exercise-6-evaluating-logistic-models-with-evaluation-metrics-1",
    "title": "Multiple logistic regression",
    "section": "Exercise 6: Evaluating logistic models with evaluation metrics",
    "text": "Exercise 6: Evaluating logistic models with evaluation metrics\n\nggplot(mod1_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot() +\n    geom_hline(yintercept = 0.08, color = \"red\")\n\n\n\n\n\n\n\nggplot(mod2_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot() +\n    geom_hline(yintercept = 0.08, color = \"red\")\n\n\n\n\n\n\n\nggplot(mod3_output, aes(x = factor(received_callback), y = .fitted)) +\n    geom_boxplot() +\n    geom_hline(yintercept = 0.08, color = \"red\")\n\n\n\n\n\n\n\n\nNext, we can use our threshold to classify each person in our dataset based on their predicted probability of getting a callback: we’ll predict that everyone with a predicted probability higher than our threshold got a callback, and otherwise they did not. Then, we’ll compare our model’s prediction to the true outcome (whether or not they actually did get a callback).\n\nthreshold &lt;- 0.08\nmod1_output %&gt;%\n    mutate(predictCallback = .fitted &gt;= threshold) %&gt;% \n    count(received_callback, predictCallback) \n## # A tibble: 4 × 3\n##   received_callback predictCallback     n\n##               &lt;dbl&gt; &lt;lgl&gt;           &lt;int&gt;\n## 1                 0 FALSE            2278\n## 2                 0 TRUE             2200\n## 3                 1 FALSE             157\n## 4                 1 TRUE              235\n\nmod2_output %&gt;%\n    mutate(predictCallback = .fitted &gt;= threshold) %&gt;%\n    count(received_callback, predictCallback)\n## # A tibble: 4 × 3\n##   received_callback predictCallback     n\n##               &lt;dbl&gt; &lt;lgl&gt;           &lt;int&gt;\n## 1                 0 FALSE            2278\n## 2                 0 TRUE             2200\n## 3                 1 FALSE             157\n## 4                 1 TRUE              235\n\nmod3_output %&gt;%\n    mutate(predictCallback = .fitted &gt;= threshold) %&gt;%\n    count(received_callback, predictCallback)\n## # A tibble: 4 × 3\n##   received_callback predictCallback     n\n##               &lt;dbl&gt; &lt;lgl&gt;           &lt;int&gt;\n## 1                 0 FALSE            2465\n## 2                 0 TRUE             2013\n## 3                 1 FALSE             159\n## 4                 1 TRUE              233\n\n\n\n\n\nModels 1 and 2: (Both models result in the same confusion matrix.)\n\n\n\n\n\nPredict callback\nPredict no callback\nTotal\n\n\n\n\nActually got callback\n235\n157\n392\n\n\nActually did not\n2200\n2278\n4478\n\n\nTotal\n2435\n2435\n4870\n\n\n\n\nModel 3:\n\n\n\n\n\nPredict callback\nPredict no callback\nTotal\n\n\n\n\nActually got callback\n233\n159\n392\n\n\nActually did not\n2013\n2465\n4478\n\n\nTotal\n2246\n2624\n4870\n\n\n\n\nNow compute the following evaluation metrics for the models:\n\n\nModels 1 and 2:\n\nAccuracy: P(Predict Y Correctly) = (235 + 2278)/(235 + 157 + 2200 + 2278) = 0.5160164\nSensitivity: P(Predict Y = 1 | Actual Y = 1) = 235/(235 + 157) = 0.5994898\nSpecificity: P(Predict Y = 0 | Actual Y = 0) = 2278/(2200 + 2278) = 0.5087092\nFalse negative rate: P(Predict Y = 0 | Actual Y = 1) = 157/(235 + 157) = 0.4005102 (notice that this is equal to 1 - Sensitivity)\nFalse positive rate: P(Predict Y = 1 | Actual Y = 0) = 2200/(2200 + 2278) = 0.4912908 (notice that this is equal to 1 - Specificity)\n\n\n\nModel 3:\n\nAccuracy: P(Predict Y Correctly) = (233 + 2465)/(233 + 159 + 2013 + 2465) = 0.5540041\nSensitivity: P(Predict Y = 1 | Actual Y = 1) = 233/(233 + 159) = 0.5943878\nSpecificity: P(Predict Y = 0 | Actual Y = 0) = 2465/(2013 + 2465) = 0.550469\nFalse negative rate: P(Predict Y = 0 | Actual Y = 1) = 159/(233 + 159) = 0.4056122 (notice that this is equal to 1 - Sensitivity)\nFalse positive rate: P(Predict Y = 1 | Actual Y = 0) = 2013/(2013 + 2465) = 0.449531 (notice that this is equal to 1 - Specificity)\n\n\n\nImagine that we are a career center on a college campus and we want to use this model to help students that are looking for jobs. Consider the consequences of incorrectly predicting whether or not an individual will get a callback. What are the consequences of a false negative? What about a false positive? Which one is worse?\n\nFalse Negatives (predicting no callback, but actually got callback): this would be a lost opportunity if a student decided not to submit their resume, thinking they wouldn’t get a callback, when actually they would have.\nFalse Positives (predicting callback, but actually didn’t get callback): this would be a disappointment for the student, thinking they were going to get a callback but they ended up not getting one."
  },
  {
    "objectID": "activities/L22-hypothesis-testing-discovery.html#learning-goals",
    "href": "activities/L22-hypothesis-testing-discovery.html#learning-goals",
    "title": "Hypothesis testing: discovery",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nUnderstand how standard errors and confidence intervals enable us to make statistical inferences\nArticulate how we can formalize a research question as a testable, statistical hypothesis"
  },
  {
    "objectID": "activities/L22-hypothesis-testing-discovery.html#readings-and-videos",
    "href": "activities/L22-hypothesis-testing-discovery.html#readings-and-videos",
    "title": "Hypothesis testing: discovery",
    "section": "Readings and videos",
    "text": "Readings and videos\nThis is a discovery activity, so no assigned readings/videos today."
  },
  {
    "objectID": "activities/L22-hypothesis-testing-discovery.html#exercise-1",
    "href": "activities/L22-hypothesis-testing-discovery.html#exercise-1",
    "title": "Hypothesis testing: discovery",
    "section": "Exercise 1",
    "text": "Exercise 1\nResearch question: Is there evidence that the mercury concentration in fish (Concen) differs according to the River they were sampled from?\n\npart a: fit the model\nFit a simple linear regression model that would address our research question\n\nmod_fish &lt;- ___\nsummary(mod_fish)\n\nInterpret the intercept from this model.\n\nResponse\n\n\n\npart b: construct a CI\nUsing the 68-95-99.7 rule, construct an approximate 95% confidence interval for the intercept term, and provide an appropriate interpretation.\n\nResponse\n\nCompare your CI to an exact 95% confidence interval for the model coefficients:\n\nconfint(mod_fish, level=0.95)\n\n\n\npart c: what can we conclude from multiple samples?\nSuppose we take 200 different samples of fish from the Lumber River. Based on these results, in how many of those samples would you expect to observe mean mercury concentration greater than 1.25ppm?\n\nResponse\n\n\n\npart d: intuition for constructing & interpreting test statistics\nSuppose previous environmental studies have found little evidence of mercury pollution in other rivers in the area, so perhaps our “default” assumption is that fish from the Lumber river should have an expected mercury concentration of 0ppm. How many standard errors is our sample estimate (1.078ppm) away from this expectation? What are three possible conclusions?\n\nResponse\n\n\n\npart e: do individual observations contradict our conclusions?\nNow suppose we sample a single fish from the Lumber River and find it has a mercury concentration of 2.5ppm. Are you surprised by this result? Why or why not? (Hint: create a code chunk that calculates the mean, standard deviation, and maximum of the Concen variable in each river in our original sample)\n\nResponse"
  },
  {
    "objectID": "activities/L22-hypothesis-testing-discovery.html#exercise-2",
    "href": "activities/L22-hypothesis-testing-discovery.html#exercise-2",
    "title": "Hypothesis testing: discovery",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet’s look at the model summary output again:\n\nsummary(mod_fish)\n\n\npart a: interpret model coefficient\nNow, let’s interpret the RiverWacamaw coefficient. Based only on the coefficient (don’t think about the standard error yet), what can we say about the difference in mercury concentration among fish in the two rivers?\n\nResponse\n\n\n\npart b: construct a CI\nUsing the 68-95-99.7 rule, construct an approximate 95% confidence interval for the RiverWacamaw coefficient, and provide an appropriate interpretation.\n\nResponse\n\n\n\npart c: interpreting the CI\nDo you believe it plausible that the mean mercury concentration of the fish population in the Wacamaw River is approximately the same as that of the fish population in the Lumber River? How would you confirm this? What assumptions are you making?\n\nResponse\n\n\n\npart d: effect of sample size on our conclusions\nSuppose we sample 10 times as many fish from the Wacamaw River, and get a similar coefficient estimate (0.2). Thinking back to the Central Limit Theorem, what should happen to the standard error of the RiverWacamaw coefficient? How small of a standard error would we need to more conclusively say that there is an actual difference in mean mercury concentrations of the Lumber River and Wacamaw River fish populations?\n\nResponse\n\n\n\npart e: reconciling parameter estimates and uncertainty\nSuppose the true population coefficient for the RiverWacamawparameter is 0.02 (i.e. the average mercury concentration is 0.02ppm higher for the Wacamaw River fish population compared to that of the Lumber River). Is this meaningful?\n\nResponse\n\n\n\npart f (CHALLENGE)\nUsing the model summary output, report the mean mercury concentration for our sample of fish from the Wacamaw River:\n\nsummary(mod_fish)\n\n\nResponse:\n\nWhich of the following values do you think is the standard error of the sample mean for the Wacamaw River?\n\n0.11712\n0.08866\n0.11712 + 0.08866 = 0.20578\n0.11712 - 0.08866 = 0.02846\nsomething else\n\nTo answer this question, look at the code chunk below, which fits the same model, but uses the Wacamaw River as our reference category instead of the Lumber River:\n\nmod_fish2 &lt;- lm(Concen ~ River, data=fish %&gt;% mutate(River=ifelse(River == \"Wacamaw\", paste0(\"_\", River), River)))\nsummary(mod_fish2)\n\nCompare this to the output for mod_fish. What do you notice about the standard errors of the intercepts (i.e., the standard errors of the means for each river) compared to the standard errors of the RiverWacamaw and RiverLumber coefficients (i.e., the standard errors of the differences between the means)?\n\nResponse:"
  },
  {
    "objectID": "activities/L22-hypothesis-testing-discovery.html#reflection",
    "href": "activities/L22-hypothesis-testing-discovery.html#reflection",
    "title": "Hypothesis testing: discovery",
    "section": "Reflection",
    "text": "Reflection\nBased on this activity and the inference tools you’ve learned about so far (sampling distributions, standard errors, confidence intervals), can you think of and describe a way that you can quantify evidence “for” or “against” a coefficient being equal to some particular value? (for example, we have evidence that the average mercury concentration in Lumber River fish is ~1.08ppm, and the standard error of this estimate suggests that observing a fish with 0ppm is very unlikely. How can we quantify that evidence?)\n\nResponse:"
  },
  {
    "objectID": "activities/L22-hypothesis-testing-discovery.html#exercise-1-1",
    "href": "activities/L22-hypothesis-testing-discovery.html#exercise-1-1",
    "title": "Hypothesis testing: discovery",
    "section": "Exercise 1",
    "text": "Exercise 1\nResearch question: Is there evidence that the mercury concentration in fish (Concen) differs according to the River they were sampled from?\n\npart a: fit the model\nFit a simple linear regression model that would address our research question\n\nmod_fish &lt;- lm(Concen ~ River, data=fish)\nsummary(mod_fish)\n## \n## Call:\n## lm(formula = Concen ~ River, data = fish)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1664 -0.5681 -0.1764  0.4219  2.4219 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   1.07808    0.08866  12.160   &lt;2e-16 ***\n## RiverWacamaw  0.19835    0.11712   1.694   0.0922 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7575 on 169 degrees of freedom\n## Multiple R-squared:  0.01669,    Adjusted R-squared:  0.01087 \n## F-statistic: 2.868 on 1 and 169 DF,  p-value: 0.09218\n\nInterpret the intercept from this model.\n\nOur model estimates an average mercury concentration of 1.078ppm among fish in the Lumber River.\n\n\n\npart b: construct a CI\nUsing the 68-95-99.7 rule, construct an approximate 95% confidence interval for the intercept term, and provide an appropriate interpretation.\n\n1.078 +/- 2*0.089 –&gt; [0.90, 1.256]\n\n\nPreferred interpretation: It is plausible that the true mean mercury concentration among fish in the Lumber River is between 0.90ppm and 1.25ppm.\n\n\n(technical addendum to this interpretation): …specifically, we expect that if we take many different samples and obtain a set of corresponding parameter estimates and confidence intervals, we expect that 95% of the resulting intervals will contain the true mean mercury concentration of the entire Lumber River fish population. We hope that our interval is one of the lucky 95% and not one of the unlucky 5% that don’t contain the true population parameter.\n\n\nNot as preferred interpretation: We are 95% confident that the mean mercury concentration among fish in the Lumber River is between 0.90ppm and 1.25ppm.\n\nCompare your CI to an exact 95% confidence interval for the model coefficients:\n\nconfint(mod_fish, level=0.95)\n##                    2.5 %    97.5 %\n## (Intercept)   0.90305825 1.2531061\n## RiverWacamaw -0.03285077 0.4295435\n\n\n\npart c: what can we conclude from multiple samples?\nSuppose we take 200 different samples of fish from the Lumber River. In how many of those samples would you expect to observe an estimated mean mercury concentration greater than 1.25ppm?\n\nWe don’t/can’t actually know! This depends on the true population parameter and the accuracy of our sampling distribution.\n\n\nWhat we can say is that if our sampling distribution model is accurate, then we should expect that about 10 out of 200 samples (5% of them) will produce confidence intervals that don’t contain the population parameter. We should expect that half of these–so 5 samples–are overestimates and the other half are underestimates.\n\n\n\npart d: intuition for constructing & interpreting test statistics\nSuppose previous environmental studies have found little evidence of mercury pollution in other rivers in the area, so perhaps our “default” assumption is that fish from the Lumber river should have an expected mercury concentration of 0ppm. How many standard errors is our sample estimate (1.078ppm) away from this expectation? What are three possible conclusions?\n\nIf we assume that 0ppm is the “true” mercury concentration, then our estimate of Beta_0 = 1.078ppm with a standard error of 0.08866 means that our estimate is (1.07808-0)/0.08866 = 12.16 standard errors away from what we should expect.\n\n\nPossible conclusions:\n\n\n\nOur working assumption that 0ppm should be the “true” mercury concentration in the Lumber river fish population was wrong! The confidence interval we constructed above suggests that a true value of 0ppm is extremely implausible.\n\n\n\n\nPerhaps ~0ppm is actually the true average mercury concentration in the population, we just got extremely, outrageously unlucky with our sample.\n\n\n\n\nPerhaps there was a measurement/data entry error, and the units are actually parts per billion, not million.\n\n\n\n\npart e: do individual observations contradict our conclusions?\nNow suppose we sample a single fish from the Lumber River and find it has a mercury concentration of 2.5ppm. Are you surprised by this result? Why or why not? (Hint: create a code chunk that calculates the mean, standard deviation, and maximum of the Concen variable in each river in our original sample)\n\nfish %&gt;% \n  group_by(River) %&gt;% \n  summarise(mean=mean(Concen), \n            sd=sd(Concen), \n            max=max(Concen))\n## # A tibble: 2 × 4\n##   River    mean    sd   max\n##   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 Lumber   1.08 0.649   3.5\n## 2 Wacamaw  1.28 0.829   3.6\n\n\nObserving a single fish with a mercury concentration of 2.5ppm is actually not that surprising! 2.5ppm is a little more than 2 standard deviations away from the mean mercury concentration in our sample of fish from the Lumber River (1.08+2*0.64=2.43), but there are certainly fish in the sample with even higher mercury concentrations (max=3.5ppm), so this isn’t outside the bounds of what we’d expect."
  },
  {
    "objectID": "activities/L22-hypothesis-testing-discovery.html#exercise-2-1",
    "href": "activities/L22-hypothesis-testing-discovery.html#exercise-2-1",
    "title": "Hypothesis testing: discovery",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet’s look at the model summary output again:\n\nsummary(mod_fish)\n## \n## Call:\n## lm(formula = Concen ~ River, data = fish)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1664 -0.5681 -0.1764  0.4219  2.4219 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   1.07808    0.08866  12.160   &lt;2e-16 ***\n## RiverWacamaw  0.19835    0.11712   1.694   0.0922 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7575 on 169 degrees of freedom\n## Multiple R-squared:  0.01669,    Adjusted R-squared:  0.01087 \n## F-statistic: 2.868 on 1 and 169 DF,  p-value: 0.09218\n\n\npart a: interpret model coefficient\nNow, let’s interpret the RiverWacamaw coefficient. Based only on the coefficient (don’t think about the standard error yet), what can we say about the difference in mercury concentration among fish in the two rivers?\n\nThe RiverWacamaw coefficient is 0.19835, meaning that the mean mercury concentration among fish in the Wacamaw River is, on average, about 0.20ppm higher than that of fish in the Lumber River.\n\n\n\npart b: construct a CI\nUsing the 68-95-99.7 rule, construct an approximate 95% confidence interval for the RiverWacamaw coefficient, and provide an appropriate interpretation.\n\n0.20 +/- 2*0.11 –&gt; [-0.02, 0.42]\n\n\nPreferred interpretation: It is plausible that the true difference in mean mercury concentration among fish in the Wacamaw River compared to the Lumber River is between -0.02 ppm and 0.42ppm.\n\n\nNot as preferred interpretation: We are 95% confident that the mean mercury concentration among fish in the Wacamaw River somewhere between 0.02ppm less than that of fish in the Lumber River and 0.42ppm more than that of fish in the Lumber River.\n\n\n\npart c: interpreting the CI\nDo you believe it plausible that the mean mercury concentration of the fish population in the Wacamaw River is approximately the same as that of the fish population in the Lumber River? How would you confirm this? What assumptions are you making?\n\nAnswers may vary–this is certainly plausible, since our 95% CI contains 0 (i.e., there is no difference in means between the two rivers). However, we might also argue that there is SOME evidence of a difference, since most of the CI is &gt; 0.\n\n\n\npart d: effect of sample size on our conclusions\nSuppose we sample 10 times as many fish from the Wacamaw River, and get a similar coefficient estimate (0.2). Thinking back to the Central Limit Theorem, what should happen to the standard error of the RiverWacamaw coefficient? How small of a standard error would we need to more conclusively say that there is an actual difference in mean mercury concentrations of the Lumber River and Wacamaw River fish populations?\n\nA larger sample should result in a smaller standard error of the RiverWacamaw coefficient. If the standard error is smaller than 0.1 (say 0.098), then a 95% confidence interval would be [0.004, 0.396]. Since this interval doesn’t include 0, we could conclude that fish in the Wacamaw River, on average, have a higher mercury concentration than fish in the Lumber River. More importantly, the lower standard error of the coefficient allows us to say there is evidence that this difference should be observable across new samples.\n\n\n\npart e: reconciling parameter estimates and uncertainty\nSuppose the true population coefficient for the RiverWacamawparameter is 0.02 (i.e. the average mercury concentration is 0.02ppm higher for the Wacamaw River fish population compared to that of the Lumber River). Is this meaningful?\n\nThis will depend on context–a priori, this difference appears to be negligible, and we could potentially chalk it up to uncontrolled confounders (e.g., perhaps fish in one river tend to be older/bigger and therefore have slightly higher mercury concentrations, even if there is no underlying difference in mercury pollution). We also might consider: what is considered a “harmful” mercury concentration, and are fish in either river near that threshold? Has this changed over time, and by how much?\n\n\n\npart f: (CHALLENGE)\nUsing the model summary output, report the mean mercury concentration for our sample of fish from the Wacamaw River:\n\nsummary(mod_fish)\n## \n## Call:\n## lm(formula = Concen ~ River, data = fish)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1664 -0.5681 -0.1764  0.4219  2.4219 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   1.07808    0.08866  12.160   &lt;2e-16 ***\n## RiverWacamaw  0.19835    0.11712   1.694   0.0922 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7575 on 169 degrees of freedom\n## Multiple R-squared:  0.01669,    Adjusted R-squared:  0.01087 \n## F-statistic: 2.868 on 1 and 169 DF,  p-value: 0.09218\n\n\n1.07808 + 0.19835 = 1.27643ppm\n\nWhich of the following values do you think is the standard error of the sample mean for the Wacamaw River?\nTo answer this question, look at the code chunk below, which fits the same model, but uses the Wacamaw River as our reference category instead of the Lumber River:\n\nmod_fish2 &lt;- lm(Concen ~ River, data=fish %&gt;% mutate(River=ifelse(River == \"Wacamaw\", paste0(\"_\", River), River)))\nsummary(mod_fish2)\n## \n## Call:\n## lm(formula = Concen ~ River, data = fish %&gt;% mutate(River = ifelse(River == \n##     \"Wacamaw\", paste0(\"_\", River), River)))\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1664 -0.5681 -0.1764  0.4219  2.4219 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  1.27643    0.07652  16.681   &lt;2e-16 ***\n## RiverLumber -0.19835    0.11712  -1.694   0.0922 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7575 on 169 degrees of freedom\n## Multiple R-squared:  0.01669,    Adjusted R-squared:  0.01087 \n## F-statistic: 2.868 on 1 and 169 DF,  p-value: 0.09218\n\nCompare this to the output for mod_fish. What do you notice about the standard errors of the intercepts (i.e., the standard errors of the means for each river) compared to the standard errors of the RiverWacamaw and RiverLumber coefficients (i.e., the standard errors of the differences between the means)?\n\nSEs for the means are 0.08866 and 0.07652 for the Lumber and Wacamaw rivers, respectively. The SE for the difference is the same in both models (0.11712), which is greater than the SE of either mean. Because standard errors quantify uncertainty in a given parameter estimate, this tells us that the uncertainty of the estimated difference between two means is greater than the uncertainty in our estimate of either mean by itself."
  },
  {
    "objectID": "activities/L20-bootstrapping.html#learning-goals",
    "href": "activities/L20-bootstrapping.html#learning-goals",
    "title": "Bootstrapping",
    "section": "Learning goals",
    "text": "Learning goals\nLet \\(\\beta\\) be some population parameter and \\(\\hat{\\beta}\\) be a sample estimate of \\(\\beta\\). In order to study the potential error in \\(\\hat{\\beta}\\), you will…\n\nexplore two approaches to approximating the sampling distribution of \\(\\hat{\\beta}\\):\n\nCentral Limit Theorem (CLT)\nbootstrapping\n\nidentify the difference between sampling and resampling\nintuit how bootstrapping results can be used to make inferences about \\(\\beta\\)"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#readings-and-videos",
    "href": "activities/L20-bootstrapping.html#readings-and-videos",
    "title": "Bootstrapping",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease watch the following video after class:\n\nbootstrapping"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-1-sample-vs-population",
    "href": "activities/L20-bootstrapping.html#exercise-1-sample-vs-population",
    "title": "Bootstrapping",
    "section": "Exercise 1: sample vs population",
    "text": "Exercise 1: sample vs population\n\nIn the summary table, is the Length coefficient 0.058 the population slope \\(\\beta_1\\) or a sample estimate \\(\\hat{\\beta}_1\\)?\nIf it’s a sample estimate, how accurate do you think it is?"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-2-the-rub",
    "href": "activities/L20-bootstrapping.html#exercise-2-the-rub",
    "title": "Bootstrapping",
    "section": "Exercise 2: The rub",
    "text": "Exercise 2: The rub\nSince we don’t know \\(\\beta_1\\), we can’t know the exact error in \\(\\hat{\\beta}_1\\)! This is where sampling distributions come in. They describe how estimates \\(\\hat{\\beta}_1\\) might vary from sample to sample, thus how far these estimates might fall from \\(\\beta_1\\):\n\nIn past activities, we used simulations to approximate the sampling distribution. For example, we took and evaluated 500 different samples of 10 counties from the population of 3142 counties. Why can’t we do that here in our fish example?"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-3-clt",
    "href": "activities/L20-bootstrapping.html#exercise-3-clt",
    "title": "Bootstrapping",
    "section": "Exercise 3: CLT",
    "text": "Exercise 3: CLT\nIn practice, we can’t observe the sampling distribution and its corresponding standard error. But we can approximate them. When our sample size n is “large enough”, we might approximate the sampling distribution using the CLT:\n\\[\\hat{\\beta}_1 \\sim N(\\beta_1, \\text{standard error}^2)\\]\nThe standard error in the CLT is approximated from our sample via some formula \\(c / \\sqrt{n}\\) where “c” is complicated. Obtain and interpret this standard error from the model summary table:\n\ncoef(summary(fish_model))"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#reflect",
    "href": "activities/L20-bootstrapping.html#reflect",
    "title": "Bootstrapping",
    "section": "REFLECT",
    "text": "REFLECT\nGreat! We can approximate the sampling distribution and standard error using the CLT. BUT:\n\nthe quality of this approximation hinges upon the validity of the Central Limit theorem which hinges upon the validity of the theoretical model assumptions\nthe CLT uses complicated formulas for the standard error estimates, thus can feel a little mysterious\n\nLet’s explore how we can use bootstrapping to complement (not entirely replace) the CLT. The saying “to pull oneself up by the bootstraps” is often attributed to Rudolf Erich Raspe’s 1781 The Surprising Adventures of Baron Munchausen in which the character pulls himself out of a swamp by his hair (not bootstraps). In short, it means to get something from nothing, through your own effort:\n\nIn this spirit, statistical bootstrapping doesn’t make any probability model assumptions. It uses only the information from our one sample to approximate standard errors."
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-4-challenge",
    "href": "activities/L20-bootstrapping.html#exercise-4-challenge",
    "title": "Bootstrapping",
    "section": "Exercise 4: Challenge",
    "text": "Exercise 4: Challenge\nRecall that we have a sample size of 171 fish:\n\nnrow(fish)\n\nWe’ll obtain a bootstrapping distribution of \\(\\hat{\\beta}_1\\) by taking many (500) different samples of 171 fish and exploring the degree to which \\(\\hat{\\beta}_1\\) varies from sample to sample. Let’s try doing this as we did in past activities:\n\n# Build 500 models using samples of size 171\nfish_models_bad_simulation &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 171, replace = FALSE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n\nhead(fish_models_bad_simulation)\n\nWhat’s funny about the results? Why do you think this happened? How might you adjust the code to “fix” things?"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-5-resampling",
    "href": "activities/L20-bootstrapping.html#exercise-5-resampling",
    "title": "Bootstrapping",
    "section": "Exercise 5: Resampling",
    "text": "Exercise 5: Resampling\nIn practice, we take one sample of size n from the population. To obtain a bootstrapping distribution of some sample estimate \\(\\hat{\\beta}\\), we…\n\ntake many resamples of size n with replacement from the sample\ncalculate \\(\\hat{\\beta}\\) using each resample\n\n\nLet’s wrap our minds around the idea of resampling using a small example of 5 fish:\n\n# Define data\nsmall_sample &lt;- data.frame(\n  id = 1:5,\n  Length = c(44, 43, 54, 52, 40))\n\nsmall_sample\n\nThis sample has a mean Length of 46.6 cm:\n\nsmall_sample %&gt;% \n  summarize(mean(Length))\n\n\nThe chunk below samples 5 fish without replacement from our small_sample of 5 fish, and calculates their mean length. Run it several times. How do the sample and resulting mean change?\n\n\nsample_1 &lt;- sample_n(small_sample, size = 5, replace = FALSE)\nsample_1\n\nsample_1 %&gt;% \n  summarize(mean(Length))\n\n\nSampling our sample without replacement merely returns our original sample. Instead, resample 5 fish from our small_sample with replacement. Run it several times. What do you notice about the samples? About their mean lengths?\n\n\nsample_2 &lt;- sample_n(small_sample, size = 5, replace = TRUE)\nsample_2\n\nsample_2 %&gt;% \n  summarize(mean(Length))\n\n\nResampling our sample provides insight into the variability, hence potential error, in our sample estimates. (This works better when we have a sample bigger than 5!) As you observed in part b, each resample might include some fish from the original sample several times and others not at all. Why is this ok?"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-6-bootstrapping",
    "href": "activities/L20-bootstrapping.html#exercise-6-bootstrapping",
    "title": "Bootstrapping",
    "section": "Exercise 6: Bootstrapping",
    "text": "Exercise 6: Bootstrapping\nWe’re ready to bootstrap! Fix one line of the code below to obtain 500 bootstrap estimates of the model of Concen by Length:\n\n# Set the seed so we get the same results\nset.seed(155)\n\n# Build 500 bootstrap models using REsamples of size 171\nfish_models_bootstrap &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 171, replace = FALSE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n\nhead(fish_models_bootstrap)"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-7-bootstrap-results",
    "href": "activities/L20-bootstrapping.html#exercise-7-bootstrap-results",
    "title": "Bootstrapping",
    "section": "Exercise 7: Bootstrap results",
    "text": "Exercise 7: Bootstrap results\nRecall that we started with 1 sample, thus 1 estimate of the model:\n\ncoef(summary(fish_model))\n\n\nWe now have 500 (resample) bootstrap estimates of the model. These vary around the red line in the plot below. What does the red line represent: the actual population model or fish_model (the estimated model calculated from our original fish sample)?\n\n\nfish %&gt;% \n  ggplot(aes(y = Concen, x = Length)) +\n  geom_abline(data = fish_models_bootstrap, aes(intercept = Intercept, slope = Length), color = \"gray\") + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\nNow focus on just the 500 (resample) bootstrap estimates of the slope Length coefficient. Before plotting the distribution of these resampled slopes, what do you anticipate? What shape do you expect the distribution will have? Around what value do you expect it to be centered?\nCheck your intuition with the plot below. Was your intuition right?\n\n\nfish_models_bootstrap %&gt;% \n  ggplot(aes(x = Length)) + \n  geom_density()"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-8-bootstrap-standard-errors",
    "href": "activities/L20-bootstrapping.html#exercise-8-bootstrap-standard-errors",
    "title": "Bootstrapping",
    "section": "Exercise 8: Bootstrap standard errors",
    "text": "Exercise 8: Bootstrap standard errors\nSince they’re calculated from resamples of our sample, not different samples from the population, the 500 bootstrap estimates of the slope are centered around our original sample estimate. Importantly:\nThe degree to which the bootstrap estimates vary from the original sample estimate provides insight in the degree to which our original sample estimate might vary from the actual population slope (i.e. its standard error)!\n\nUse the bootstrap estimates of the Length slope coefficient to approximate the standard error of 0.05813, our original sample estimate. HINT: standard deviation\n\n\n# fish_models_bootstrap %&gt;% \n#   ___(___(Length))\n\n\nHow does this bootstrapped approximation of standard error compare to that calculated via (a complicated mystery) formula and reported in the model summary table?\n\n\ncoef(summary(fish_model))"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#pause-powerful-stuff",
    "href": "activities/L20-bootstrapping.html#pause-powerful-stuff",
    "title": "Bootstrapping",
    "section": "Pause: Powerful stuff!",
    "text": "Pause: Powerful stuff!\nJust pause here to appreciate how awesome it is that you approximated the potential error in our sample estimates using simulation and your sample data alone – no “theorems” or complicated formulas. You might say we pulled ourselves up by the bootstraps."
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-9-looking-ahead-at-intervals",
    "href": "activities/L20-bootstrapping.html#exercise-9-looking-ahead-at-intervals",
    "title": "Bootstrapping",
    "section": "Exercise 9: Looking ahead at intervals",
    "text": "Exercise 9: Looking ahead at intervals\nIn the past few activities, we’ve been exploring sampling variability and error. These tools are critical in using our sample to make inferences about the broader population. We’ll explore inference more formally in the weeks ahead. Here, use your intuition to apply our bootstrapping results:\n\nfish %&gt;% \n  ggplot(aes(y = Concen, x = Length)) +\n  geom_abline(data = fish_models_bootstrap, aes(intercept = Intercept, slope = Length), color = \"gray\")\n\n\nfish_models_bootstrap %&gt;% \n  ggplot(aes(x = Length)) + \n  geom_density()\n\n\nOur original sample estimate of the Length coefficient, 0.0581, was simply our best guess of the actual coefficient among all fish. But we know it’s wrong. Based on the plots above, provide a bigger range or interval of plausible values for the actual coefficient among all fish.\nWe can do better than visual approximations. Use the fish_models_bootstrap results to provide a more specific interval of plausible values for the actual Length coefficient. THINK: Do you think we should use the full range of observed bootstrap estimates? Just a fraction?\n\n\n# fish_models_bootstrap %&gt;% \n#   summarize(___(Length, ___), ___(Length, ___))"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-10-looking-ahead-at-hypothesis-testing",
    "href": "activities/L20-bootstrapping.html#exercise-10-looking-ahead-at-hypothesis-testing",
    "title": "Bootstrapping",
    "section": "Exercise 10: Looking ahead at hypothesis testing",
    "text": "Exercise 10: Looking ahead at hypothesis testing\nSome researchers claim that mercury content is associated with the length of a fish. Let’s use our bootstrapping results to test this hypothesis.\n\nBased on only the plot below of our bootstrap models, do you think our sample data supports this hypothesis?\n\n\nfish %&gt;% \n  ggplot(aes(y = Concen, x = Length)) +\n  geom_abline(data = fish_models_bootstrap, aes(intercept = Intercept, slope = Length), color = \"gray\")\n\n\nWhat about numerical evidence? Based on the interval you calculated in part b of the previous exercise, do you think our sample data supports this hypothesis?"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-1-sample-vs-population-1",
    "href": "activities/L20-bootstrapping.html#exercise-1-sample-vs-population-1",
    "title": "Bootstrapping",
    "section": "Exercise 1: sample vs population",
    "text": "Exercise 1: sample vs population\n\nsample estimate\nno idea (at this point at least)! we don’t know the actual population slope"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-2-the-rub-1",
    "href": "activities/L20-bootstrapping.html#exercise-2-the-rub-1",
    "title": "Bootstrapping",
    "section": "Exercise 2: The rub",
    "text": "Exercise 2: The rub\nWe only have access to a sample of fish, not the entire population."
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-3-clt-1",
    "href": "activities/L20-bootstrapping.html#exercise-3-clt-1",
    "title": "Bootstrapping",
    "section": "Exercise 3: CLT",
    "text": "Exercise 3: CLT\n0.005"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-4-challenge-1",
    "href": "activities/L20-bootstrapping.html#exercise-4-challenge-1",
    "title": "Bootstrapping",
    "section": "Exercise 4: Challenge",
    "text": "Exercise 4: Challenge\nThe results are all the same. Since we sampled without replacement, we got the same sample hence the same sample estimates every time."
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-5-resampling-1",
    "href": "activities/L20-bootstrapping.html#exercise-5-resampling-1",
    "title": "Bootstrapping",
    "section": "Exercise 5: Resampling",
    "text": "Exercise 5: Resampling\n\nWe always get the same sample (the original 5 fish), just in a different order. Thus the mean is always the sample.\nThey differ.\nSampling the same fish more than once is like observing different fish with similar characteristics."
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-6-bootstrapping-1",
    "href": "activities/L20-bootstrapping.html#exercise-6-bootstrapping-1",
    "title": "Bootstrapping",
    "section": "Exercise 6: Bootstrapping",
    "text": "Exercise 6: Bootstrapping\n\n# Set the seed so we get the same results\nset.seed(155)\n\n# Build 500 bootstrap models using REsamples of size 171\nfish_models_bootstrap &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 171, replace = TRUE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n\nhead(fish_models_bootstrap)\n##    Intercept     Length     sigma r.squared         F numdf dendf .row .index\n## 1 -1.1802375 0.05827521 0.5834448 0.4127396 118.77693     1   169    1      1\n## 2 -1.2902917 0.06296431 0.5667005 0.4661328 147.55814     1   169    1      2\n## 3 -1.0449945 0.05645232 0.5836492 0.4094752 117.18610     1   169    1      3\n## 4 -1.2721884 0.06065800 0.5253640 0.5043690 171.97948     1   169    1      4\n## 5 -0.8324804 0.04929179 0.5820092 0.3695009  99.04160     1   169    1      5\n## 6 -0.8811652 0.05088282 0.5786866 0.3671583  98.04942     1   169    1      6"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-7-bootstrap-results-1",
    "href": "activities/L20-bootstrapping.html#exercise-7-bootstrap-results-1",
    "title": "Bootstrapping",
    "section": "Exercise 7: Bootstrap results",
    "text": "Exercise 7: Bootstrap results\n\nfish_model\nintuition\nThey are normally distributed around our original sample estimate."
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-8-bootstrap-standard-errors-1",
    "href": "activities/L20-bootstrapping.html#exercise-8-bootstrap-standard-errors-1",
    "title": "Bootstrapping",
    "section": "Exercise 8: Bootstrap standard errors",
    "text": "Exercise 8: Bootstrap standard errors\n\n.\n\n\nfish_models_bootstrap %&gt;%\n  summarize(sd(Length))\n##    sd(Length)\n## 1 0.005664586\n\n\nvery close!"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-9-looking-ahead-at-intervals-1",
    "href": "activities/L20-bootstrapping.html#exercise-9-looking-ahead-at-intervals-1",
    "title": "Bootstrapping",
    "section": "Exercise 9: Looking ahead at intervals",
    "text": "Exercise 9: Looking ahead at intervals\n\nWill vary. Maybe 0.0375ish to 0.07ish.\nWill vary. For example, if we lop off the extreme 2.5% (the smallest and biggest estimates) and just keep the middle 95%:\n\n\nfish_models_bootstrap %&gt;%\n  summarize(quantile(Length, 0.025), quantile(Length, 0.975))\n##   quantile(Length, 0.025) quantile(Length, 0.975)\n## 1              0.04677145              0.06905934"
  },
  {
    "objectID": "activities/L20-bootstrapping.html#exercise-10-looking-ahead-at-hypothesis-testing-1",
    "href": "activities/L20-bootstrapping.html#exercise-10-looking-ahead-at-hypothesis-testing-1",
    "title": "Bootstrapping",
    "section": "Exercise 10: Looking ahead at hypothesis testing",
    "text": "Exercise 10: Looking ahead at hypothesis testing\n\nYes. All of the lines reflect a positive association.\nYes. It falls entirely above 0 (a slope of 0 indicating no association)."
  },
  {
    "objectID": "activities/L08-mlr-intro.html#learning-goals",
    "href": "activities/L08-mlr-intro.html#learning-goals",
    "title": "Introduction to multiple regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be familiar with:\n\nsome limitations of simple linear regression\nthe general goals behind multiple linear regression\nstrategies for visualizing and interpreting multiple linear regression models of \\(Y\\) vs 2 predictors, 1 quantitative and 1 categorical"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#readings-and-videos",
    "href": "activities/L08-mlr-intro.html#readings-and-videos",
    "title": "Introduction to multiple regression",
    "section": "Readings and videos",
    "text": "Readings and videos\nToday is a day to discover ideas, so no readings or videos to go through before class."
  },
  {
    "objectID": "activities/L08-mlr-intro.html#motivation",
    "href": "activities/L08-mlr-intro.html#motivation",
    "title": "Introduction to multiple regression",
    "section": "Motivation",
    "text": "Motivation\nEXAMPLE 1\nLet’s explore some data on penguins. First, enter install.packages(\"palmerpenguins\") in the console (not Rmd). Then load the penguins data. You can find a codebook for these data by typing ?penguins in your console (not Rmd).\n\n# Load packages\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load data\nlibrary(palmerpenguins)\ndata(penguins)\npenguins &lt;- penguins %&gt;% \n  filter(species != \"Adelie\", bill_length_mm &lt; 57)\n\n# Check it out\nhead(penguins)\n\nOur goal is to build a model that we can use to get good predictions of penguins’ flipper (“arm”) lengths. Consider 2 simple linear regression models of flipper_length_mm by penguin sex and species:\n\nsummary(lm(flipper_length_mm ~ sex, penguins))$r.squared\nsummary(lm(flipper_length_mm ~ species, penguins))$r.squared\n\nHow might we improve our predictions of flipper_length_mm using only these 2 predictors? What do you think is a reasonable range of possible values for the new R-squqared?\nEXAMPLE 2\nConsider a simple linear regression model of flipper_length_mm by bill_length_mm:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\nThoughts? What’s going on here? How does this highlight the limitations of a simple linear regression model?\nEXAMPLE 3\nThe cps dataset contains employment information collected by the U.S. Current Population Survey (CPS) in 2018. We can use these data to explore wages among 18-34 year olds. The original codebook is here.\n\n# Import data\ncps &lt;- read_csv(\"https://mac-stat.github.io/data/cps_2018.csv\") %&gt;% \n  select(-education, -hours) %&gt;% \n  filter(age &gt;= 18, age &lt;= 34) %&gt;% \n  filter(wage &lt; 250000)\n\n\n# Check it out\nhead(cps)\n\nWe can use a simple linear regression model to summarize the relationship of wage with marital status:\n\n# Build the model\nwage_mod &lt;- lm(wage ~ marital, data = cps)\n\n# Summarize the model\ncoef(summary(wage_mod))\n\nWhat do you / don’t you conclude from this model? How does it highlight the limitations of a simple linear regression model?\nReflection: Why are multiple regression models so useful?\nWe can put more than 1 predictor into a regression model! Adding predictors to models…\n\nPredictive viewpoint: Helps us better predict the response\nDescriptive viewpoint: Helps us better understand the isolated (causal) effect of a variable by holding constant confounders\n\nMultiple linear regression model formula\nIn general, a multiple linear regression model of \\(Y\\) with multiple predictors \\((X_1, X_2, ..., X_p)\\) is represented by the following formula:\n\\[E[Y \\mid X_1, X_2, ..., X_p] = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\\]"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-1-visualizing-the-relationship",
    "href": "activities/L08-mlr-intro.html#exercise-1-visualizing-the-relationship",
    "title": "Introduction to multiple regression",
    "section": "Exercise 1: Visualizing the relationship",
    "text": "Exercise 1: Visualizing the relationship\nWe’ve learned how to visualize the relationship of flipper_length_mm by bill_length_mm alone:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point()\n\n\nTHINK: How might we change the scatterplot points to also indicate information about penguin species? (There’s more than 1 approach!)\nTry out your idea by modifying the code below. If you get stuck, talk with the tables around you!\n\n\npenguins %&gt;%\n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, ___ = ___)) +\n  geom_point()"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-2-visualizing-the-model",
    "href": "activities/L08-mlr-intro.html#exercise-2-visualizing-the-model",
    "title": "Introduction to multiple regression",
    "section": "Exercise 2: Visualizing the model",
    "text": "Exercise 2: Visualizing the model\nWe’ve also learned that a simple linear regression model of flipper_length_mm by bill_length_mm alone can be represented by a line:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\nTHINK: Reflecting on your plot of flipper_length_mm by bill_length_mm and species in Exercise 1, how do you think a multiple regression model of flipper_length_mm using both of these predictors would be represented?\nCheck your intuition below by modifying the code below to include species in this plot, as you did in Exercise 1.\n\n\npenguins %&gt;%\n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, ___ = ___)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-3-intuition",
    "href": "activities/L08-mlr-intro.html#exercise-3-intuition",
    "title": "Introduction to multiple regression",
    "section": "Exercise 3: Intuition",
    "text": "Exercise 3: Intuition\nYour plot in Exercise 2 demonstrated that the multiple linear regression model of flipper_length_mm by bill_length_mm and species is represented by 2 lines. Let’s interpret the punchlines!\nFor each question, provide an answer along with evidence from the model lines that supports your answer.\n\nWhat’s the relationship between flipper_length_mm and species, no matter a penguin’s bill_length_mm?\nWhat’s the relationship between flipper_length_mm and bill_length_mm, no matter a penguin’s species?\nDoes the rate of increase in flipper_length_mm with bill_length_mm differ between the two species?"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-4-model-formula",
    "href": "activities/L08-mlr-intro.html#exercise-4-model-formula",
    "title": "Introduction to multiple regression",
    "section": "Exercise 4: Model formula",
    "text": "Exercise 4: Model formula\nOf course, there’s a formula behind the multiple regression model. We can obtain this using the usual lm() function.\n\n# Build the model\npenguin_mod &lt;- lm(flipper_length_mm ~ bill_length_mm + species, data = penguins)\n\n# Summarize the model\ncoef(summary(penguin_mod))\n\n\nIn the lm() function, how did we communicate that we wanted to model flipper_length_mm by both bill_length_mm and species?\nComplete the following model formula:\nE[flipper_length_mm | bill_length_mm, speciesGentoo] = ___ + ___ * bill_length_mm + ___ * speciesGentoo"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-5-sub-model-formulas",
    "href": "activities/L08-mlr-intro.html#exercise-5-sub-model-formulas",
    "title": "Introduction to multiple regression",
    "section": "Exercise 5: Sub-model formulas",
    "text": "Exercise 5: Sub-model formulas\nOk. We now have a single formula for the model.\nAnd we observed earlier that this formula is represented by two lines: one describing the relationship between flipper_length_mm and bill_length_mm for Chinstrap penguins and the other for Gentoo penguins.\nLet’s bring these ideas together.\nUtilize the model formula to obtain the equations of these two lines, i.e. to obtain the sub-model formulas for the 2 species. Hint: Plug speciesGentoo = 0 and speciesGentoo = 1.\nChinstrap: flipper_length_mm = ___ + ___ bill_length_mm\nGentoo: flipper_length_mm = ___ + ___ bill_length_mm"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-6-coefficients-physical-interpretation",
    "href": "activities/L08-mlr-intro.html#exercise-6-coefficients-physical-interpretation",
    "title": "Introduction to multiple regression",
    "section": "Exercise 6: coefficients – physical interpretation",
    "text": "Exercise 6: coefficients – physical interpretation\nReflecting on Exercise 5, let’s interpret what the model coefficients tell us about the physical properties of the two 2 sub-model lines. Choose the correct option given in parentheses:\n\nThe intercept coefficient, 127.75, is the intercept of the line for (Chinstrap / Gentoo) penguins.\nThe bill_length_mm coefficient, 1.40, is the (intercept / slope) of both lines.\nThe speciesGentoo coefficient, 22.85, indicates that the (intercept / slope) of the line for Gentoo is 22.85mm higher than the (intercept / slope) of the line for Chinstrap. Similarly, since the lines are parallel, the line for Gentoo is 22.85mm higher than the line for Chinstrap at any bill_length_mm."
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-7-coefficients-contextual-interpretation",
    "href": "activities/L08-mlr-intro.html#exercise-7-coefficients-contextual-interpretation",
    "title": "Introduction to multiple regression",
    "section": "Exercise 7: coefficients – contextual interpretation",
    "text": "Exercise 7: coefficients – contextual interpretation\nNext, interpret each coefficient in a contextually meaningful way. What do they tell us about penguin flipper lengths?!\n\nInterpret 127.75 (intercept of the Chinstrap line).\nInterpret 1.40 (slope of both lines). For both Chinstrap and Gentoo penguins, we expect…\nInterpret 22.85. At any bill_length_mm, we expect…"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-8-prediction",
    "href": "activities/L08-mlr-intro.html#exercise-8-prediction",
    "title": "Introduction to multiple regression",
    "section": "Exercise 8: Prediction",
    "text": "Exercise 8: Prediction\nNow that we better understand the model, let’s use it to predict flipper lengths! Recall the model summary and visualization:\n\ncoef(summary(penguin_mod))\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, color = species)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\nPredict the flipper length of a Chinstrap penguin with a 50mm long bill. Make sure your calculation is consistent with the plot.\n\n\n127.75 + 1.40*___ + 22.85*___\n\n\nPredict the flipper length of a Gentoo penguin with a 50mm long bill. Make sure your calculation is consistent with the plot.\n\n\n127.75 + 1.40*___ + 22.85*___\n\n\nUse the predict() function to confirm your predictions in parts a and b.\n\n\n# Confirm the calculation in part a\npredict(penguin_mod,\n        newdata = data.frame(bill_length_mm = ___, species = \"___\"))\n\n# Confirm the calculation in part b\npredict(penguin_mod,\n        newdata = data.frame(bill_length_mm = ___, species = \"___\"))"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-9-r-squared",
    "href": "activities/L08-mlr-intro.html#exercise-9-r-squared",
    "title": "Introduction to multiple regression",
    "section": "Exercise 9: R-squared",
    "text": "Exercise 9: R-squared\nFinally, recall that improving our predictions was one motivation for multiple linear regression (using 2 predictors instead of 1). To this end, consider the R-squared values of the simple linear regression models that use just one predictor at a time:\n\nmod_bill &lt;- lm(flipper_length_mm ~ bill_length_mm, data = penguins)\nsummary(mod_bill)\n\nmod_species &lt;- lm(flipper_length_mm ~ species, data = penguins)\nsummary(mod_species)\n\n\nIf you had to use only 1 of our 2 predictors, which would give the better predictions of flipper_length_mm?\nWhat do you guess is the R-squared of our multiple regression model that uses both of these predictors? Why?\nCheck your intuition. How does the R-squared of our multiple regression model compare to that of the 2 separate simple linear regression models?\n\n\nsummary(penguin_mod)"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#reflection",
    "href": "activities/L08-mlr-intro.html#reflection",
    "title": "Introduction to multiple regression",
    "section": "Reflection",
    "text": "Reflection\nYou’ve now explored your first multiple regression model! Thus you likely have a lot of questions about what’s to come. What are they?\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-1-visualizing-the-relationship-1",
    "href": "activities/L08-mlr-intro.html#exercise-1-visualizing-the-relationship-1",
    "title": "Introduction to multiple regression",
    "section": "Exercise 1: Visualizing the relationship",
    "text": "Exercise 1: Visualizing the relationship\n\nno wrong answer\nThere are multiple options!\n\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, color = species)) + \n  geom_point()\n\n\n\n\n\n\n\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, shape = species)) + \n  geom_point()"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-2-visualizing-the-model-1",
    "href": "activities/L08-mlr-intro.html#exercise-2-visualizing-the-model-1",
    "title": "Introduction to multiple regression",
    "section": "Exercise 2: Visualizing the model",
    "text": "Exercise 2: Visualizing the model\n\nno wrong answer\n\n\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, color = species)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-3-intuition-1",
    "href": "activities/L08-mlr-intro.html#exercise-3-intuition-1",
    "title": "Introduction to multiple regression",
    "section": "Exercise 3: Intuition",
    "text": "Exercise 3: Intuition\n\nGentoo tend to have longer flippers.\nFlipper length is positively associated with bill length.\nNo. the lines are parallel / have the same slopes."
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-4-model-formula-1",
    "href": "activities/L08-mlr-intro.html#exercise-4-model-formula-1",
    "title": "Introduction to multiple regression",
    "section": "Exercise 4: Model formula",
    "text": "Exercise 4: Model formula\n\nbill_length_mm + species\nE[flipper_length_mm | bill_length_mm, speciesGentoo] = 127.75 + 1.40 * bill_length_mm + 22.85 * speciesGentoo"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-5-sub-model-formulas-1",
    "href": "activities/L08-mlr-intro.html#exercise-5-sub-model-formulas-1",
    "title": "Introduction to multiple regression",
    "section": "Exercise 5: Sub-model formulas",
    "text": "Exercise 5: Sub-model formulas\nChinstrap: flipper_length_mm = 127.75 + 1.40 bill_length_mm\nGentoo: flipper_length_mm = (127.75 + 22.85) + 1.40 bill_length_mm = 150.6 + 1.40 bill_length_mm"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-6-coefficients-physical-interpretation-1",
    "href": "activities/L08-mlr-intro.html#exercise-6-coefficients-physical-interpretation-1",
    "title": "Introduction to multiple regression",
    "section": "Exercise 6: coefficients – physical interpretation",
    "text": "Exercise 6: coefficients – physical interpretation\n\nThe intercept coefficient, 127.75, is the intercept of the line for Chinstrap penguins.\nThe bill_length_mm coefficient, 1.40, is the slope of both lines.\nThe speciesGentoo coefficient, 22.85, indicates that the intercept of the line for Gentoo is 22.85mm higher than the intercept of the line for Chinstrap. Similarly, since the lines are parallel, the line for Gentoo is 22.85mm higher than the line for Chinstrap at any bill_length_mm."
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-7-coefficients-contextual-interpretation-1",
    "href": "activities/L08-mlr-intro.html#exercise-7-coefficients-contextual-interpretation-1",
    "title": "Introduction to multiple regression",
    "section": "Exercise 7: coefficients – contextual interpretation",
    "text": "Exercise 7: coefficients – contextual interpretation\n\nFor Chinstrap penguins with 0mm bills (silly), we expect a flipper length of 127.75mm.\nFor both Chinstrap and Gentoo penguins, flipper lengths increase by 1.40mm on average for every additional mm in bill length.\nAt any bill_length_mm, we expect the a Gentoo penguin to have 22.85mm longer flippers than a Chinstrap, on average."
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-8-prediction-1",
    "href": "activities/L08-mlr-intro.html#exercise-8-prediction-1",
    "title": "Introduction to multiple regression",
    "section": "Exercise 8: Prediction",
    "text": "Exercise 8: Prediction\n\n# a\n127.75 + 1.40*50 + 22.85*0\n## [1] 197.75\n\n# b\n127.75 + 1.40*50 + 22.85*1\n## [1] 220.6\n\n# c\npredict(penguin_mod,\n        newdata = data.frame(bill_length_mm = 50, \n                             species = \"Chinstrap\"))\n## Error: object 'penguin_mod' not found\npredict(penguin_mod,\n        newdata = data.frame(bill_length_mm = 50, \n                             species = \"Gentoo\"))\n## Error: object 'penguin_mod' not found"
  },
  {
    "objectID": "activities/L08-mlr-intro.html#exercise-9-r-squared-1",
    "href": "activities/L08-mlr-intro.html#exercise-9-r-squared-1",
    "title": "Introduction to multiple regression",
    "section": "Exercise 9: R-squared",
    "text": "Exercise 9: R-squared\n\nspecies\nno wrong answer\nIt’s higher than the R-squared when we use either predictor alone!"
  },
  {
    "objectID": "activities/L26-pvalues-discussion.html#readings-and-videos",
    "href": "activities/L26-pvalues-discussion.html#readings-and-videos",
    "title": "P-value Discussion",
    "section": "Readings and videos",
    "text": "Readings and videos\nYour instructor will assign you to one of four groups, each with a different reading to complete ahead of class time. You are of course welcome to read more than only your assigned reading if you choose to! The group reading assignments are as follows:\n\nGroup 1: The ASA Statement on p-values\nGroup 2: Scientific method: Statistical error\nGroup 3: Moving to a World Beyond “p &lt; 0.05”\nGroup 4: Statistical tests, p-values, confidence intervals, and power: a guide to misinterpretations"
  },
  {
    "objectID": "activities/L26-pvalues-discussion.html#step-1-review",
    "href": "activities/L26-pvalues-discussion.html#step-1-review",
    "title": "P-value Discussion",
    "section": "Step 1: Review",
    "text": "Step 1: Review\nTake a few minutes to review the assigned reading. Make note of the things you found most important, the things you found most confusing, or the things you still have questions about."
  },
  {
    "objectID": "activities/L26-pvalues-discussion.html#step-2-discuss",
    "href": "activities/L26-pvalues-discussion.html#step-2-discuss",
    "title": "P-value Discussion",
    "section": "Step 2: Discuss",
    "text": "Step 2: Discuss\nOnce everyone in your group is ready, find an empty space at the whiteboard.\nYou’ll discuss the following questions with your group and write down your key takeaways from your conversation on the board. After a few minutes, rotate to the next station: respond/react to the previous responses (e.g., add a + if you agree) and add your own. Repeat until you’ve visited all stations.\nQuestions:\n\nHow does this reading relate to your previous knowledge about p-values?\nWas anything that you learned from the reading particularly surprising?\nWhat are some of the ways in which p-values are often misinterpreted and/or misused?\nWhat suggestions does the article offer in terms of how p-values should be used?\nDoes the article provide any suggestions in terms of other tools that we should use instead of or in addition to p-values?\nWhat are your main takeaways from the reading?"
  },
  {
    "objectID": "activities/L26-pvalues-discussion.html#step-3-share-out",
    "href": "activities/L26-pvalues-discussion.html#step-3-share-out",
    "title": "P-value Discussion",
    "section": "Step 3: Share out",
    "text": "Step 3: Share out\nDesignate someone from your group who will share the highlights of your discussion with the full class!"
  },
  {
    "objectID": "activities/L13-mlr-model-building-1.html#learning-goals",
    "href": "activities/L13-mlr-model-building-1.html#learning-goals",
    "title": "Multiple linear regression: model building (part 1)",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nDistinguish between descriptive, predictive, and causal research questions\nIterate on your group’s research question to make it more precise and answerable\nChoose appropriate model(s) for addressing your group’s research question"
  },
  {
    "objectID": "activities/L13-mlr-model-building-1.html#readings-and-videos",
    "href": "activities/L13-mlr-model-building-1.html#readings-and-videos",
    "title": "Multiple linear regression: model building (part 1)",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease watch the following video before class.\n\nVideo: Causal Diagrams and Confounding Variables\n\nFile organization: If you would like to take notes in this document, download the template and save it in the “Activities” subfolder of your “STAT155” folder. You are more than welcome to take notes in a separate google document, shared with your project group, if you’d find that more useful!"
  },
  {
    "objectID": "activities/L13-mlr-model-building-1.html#step-1-review",
    "href": "activities/L13-mlr-model-building-1.html#step-1-review",
    "title": "Multiple linear regression: model building (part 1)",
    "section": "Step 1: Review",
    "text": "Step 1: Review\nTake a look at the first project checkpoint (your statistical analysis plan) that your group submitted. As part of this checkpoint, you should have come up with a research question. Record the research question you came up with: we’ll iterate on this question throughout the activity!\n\nRecord your research question here\n\nAnswer the following questions as a group (some of this may already be in your statistical analysis plan!):\n\nWho would be interested in the answer to this question?\nWhat variables do you need in a dataset to address this question?\nWhat data summaries (not models) would help you answer this question, and why?\nWhat plots (not models) would help you address your research question, and why?"
  },
  {
    "objectID": "activities/L13-mlr-model-building-1.html#step-2-descriptive-research-questions",
    "href": "activities/L13-mlr-model-building-1.html#step-2-descriptive-research-questions",
    "title": "Multiple linear regression: model building (part 1)",
    "section": "Step 2: Descriptive Research Questions",
    "text": "Step 2: Descriptive Research Questions\nDescriptive research questions are questions that seek to better understand the relationships between variables, without interest in causality. In practice, nearly every research question asked is ultimately interested in causality, but practical constraints (such as unmeasured confounding) lead us to ask descriptive questions instead.\nIf we’re only interested in associations (not causality), we don’t need to adjust for potential confounding variables in our model.\n\nFor your group’s chosen research question, write a model statement that would address a descriptive version of your research question below:\n\nModel statement for a descriptive question here"
  },
  {
    "objectID": "activities/L13-mlr-model-building-1.html#step-3-predictive-research-questions",
    "href": "activities/L13-mlr-model-building-1.html#step-3-predictive-research-questions",
    "title": "Multiple linear regression: model building (part 1)",
    "section": "Step 3: Predictive Research Questions",
    "text": "Step 3: Predictive Research Questions\nPredictive research questions seek to determine if (and how well) we can predict outcomes for new / future events, using the information we already have. We’ve seen a bit of prediction in this course when we talked about fitted values!\n\nWith your groups, discuss the following:\n\nIs your research question predictive, or inferential? Inferential questions seek to understand the relationships between variables.\nIf your question were predictive, who would be interested/invested in the results from your project? How could the results from your project be used in practice?\nAre there any variables that are not available to you in your data that you would include in your predictive model if you could? Why or why not?"
  },
  {
    "objectID": "activities/L13-mlr-model-building-1.html#step-3-causal-research-questions",
    "href": "activities/L13-mlr-model-building-1.html#step-3-causal-research-questions",
    "title": "Multiple linear regression: model building (part 1)",
    "section": "Step 3: Causal Research Questions",
    "text": "Step 3: Causal Research Questions\nCausal research questions are ultimately what most inferential statistics is interested in, regardless of whether or not we end up being able to make causal conclusions. From the videos for today, you learned about different types of variables, and whether or not they should be included or excluded from a model, depending on your causal research question.\nWith your groups, make a causal diagram (DAG) on the whiteboard for your research question. Consider including all variables you wish you had access to, even if they aren’t available in your data (this will help you later when talking about limitations of your analysis in your final paper), but certainly include relevant variables that are available in your data.\nFor each variable in your DAG that is available in your dataset, determine whether it should be included or excluded from your model. Use this to update your descriptive model statement from Step 2.\n\nModel statement for a causal question here\n\nNow look back at your DAG, and note if any of the variables that are not available in your data are potential confounders. If so, record them here (this means you likely won’t be able to draw causal conclusions):\n\nList of “unmeasured” confounding variables here"
  },
  {
    "objectID": "activities/L13-mlr-model-building-1.html#step-4-reflection",
    "href": "activities/L13-mlr-model-building-1.html#step-4-reflection",
    "title": "Multiple linear regression: model building (part 1)",
    "section": "Step 4: Reflection",
    "text": "Step 4: Reflection\nToday was all about iterating on a research question, and using those questions to guide the way we explore data and fit statistical models. How confident do you feel in distinguishing between descriptive, predictive, and causal research questions? How confident do you feel in knowing which components of a model matter more or less, in each specific case? What might help you feel more confident?\n\nResponse: Put your response here."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": " ",
    "section": "",
    "text": "Macalester College, Fall 2025\n\nSection 05: Tu/Th 9:40-11:10am, THTR 202\n\n\n\n\nJedidiah (Jed) Carlson, PhD\nPronouns: he/him\nPronunciation: listen here\nOffice: Olin-Rice 236\nWebsite: https://jedidiahcarlson.com\nEmail: jcarls13@macalester.edu\n\n\n\n\n\n\nCall me “Jed”\n\n\n\nFeel free to call me (in order of my personal preference), Jed, Professor Carlson, or Dr. Carlson–but please use whichever of these options you are most comfortable with! (note that “Professor Jed” makes me cringe)\n\n\nDrop-in (office) hours:\n\nlocation: My office (OLRI 236)\ntimes: See this calendar.\n\n\n\n\nThis course provides an introduction to statistical modeling. In other words, you will develop the basic skills to analyze data, test research hypotheses, and make predictions about the world.\nBeing able to summarize, interpret, and communicate about data are crucial for navigating today’s information landscape, and these are precisely the skills that we’ll build in this class. Throughout the semester, we’ll study the fundamental methods that statisticians use to extract knowledge from data, emphasizing statistical literacy & intuition, real data applications, and modern computing over memorizing facts and formulas.\n\n\nBy actively participating in this course, you will develop and/or strengthen your abilities to:\n\nVisualize: explore, understand, and describe patterns in data with plots and graphics\nModel: build, interpret, and evaluate statistical models to identify trends in data\nInfer: extend observations from sample data to draw conclusions and make predictions\nCompute: use the (free!) statistical software R to analyze real data and create reproducible reports\nContextualize: interpret results in context, by considering the methods of data collection, the scientific and social contexts, and ethical dimensions\nCommunicate: accurately describe methods and results in a way that is scientifically sound and widely accessible\nCollaborate: work productively and effectively in a group setting\n\n\n\n\nWhen taking a new course, figuring out the right workflow/cadence of effort throughout the week can be a big adjustment. And most of you are doing this for 4 different courses! Below are some suggestions for what to expect in the course and how to focus your time and attention during and outside of class.\n\n\nPlan Ahead\nIn a typical week, plan to spend 8-10 hours on STAT 155 (or any 4-credit course), including class time.\n\nIf you are working far more or far less than 8 hours per week, let me know.\nCarve out dedicated time on your calendar for intentionally studying/reviewing and doing homework.\nStay up-to-date on the course calendar.\n\n\n\n\nDo the things\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\nAttend class and actively engage in class\nWork with your classmates; ask each other questions; share your ideas\nComplete the in-class activities (this might mean completing it outside of class, if you didn’t finish)\n\n\n\n\n\n\n\nSuggestion\n\n\n\nReview your learning process and group work reflections just before class to frame how you want to engage in class. (Perhaps you’ve noted a struggle and want to try a new strategy.)\n\n\n\n\n\nReflect\nMake sure to take the time to finish the activity and review the solutions. I will have a checkpoint on Moodle for most days to draw attention to important concepts covered in the previous class.\nReview\nMost class periods will involve working with a new tool and computational concept. Rewrite / organize your notes. Summarize concepts in your own words.\nBe Curious\nDon’t be afraid to ask questions. These are opportunities to learn and dig deeper. You get out what you put into a course.\n\n\n\n\n\n\nSuggestion\n\n\n\n\nOpen the checkpoint on Moodle as you review the material. Jot down questions or ideas that you have about topics in the material.\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to immediately attempt the related exercises on the upcoming homework assignment.\nCome to instructor office drop-in hours to chat about the course or anything else! 😃\n\n\n\n\n\n\n\n\n\n\n\nThere is no required textbook for this course—there will occasionally be some readings assigned from the 155 Course Notes or other sources. All links and materials needed will be provided on the Schedule tab of this website.\nThe best resources for this course are course content videos, attending and participating in class / assignments, and office hours. I am happy to talk about possible additional materials / strategies for effective learning at any time throughout the semester!\n\n\n\nWe will use the (completely free and open source) R programming language extensively throughout this course. RStudio (an interface for R) will facilitate our use of R. You may use RStudio in one of two ways:\n\nDesktop version: Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nOnline: Go to https://rstudio.macalester.edu, and log in with your full Mac email address and your usual Mac password to get access. (Note that this is a shared resource across MSCS, and you may experience performance issues due to high traffic, server outages, etc.)\n\nMore detailed instructions on downloading, installing, and getting started with R, RStudio, and an important package called Quarto is available on the Tech Setup tab.\n\n\n\nYour peers in the class are an underappreciated resource for learning the material and helping you stay on top of deadlines, course policies, etc. I strongly encourage you to connect with one another, in the form of a weekly study group, WhatsApp chat, etc.\n\n\n\nAll course materials will be posted on the course website. The Schedule tab of this website will be updated regularly with information about due dates, in-class activities, etc.\n\n\n\nMoodle will be used to submit assignments/checkpoint quizzes, post grades, assignment feedback, announcements, and more. Please check the course Moodle page every day before class!\n\n\n\nWe have many preceptors for this course! You may attend office hours for any of the STAT 155 preceptors, not just those grading/attending my sections. All MSCS courses will also share a dedicated R preceptor who can help with any issues you have with your R code or RStudio configuration. The course Moodle site contains detailed information and a Google Calendar link for preceptor office hour times/locations.\nThe role of an MSCS preceptor is to help students with content questions, assist in the navigation of available resources, advise on studying approaches for classes, and assist with concepts, tools, and skills needed for problem sets. However, students are accountable for their own learning; as such, preceptors are not allowed to share answers to assignments (unless specifically directed by the instructor), are not expected to immediately know the right approach, or provide assistance outside of office hours. Guidelines and expectations on how to interact with preceptors can be found here.\n\n\n\nOffice hours are an open-ended time for you to go over coursework, clarify concepts, solicit my biased opinions sage wisdom on career planning/graduate school, discuss research/internship opportunities, connect you with resources you need, or chat about life in general.\nOffice hours are oriented around group discussion. They are not first come, first served appointments, nor are they a place to sit and work on your assignments until you have questions. Please be respectful of your peers and do not monopolize the time.\n\n\n\nIf you’re not finding the answer you’re looking for using any of the resources above, or if you wish to discuss a private matter (e.g., attendance, grades, accommodations, etc.) please contact me via email. Please put “STAT 155” in the subject line of all emails to me, to help ensure that it does not get lost in my inbox!\nI will generally not respond to emails outside of business hours (9am-5pm M-F). Please allow 1 business day for a response (e.g. an email sent on Friday may not get a response until the following Monday).\nAny urgent announcements (e.g. unexpected class cancellations, notice of modifications to assignments) will be made over email.\n\n\n\n\n\nThe grading system in this course is designed to help you achieve the learning objectives while allowing space to make and learn from mistakes along the way. Your final letter grade will be determined by your progress towards five core course components:\n\n\nEngagement and commitment to growth are foundational to your own learning & to fostering a supportive learning community. So that we can share clear and consistent information about meeting these expectations, information about attendance and engagement will be recorded in the “In-class engagement” activity on Moodle.\nEXPECTATIONS:\n\nIn class:\n\nDo not miss &gt;3 in-person class sessions. (4-6 absences will lower your grade. 7+ absences will result in a D/NC.)\nBe on time & don’t leave early\nDo not use your phone (they must be put away when you enter class, even if class hasn’t started)\nDo not use your laptop for anything other than taking notes or working on the in-class activity. I recommend using a different browser window rather than opening up a new tab alongside the rest of your personal/school stuff.\nBe actively present. Don’t work alone, work on other courses, or work on practice problems for this course without explicit permission\n\nOutside class:\n\nstay updated on announcements (typically via email), deadlines, Moodle\nVisit my office hours at least 2 times during the semester (once before fall break and once after), and at least 2 of the preceptors’ office hours\n\n\n\n\n\nRoughly half of our class sessions will require some prep work to build a common foundation and maximize our time together (just like assigned reading & reflection in a humanities class!). Before these classes, you will watch short videos and/or read sections of the online textbook which introduce new concepts, then take a low-stakes checkpoint quiz (CP) on Moodle.\nEXPECTATIONS: Pass 13+ of the 16 CPs (pass ~80%); OR earn at least 80% of total points across all CPs.\nPOLICIES:\n\nCPs are due 10 minutes before class on the assigned date. There are no extensions for CPs. They’re important preparation for the relevant class session.\nYou will make mistakes and that’s ok!\n\nYou can reattempt most CP questions with a 33% penalty for each incorrect response. Exceptions are open-ended questions or multiple choice questions with only 2 options (TRUE/FALSE).\nCPs are graded pass / fail. To pass, you must earn at least 80% of the points.\nThe goal is to pass 13+ CPs. Thus you might miss or not pass 3 CPs without it impacting your grade.\n\n\n\n\n\nIn 8 practice problem sets (PP), you will practice and explore the course material in more depth. The following flexibility is built in to help reduce stress and to facilitate deeper learning. Detailed directions and policies are here.\n\nGrading\nYou can make some mistakes without it chipping away at your score (e.g. you will earn 5/5 points on an exercise if it’s at least 90% correct & complete).\nDropped score\nIF you submit and demonstrate clear effort on all 8 PPs, your lowest PP score will be dropped from your final grade.\nExtensions\nLimited extensions will be provided (see the assignment policy document for details).\n\n\n\n\nMore details will be provided later in the semester. Here are some basics:\n\nWe’ll start working on projects in ~week 6, with the majority of the work happening later in the semester.\nProject groups will be (semi-)assigned by me. Before the projects start, I will send out a survey to gauge your preferences (either for project members or topical interests) and do my best to assign groups that honor those preferences. So it’s in your best interest to meet other students that you might want to work with!\nProject grades will be based upon a final group written report (no oral presentation), multiple group and individual checkpoints, and individual contributions to the project (thus it’s possible for different group members to earn different grades).\n\nMore generally, collaboration improves higher-level thinking, confidence, communication, community, & more. You will work in groups in and outside class. These groups will occasionally switch & will often be assigned.\nExpectations:\n\nFollow the MSCS Community Guidelines.\nIn group settings, both in and outside class, you:\n\nactively contribute to discussions\nactively include all other group members in discussion\ncreate a space where others feel comfortable making mistakes & sharing their ideas\neffectively communicate with your project group about meeting times, etc.\n\n\n\n\n\nYour course engagement, preparation, practice, and application will support your deeper understanding of the course material. This will be assessed through three quizzes. These are in-person quizzes. You must schedule all travel etc. around them – there will not be any alternative quiz times (with the exception of college-authorized absences for college-sponsored activities):\n\nQuiz 1: Thursday, September 25. 1 hour in class.\nQuiz 2: Thursday, October 30. 1 hour in class.\nQuiz 3: Tuesday, 12/16 from 10:30am-12:30pm (Finals Week)\n The final quiz will be written to take ~1.25 hours, but you will have the full 2-hour period to complete it.\n\nQuiz policies:\n\nAll quizzes will have the following format:\n\ntaken individually, using pen/pencil & paper\nyou will not need to write code, but you will need to read & interpret R output\nyou cannot use and will not need to use a calculator\nclosed notes, but you can use a 3x5 index card with writing on both sides. These can be handwritten or typed, but you may not include screenshots or share note cards – making your own card is important to the review process. You are required to hand this in with your quiz.\n\nQuizzes 2 & 3 will be cumulative. This is unavoidable as the material builds upon itself.\nThere will be limited opportunities for revision:\n\nYou can earn up to 50% of missed points back on Quizzes 1 & 2 if you:\n\nWrite corrections for any exercise on which you missed points. These must be on a separate sheet of paper (not your original quiz), clearly labeled, and with exercises listed in numerical order.\nOn a separate piece of paper, write a reflection: (a) how you prepared for the quiz ; (b) on what topics you felt strongest prior to the quiz; and (c) on what topics you felt most uncertain prior to the quiz.\nStaple your corrections and reflection to the back of the original quiz.\nSubmit this material to the instructor, no later than 1 week after quizzes were handed back in class.\n\n\n\nYou cannot earn back points on Quiz 3 as it occurs during finals week.\n\n\n\n\nYour course grade will be primarily determined by three evenly-weighted components (Quizzes, Practice Problems, and the Project).\n\n33% Quizzes\n33% Practice Problems\n33% Project\n\nOverall percentages on these three components will correspond to the following letter grades:\n\n\n\nLetter Grade\nOverall Course Percentage\n\n\n\n\nA\n&gt;93%\n\n\nA-\n87-93%\n\n\nB+\n84-87%\n\n\nB\n81-84%\n\n\nB-\n78-81%\n\n\nC+\n75-78%\n\n\nC\n72-75%\n\n\nC-\n69-72%\n\n\nD/NC\n&lt;69% or 7+ absences\n\n\n\nThis grade may then be modified by your progress towards the Engagement and Preparation (Checkpoint Quizzes) goals:\n\n\n\n\n\n\n\nModifier\nScenario\n\n\n\n\nnone (e.g. A → A)\nmeets expectations in both areas (Engagement & Preparation)\n\n\n1/3 lower grade (e.g., A → A-)\ndemonstrates strong progress toward expectations in both areas (e.g., 4 absences or 70% Checkpoint total)\n\n\n1 lower grade (e.g., A → B)\ndemonstrates moderate progress toward expectations in both areas (e.g., 5-6 absences or 50% Checkpoint total)\n\n\n&gt;1 lower grade\ndemonstrates little progress toward expectations in one or both areas\n\n\nDrop to D/NC\nhas 7+ absences\n\n\n\nNote: The goal of sharing this specific information is to provide transparency around final grades, hence clear goals to work toward. That said, assigning grades is much more nuanced than any grading rubric / framework might suggest (for good reasons). What’s shared here is a general scenario — it represents the minimum expectations for each grade — but I may slightly relax the cutoffs for letter grades on a case-by-case basis, depending on your overall engagement in class, utilization of office hours, demonstrated growth on quizzes, contributions to your group project, etc."
  },
  {
    "objectID": "syllabus.html#your-instructor",
    "href": "syllabus.html#your-instructor",
    "title": " ",
    "section": "",
    "text": "Jedidiah (Jed) Carlson, PhD\nPronouns: he/him\nPronunciation: listen here\nOffice: Olin-Rice 236\nWebsite: https://jedidiahcarlson.com\nEmail: jcarls13@macalester.edu\n\n\n\n\n\n\nCall me “Jed”\n\n\n\nFeel free to call me (in order of my personal preference), Jed, Professor Carlson, or Dr. Carlson–but please use whichever of these options you are most comfortable with! (note that “Professor Jed” makes me cringe)\n\n\nDrop-in (office) hours:\n\nlocation: My office (OLRI 236)\ntimes: See this calendar."
  },
  {
    "objectID": "syllabus.html#overview",
    "href": "syllabus.html#overview",
    "title": " ",
    "section": "",
    "text": "This course provides an introduction to statistical modeling. In other words, you will develop the basic skills to analyze data, test research hypotheses, and make predictions about the world.\nBeing able to summarize, interpret, and communicate about data are crucial for navigating today’s information landscape, and these are precisely the skills that we’ll build in this class. Throughout the semester, we’ll study the fundamental methods that statisticians use to extract knowledge from data, emphasizing statistical literacy & intuition, real data applications, and modern computing over memorizing facts and formulas.\n\n\nBy actively participating in this course, you will develop and/or strengthen your abilities to:\n\nVisualize: explore, understand, and describe patterns in data with plots and graphics\nModel: build, interpret, and evaluate statistical models to identify trends in data\nInfer: extend observations from sample data to draw conclusions and make predictions\nCompute: use the (free!) statistical software R to analyze real data and create reproducible reports\nContextualize: interpret results in context, by considering the methods of data collection, the scientific and social contexts, and ethical dimensions\nCommunicate: accurately describe methods and results in a way that is scientifically sound and widely accessible\nCollaborate: work productively and effectively in a group setting\n\n\n\n\nWhen taking a new course, figuring out the right workflow/cadence of effort throughout the week can be a big adjustment. And most of you are doing this for 4 different courses! Below are some suggestions for what to expect in the course and how to focus your time and attention during and outside of class.\n\n\nPlan Ahead\nIn a typical week, plan to spend 8-10 hours on STAT 155 (or any 4-credit course), including class time.\n\nIf you are working far more or far less than 8 hours per week, let me know.\nCarve out dedicated time on your calendar for intentionally studying/reviewing and doing homework.\nStay up-to-date on the course calendar.\n\n\n\n\nDo the things\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\nAttend class and actively engage in class\nWork with your classmates; ask each other questions; share your ideas\nComplete the in-class activities (this might mean completing it outside of class, if you didn’t finish)\n\n\n\n\n\n\n\nSuggestion\n\n\n\nReview your learning process and group work reflections just before class to frame how you want to engage in class. (Perhaps you’ve noted a struggle and want to try a new strategy.)\n\n\n\n\n\nReflect\nMake sure to take the time to finish the activity and review the solutions. I will have a checkpoint on Moodle for most days to draw attention to important concepts covered in the previous class.\nReview\nMost class periods will involve working with a new tool and computational concept. Rewrite / organize your notes. Summarize concepts in your own words.\nBe Curious\nDon’t be afraid to ask questions. These are opportunities to learn and dig deeper. You get out what you put into a course.\n\n\n\n\n\n\nSuggestion\n\n\n\n\nOpen the checkpoint on Moodle as you review the material. Jot down questions or ideas that you have about topics in the material.\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to immediately attempt the related exercises on the upcoming homework assignment.\nCome to instructor office drop-in hours to chat about the course or anything else! 😃"
  },
  {
    "objectID": "syllabus.html#resources-and-communication",
    "href": "syllabus.html#resources-and-communication",
    "title": " ",
    "section": "",
    "text": "There is no required textbook for this course—there will occasionally be some readings assigned from the 155 Course Notes or other sources. All links and materials needed will be provided on the Schedule tab of this website.\nThe best resources for this course are course content videos, attending and participating in class / assignments, and office hours. I am happy to talk about possible additional materials / strategies for effective learning at any time throughout the semester!\n\n\n\nWe will use the (completely free and open source) R programming language extensively throughout this course. RStudio (an interface for R) will facilitate our use of R. You may use RStudio in one of two ways:\n\nDesktop version: Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nOnline: Go to https://rstudio.macalester.edu, and log in with your full Mac email address and your usual Mac password to get access. (Note that this is a shared resource across MSCS, and you may experience performance issues due to high traffic, server outages, etc.)\n\nMore detailed instructions on downloading, installing, and getting started with R, RStudio, and an important package called Quarto is available on the Tech Setup tab.\n\n\n\nYour peers in the class are an underappreciated resource for learning the material and helping you stay on top of deadlines, course policies, etc. I strongly encourage you to connect with one another, in the form of a weekly study group, WhatsApp chat, etc.\n\n\n\nAll course materials will be posted on the course website. The Schedule tab of this website will be updated regularly with information about due dates, in-class activities, etc.\n\n\n\nMoodle will be used to submit assignments/checkpoint quizzes, post grades, assignment feedback, announcements, and more. Please check the course Moodle page every day before class!\n\n\n\nWe have many preceptors for this course! You may attend office hours for any of the STAT 155 preceptors, not just those grading/attending my sections. All MSCS courses will also share a dedicated R preceptor who can help with any issues you have with your R code or RStudio configuration. The course Moodle site contains detailed information and a Google Calendar link for preceptor office hour times/locations.\nThe role of an MSCS preceptor is to help students with content questions, assist in the navigation of available resources, advise on studying approaches for classes, and assist with concepts, tools, and skills needed for problem sets. However, students are accountable for their own learning; as such, preceptors are not allowed to share answers to assignments (unless specifically directed by the instructor), are not expected to immediately know the right approach, or provide assistance outside of office hours. Guidelines and expectations on how to interact with preceptors can be found here.\n\n\n\nOffice hours are an open-ended time for you to go over coursework, clarify concepts, solicit my biased opinions sage wisdom on career planning/graduate school, discuss research/internship opportunities, connect you with resources you need, or chat about life in general.\nOffice hours are oriented around group discussion. They are not first come, first served appointments, nor are they a place to sit and work on your assignments until you have questions. Please be respectful of your peers and do not monopolize the time.\n\n\n\nIf you’re not finding the answer you’re looking for using any of the resources above, or if you wish to discuss a private matter (e.g., attendance, grades, accommodations, etc.) please contact me via email. Please put “STAT 155” in the subject line of all emails to me, to help ensure that it does not get lost in my inbox!\nI will generally not respond to emails outside of business hours (9am-5pm M-F). Please allow 1 business day for a response (e.g. an email sent on Friday may not get a response until the following Monday).\nAny urgent announcements (e.g. unexpected class cancellations, notice of modifications to assignments) will be made over email."
  },
  {
    "objectID": "syllabus.html#grading-and-feedback",
    "href": "syllabus.html#grading-and-feedback",
    "title": " ",
    "section": "",
    "text": "The grading system in this course is designed to help you achieve the learning objectives while allowing space to make and learn from mistakes along the way. Your final letter grade will be determined by your progress towards five core course components:\n\n\nEngagement and commitment to growth are foundational to your own learning & to fostering a supportive learning community. So that we can share clear and consistent information about meeting these expectations, information about attendance and engagement will be recorded in the “In-class engagement” activity on Moodle.\nEXPECTATIONS:\n\nIn class:\n\nDo not miss &gt;3 in-person class sessions. (4-6 absences will lower your grade. 7+ absences will result in a D/NC.)\nBe on time & don’t leave early\nDo not use your phone (they must be put away when you enter class, even if class hasn’t started)\nDo not use your laptop for anything other than taking notes or working on the in-class activity. I recommend using a different browser window rather than opening up a new tab alongside the rest of your personal/school stuff.\nBe actively present. Don’t work alone, work on other courses, or work on practice problems for this course without explicit permission\n\nOutside class:\n\nstay updated on announcements (typically via email), deadlines, Moodle\nVisit my office hours at least 2 times during the semester (once before fall break and once after), and at least 2 of the preceptors’ office hours\n\n\n\n\n\nRoughly half of our class sessions will require some prep work to build a common foundation and maximize our time together (just like assigned reading & reflection in a humanities class!). Before these classes, you will watch short videos and/or read sections of the online textbook which introduce new concepts, then take a low-stakes checkpoint quiz (CP) on Moodle.\nEXPECTATIONS: Pass 13+ of the 16 CPs (pass ~80%); OR earn at least 80% of total points across all CPs.\nPOLICIES:\n\nCPs are due 10 minutes before class on the assigned date. There are no extensions for CPs. They’re important preparation for the relevant class session.\nYou will make mistakes and that’s ok!\n\nYou can reattempt most CP questions with a 33% penalty for each incorrect response. Exceptions are open-ended questions or multiple choice questions with only 2 options (TRUE/FALSE).\nCPs are graded pass / fail. To pass, you must earn at least 80% of the points.\nThe goal is to pass 13+ CPs. Thus you might miss or not pass 3 CPs without it impacting your grade.\n\n\n\n\n\nIn 8 practice problem sets (PP), you will practice and explore the course material in more depth. The following flexibility is built in to help reduce stress and to facilitate deeper learning. Detailed directions and policies are here.\n\nGrading\nYou can make some mistakes without it chipping away at your score (e.g. you will earn 5/5 points on an exercise if it’s at least 90% correct & complete).\nDropped score\nIF you submit and demonstrate clear effort on all 8 PPs, your lowest PP score will be dropped from your final grade.\nExtensions\nLimited extensions will be provided (see the assignment policy document for details).\n\n\n\n\nMore details will be provided later in the semester. Here are some basics:\n\nWe’ll start working on projects in ~week 6, with the majority of the work happening later in the semester.\nProject groups will be (semi-)assigned by me. Before the projects start, I will send out a survey to gauge your preferences (either for project members or topical interests) and do my best to assign groups that honor those preferences. So it’s in your best interest to meet other students that you might want to work with!\nProject grades will be based upon a final group written report (no oral presentation), multiple group and individual checkpoints, and individual contributions to the project (thus it’s possible for different group members to earn different grades).\n\nMore generally, collaboration improves higher-level thinking, confidence, communication, community, & more. You will work in groups in and outside class. These groups will occasionally switch & will often be assigned.\nExpectations:\n\nFollow the MSCS Community Guidelines.\nIn group settings, both in and outside class, you:\n\nactively contribute to discussions\nactively include all other group members in discussion\ncreate a space where others feel comfortable making mistakes & sharing their ideas\neffectively communicate with your project group about meeting times, etc.\n\n\n\n\n\nYour course engagement, preparation, practice, and application will support your deeper understanding of the course material. This will be assessed through three quizzes. These are in-person quizzes. You must schedule all travel etc. around them – there will not be any alternative quiz times (with the exception of college-authorized absences for college-sponsored activities):\n\nQuiz 1: Thursday, September 25. 1 hour in class.\nQuiz 2: Thursday, October 30. 1 hour in class.\nQuiz 3: Tuesday, 12/16 from 10:30am-12:30pm (Finals Week)\n The final quiz will be written to take ~1.25 hours, but you will have the full 2-hour period to complete it.\n\nQuiz policies:\n\nAll quizzes will have the following format:\n\ntaken individually, using pen/pencil & paper\nyou will not need to write code, but you will need to read & interpret R output\nyou cannot use and will not need to use a calculator\nclosed notes, but you can use a 3x5 index card with writing on both sides. These can be handwritten or typed, but you may not include screenshots or share note cards – making your own card is important to the review process. You are required to hand this in with your quiz.\n\nQuizzes 2 & 3 will be cumulative. This is unavoidable as the material builds upon itself.\nThere will be limited opportunities for revision:\n\nYou can earn up to 50% of missed points back on Quizzes 1 & 2 if you:\n\nWrite corrections for any exercise on which you missed points. These must be on a separate sheet of paper (not your original quiz), clearly labeled, and with exercises listed in numerical order.\nOn a separate piece of paper, write a reflection: (a) how you prepared for the quiz ; (b) on what topics you felt strongest prior to the quiz; and (c) on what topics you felt most uncertain prior to the quiz.\nStaple your corrections and reflection to the back of the original quiz.\nSubmit this material to the instructor, no later than 1 week after quizzes were handed back in class.\n\n\n\nYou cannot earn back points on Quiz 3 as it occurs during finals week."
  },
  {
    "objectID": "syllabus.html#grading-system",
    "href": "syllabus.html#grading-system",
    "title": " ",
    "section": "",
    "text": "Your course grade will be primarily determined by three evenly-weighted components (Quizzes, Practice Problems, and the Project).\n\n33% Quizzes\n33% Practice Problems\n33% Project\n\nOverall percentages on these three components will correspond to the following letter grades:\n\n\n\nLetter Grade\nOverall Course Percentage\n\n\n\n\nA\n&gt;93%\n\n\nA-\n87-93%\n\n\nB+\n84-87%\n\n\nB\n81-84%\n\n\nB-\n78-81%\n\n\nC+\n75-78%\n\n\nC\n72-75%\n\n\nC-\n69-72%\n\n\nD/NC\n&lt;69% or 7+ absences\n\n\n\nThis grade may then be modified by your progress towards the Engagement and Preparation (Checkpoint Quizzes) goals:\n\n\n\n\n\n\n\nModifier\nScenario\n\n\n\n\nnone (e.g. A → A)\nmeets expectations in both areas (Engagement & Preparation)\n\n\n1/3 lower grade (e.g., A → A-)\ndemonstrates strong progress toward expectations in both areas (e.g., 4 absences or 70% Checkpoint total)\n\n\n1 lower grade (e.g., A → B)\ndemonstrates moderate progress toward expectations in both areas (e.g., 5-6 absences or 50% Checkpoint total)\n\n\n&gt;1 lower grade\ndemonstrates little progress toward expectations in one or both areas\n\n\nDrop to D/NC\nhas 7+ absences\n\n\n\nNote: The goal of sharing this specific information is to provide transparency around final grades, hence clear goals to work toward. That said, assigning grades is much more nuanced than any grading rubric / framework might suggest (for good reasons). What’s shared here is a general scenario — it represents the minimum expectations for each grade — but I may slightly relax the cutoffs for letter grades on a case-by-case basis, depending on your overall engagement in class, utilization of office hours, demonstrated growth on quizzes, contributions to your group project, etc."
  },
  {
    "objectID": "syllabus.html#religious-observance",
    "href": "syllabus.html#religious-observance",
    "title": " ",
    "section": "Religious Observance",
    "text": "Religious Observance\nIf you have a religious observance/practice that conflicts with your participation in the course, please contact me before the end of the second week of the semester to discuss appropriate accommodations."
  },
  {
    "objectID": "syllabus.html#academic-integrity",
    "href": "syllabus.html#academic-integrity",
    "title": " ",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to strictly abide by the college’s standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus.html#artificial-intelligence-ai-use",
    "href": "syllabus.html#artificial-intelligence-ai-use",
    "title": " ",
    "section": "Artificial Intelligence (AI) Use",
    "text": "Artificial Intelligence (AI) Use\nIn this course, I strongly discourage the use of so-called AI tools (ChatGPT, Google Gemini, Claude, Grok, etc.) for any work done in or outside of class, for two major pedagogical reasons (in addition to numerous ethical/technical concerns that we can discuss in class).\n\nLearning is an innately social act. If you rely on LLMs for answering questions and overcoming obstacles related to the course, you severely limit your (and others’!) opportunities for building community and a shared intellectual life. *ChatGPT also NEVER has donuts available when you ask it a question, whereas my office hours SOMETIMES do.\nMy goal as a professor (and part of Macalester’s Statement of Purpose), is to train you become “adept at critical, analytical and logical thinking.” Sidestepping that process of intellectual development by outsourcing your thinking to so-called AI is no different than trying to learn how to make coffee by drinking convenience store espresso, or “solving” a Sudoku puzzle by feeding it to a brute-force search algorithm. While AI may provide a quick shortcut to correct answers on a homework assignment, there are no shortcuts in actual learning.\n\nPlease note that my discouraging of these tools is not an outright ban (partly because I do not want to inadvertently incentivize you to use AI in ways that violate Macalester’s academic integrity policy, and partly because I have no interest in investing the time and effort to police it). Instead, I ask that you simply be honest and transparent about if/how/when you use these tools, with no penalty to your grade. This not only maintains a standard of integrity and gives me insight into how you learn, but also provides me with valuable information that we can use to improve the course content (e.g., if several students felt like they needed to use ChatGPT to answer a homework question, it was probably a poorly written question!).\n\nTo this end, on each homework assignment, there will be a Disclosures and Citations section where I ask you to briefly describe any outside help you sought while completing it, including Office Hours, study groups, AI use, etc."
  },
  {
    "objectID": "syllabus.html#well-being",
    "href": "syllabus.html#well-being",
    "title": " ",
    "section": "Well-being",
    "text": "Well-being\nI want you to succeed. Both here at Macalester and beyond. To help make this happen, I am committed to the following.\nRespect: Everyone comes from a different path through life, and it is our moral duty as human beings to listen to each other without judgment and to respect one another. I have no tolerance for discrimination of any kind, in and out of the classroom. If you are seeking campus resources regarding discrimination, the Department of Multicultural Life and the Center for Religious and Spiritual Life are wonderful resources. We will also respect the MSCS Community Guidelines.\nSensitive Topics: Applications in this course span issues in science, policy, and society. As such, the material may sometimes broach sensitive topics. I will try to announce in class if an assignment or activity involves a potentially sensitive topic. If you have reservations about a particular topic, please come talk to me to discuss possible options.\nAccommodations: If you need accommodations for any reason, please contact Disability Services to discuss your needs, and speak with me as soon as possible afterwards so that we can discuss your accommodation plan. If you already have official accommodations, please discuss these with me within the first week of class so that you get off to a great start. Contact me if you have other special circumstances. I will find resources for you.\nTitle IX: You deserve a community free from discrimination, sexual harassment, hostility, sexual assault, domestic violence, dating violence, and stalking. If you or anyone you know has experienced harassment or discrimination, know that you are not alone. Macalester provides staff and resources to help you find support. Please be aware that as a faculty member, it is my responsibility to report disclosure about sexual harassment, sexual misconduct, relationship violence, and stalking to the Title IX Office. The purpose of this report is to ensure that anyone experiencing harm receives the resources and support they need. I will keep this information private, and it will not be shared beyond this required report.\nYou may also contact Macalester’s Title IX Coordinator directly (phone: 651-696-6258; e-mail: titleixcordinator@macalester.edu); they will provide you with supportive measures, resources, and referrals. Additional information about how to file a report (including anonymously) is available on the Title IX website.\nOther resources:\n\nfind help\nThis go-to page includes links to student resources, housing and food resources, academic support, and financial resources. Included:\n\nEmergency aid fund for students experiencing unexpected financial hardship.\nReporting incidents of harassment, bias, & discrimination.\n\nmental health & wellness–The Hamre Center can provide or connect you to ongoing, urgent, emergency, and telehealth care."
  },
  {
    "objectID": "syllabus.html#you-belong-here",
    "href": "syllabus.html#you-belong-here",
    "title": " ",
    "section": "You belong here!",
    "text": "You belong here!\nStatistics and data science have a long history of excluding and exploiting people from marginalized communities and identities. Many of the earliest statisticians in the 19th and 20th centuries used and abused statistics to justify colonialism, ableism, classism, sexism, eugenics, and white supremacy.\nOn top of this problematic history, cultural norms around academic performance in quantitative disciplines can make courses like this one feel intimidating and exclusionary, rather than collaborative and interdisciplinary.\nTo counter these barriers, my central goal as an instructor is to intentionally foster community and connectedness. I believe that your unique voices and perspectives in this class will enrich our collective learning process and, in turn, your college experience. I encourage you to get to know your classmates (and me!) beyond a superficial familiarity and connect over our shared interests, identities, and ideas. You can help cultivate that community by being thoughtful about the way you engage with others and stretching your comfort zone to interact with people who are outside of your established social circles."
  },
  {
    "objectID": "syllabus.html#informed-skepticism",
    "href": "syllabus.html#informed-skepticism",
    "title": " ",
    "section": "Informed skepticism",
    "text": "Informed skepticism\nIn virtually all of contemporary Western science, data analysis and statistical reasoning are crucial cogs in how knowledge is generated. However, it is shockingly common to encounter “data-driven” conclusions that are 1) not generalizable or cannot be replicated, 2) invalidated by honest coding/modeling mistakes, 3) based on deliberately cherry-picked models, or–in extreme cases–4) data that have been outright fabricated/falsified. Like in all aspects of life, trust in scientific claims must be earned.\nIn this course and beyond, I encourage you to approach any statistical results or data summaries you encounter with a healthy skepticism, informed by both your gut intuition and the material you’ve learned. Know that you may be wrong (counter-intuitive results are abundant!) but you should always feel empowered to respectfully and rigorously challenge statistical claims."
  },
  {
    "objectID": "syllabus.html#a-commitment-to-ethical-deliberation-and-conduct",
    "href": "syllabus.html#a-commitment-to-ethical-deliberation-and-conduct",
    "title": " ",
    "section": "A commitment to ethical deliberation and conduct",
    "text": "A commitment to ethical deliberation and conduct\nBecause statistics and data science are a way to make sense of the world around us, it is also a way to influence it. This comes with an inherent responsibility to grapple with the ethical and sociopolitical dimensions of the content in this course. This includes delving into the context of how methods were developed, questioning assumptions, and considering the potential for misuse and misinterpretation. Throughout the course, you will be challenged to consider the broader impact of your work: How might your results and interpretations directly or indirectly affect the environment, specific individuals, or human culture & society? Whose prior scientific contributions are you amplifying or ignoring? How do your assumptions and biases shape your scientific approach and communication?"
  },
  {
    "objectID": "syllabus.html#mistakes-and-uncertainty-are-essential",
    "href": "syllabus.html#mistakes-and-uncertainty-are-essential",
    "title": " ",
    "section": "Mistakes and uncertainty are essential",
    "text": "Mistakes and uncertainty are essential\nI expect that you and I will make lots of mistakes along the way in this course. Perhaps paradoxically, this is an important way to gain confidence: as we make mistakes, we will develop skills for recognizing and correcting them. These skills are vital for succeeding in STEM careers (and life in general). This course will provide a low-stakes environment for us to practice accountability, reflection, and troubleshooting when mistakes occur."
  },
  {
    "objectID": "syllabus.html#context-before-content",
    "href": "syllabus.html#context-before-content",
    "title": " ",
    "section": "Context before content",
    "text": "Context before content\nRigorous statistical reasoning and data science demands that we understand the context of our data and our research questions before we run a model and obtain/interpret results. I also aim to be mindful of various other contexts that shape our learning experience: our individual identities/histories, the classroom environment, the campus climate, etc. Throughout the semester, we will create space to address and discuss whatever contexts might impact our ability to engage the material (and how they may even relate to the material!)."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "As noted in the syllabus, a detailed description of the group project can be found here. Important dates and additional information are listed below.\n\nImportant Dates\n\nFriday, February 28: Project Checkpoint 1 Due\nFriday, April 11: Project Checkpoint 2 Due\nLast day of class: Final Draft Due\n\n\n\nGrading\nThe final draft will be graded using the rubric found here. Although the first two checkpoints will not directly contribute to your course grade, the feedback they allow me to provide will ensure the success of your final draft!\n\n\nResources\nLater in the semester, I will post at least one example of a successful final draft, as well as a google doc template for the final draft.\n\n\nProject Groups\nProject groups will ultimately be determined by me, with the assistance of a Project Group Preferences survey. The survey will be sent out early in the semester (exact date TBD) and will allow you to either list people you would like to be in a group with or specify that you would like to be placed in a group randomly by me. I will do my best to ensure that groups are constructed as closely to survey responses as possible. Since one component of the project involves an in-class presentation, you may not work with students in different sections on the project.\nIf for any reason there is an individual (or individuals) with whom you do not feel safe participating in a project group with, there will be a space to note this on the survey. You will not be expected to provide any justification for your response to this question, but note that as I need to place you in groups, the survey will not be anonymous.\nGroup work and collaboration are important components of nearly all statistical analyses and projects. I recognize that individual contributions to a group project are not always consistent between group members. To this end, you will (as a group) be expected to explicitly specify the project tasks completed by each team member along with the final draft of your paper.\nIf there are any concerns with project groups throughout the semester, I am happy to meet with groups or individuals to discuss ways to move forward."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Practice Problems",
    "section": "",
    "text": "Please review the Practice Problems Policies document!\n\nPractice Problems 1, due 9/12"
  },
  {
    "objectID": "activities/99-appendix.html",
    "href": "activities/99-appendix.html",
    "title": "Installing R and RStudio",
    "section": "",
    "text": "Installing R and RStudio\n\n\n\nYou’re strongly encouraged to install R & RStudio on the laptop that you plan to bring to class.\nFollow these two steps in the given order. (For those that already have R and RStudio: if your versions are more than 6 months old, they might not be compatible with the course material. You might either update now or on the fly, if necessary.)\n\nDownload & install R\n\nGo to https://mirror.las.iastate.edu/CRAN/\nClick the appropriate “Download R for…” link, depending upon your operating system (e.g. Windows, macOS, Linux). Then follow the instructions there to download R.\nIf you are using a Mac: Check to see if you have an Intel or Apple Silicon Processor Chip (Apple logo &gt; About this Mac). This will impact the version you download.\n\nDownload & install RStudio\n\nGo to https://posit.co/download/rstudio-desktop/.\nUnder Step 2:\n\nIf the website automatically detects your operating system, there will be a “Download RStudio Desktop For …” button. Click on this to install RStudio.\nOtherwise, there will be a list of operating systems. Click on the “RSTUDIO-…” link under your operating system to install RStudio.\n\nIf you are using a Mac: Once you download the dmg file and click on it, drag the RStudio icon to Applications. Then open Finder and click the eject icon next to the RStudio temporary drive under Locations.\n\n\n\n\nAlternatively, if you don’t plan to use RStudio after this course or are having trouble installing the software, you can use Mac’s RStudio server at rstudio.macalester.edu. Please note that if you go this route, you will need to meet with the instructor to discuss file management specific to the server."
  },
  {
    "objectID": "activities/ACTIVITY_TEMPLATE.html",
    "href": "activities/ACTIVITY_TEMPLATE.html",
    "title": "LESSON TITLE (e.g., Univariate summaries and visualization)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nLearning goal 1\nLearning goal 2\n\nLinks to required video(s) / reading(s):\n\nLink 1\nLink 2"
  },
  {
    "objectID": "activities/ACTIVITY_TEMPLATE.html#exercise-1",
    "href": "activities/ACTIVITY_TEMPLATE.html#exercise-1",
    "title": "LESSON TITLE (e.g., Univariate summaries and visualization)",
    "section": "Exercise 1",
    "text": "Exercise 1\nText"
  },
  {
    "objectID": "activities/ACTIVITY_TEMPLATE.html#exercise-2",
    "href": "activities/ACTIVITY_TEMPLATE.html#exercise-2",
    "title": "LESSON TITLE (e.g., Univariate summaries and visualization)",
    "section": "Exercise 2",
    "text": "Exercise 2\nText"
  },
  {
    "objectID": "activities/ACTIVITY_TEMPLATE.html#reflection",
    "href": "activities/ACTIVITY_TEMPLATE.html#reflection",
    "title": "LESSON TITLE (e.g., Univariate summaries and visualization)",
    "section": "Reflection",
    "text": "Reflection\nPrompts\n\nResponse: Students can type responses here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "",
    "text": "STAT 155: Introduction to Statistical Modeling\nMacalester College, Fall 2025\n\nLearn the fundamentals of summarizing, visualizing, and modeling data to answer research questions.\n\n\nInstructor: Jedidiah Carlson  Class meeting times:\n\nSection 05: Tu/Th 9:40-11:10am\n\nClass location: THTR 202 \nJed’s drop-in hours:\n\nlocation: My office (OLRI 236)\ntimes: See this calendar.\n\n\nR/RStudio Preceptor Office Hours: Available on the MSCS Events google calendar (not to be used for questions about course content, only R-related things!)\nSTAT 155 Preceptor Office Hours: There is a link to a Google Calendar containing all preceptor office hours available at the top of the course Moodle page!\n\nThis course website will be updated throughout the semester with new activities, assignments, and announcements, so please bookmark this page if you are enrolled in the course!\nIf you find any typos, bugs, dead links, or have other questions, please email jcarls13@macalester.edu"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "This page is the first place you’ll want to visit at the beginning of each class. The Topic column will contain a link to today’s activity (to follow along on the screen), and the .qmd template column contains a link to download a .qmd file where you can work on the exercises.\n\nDetails for the current week will be filled in throughout the semester. Any urgent announcements will be made over email.\nProject-related due dates are not yet in the schedule.\nDetails are subject to change (with plenty of advance warning).\nUnless specified otherwise:\n\nMoodle Checkpoints (CPs) are due 10 minutes before class.\nPractice problems (PPs) are due on Moodle by 11:59pm on the due date.\n\n\n\n\n\nDate\nTopic\n.qmd template\nDue\n\n\nUnit 1: Simple Linear Regression\n\n\n\n\n\n9/2\nWelcome\n01-foundations-welcome-notes.qmd\nBefore class:\n\nReview the course syllabus\nFamiliarize yourself with Moodle and the course website\nComplete the Introductions survey\nDownload R and RStudio\n\n\n\n9/4\nUnivariate visual & numerical summaries\n02-foundations-univariate-notes.qmd\nCP 1\n\n\n9/9\nSimple linear regression\n\nCP 2\n\n\n9/11\nModel evaluation\n\nPP 1, CP 3\n\n\n9/16\nTransformations\n\nCP 4\n\n\n9/18\nCategorical predictors\n\nPP 2, CP 5\n\n\nUnit 2: Multiple Linear Regression\n\n\n\n\n\n9/23\nMultiple linear regression discovery day\n\n\n\n\n9/25\nQuiz 1\n\n\n\n\n9/30\nModeling principles\n\nCP 6\n\n\n10/2\nConfounding\n\nPP 3, CP 7\n\n\n10/7\nInteraction\n\nCP 8\n\n\n10/9\nReview + project time\n\n\n\n\n10/14\nModel building\n\nPP 4, CP 9\n\n\n10/16\nFall break (no class!)\n\n\n\n\nUnit 3: Logistic Regression\n\n\n\n\n\n10/21\nLogistic regression I\n\nCP 10\n\n\n10/23\nLogistic regression II\n\nCP 11\n\n\n10/28\nReview + project time\n\nPP 5\n\n\n10/30\nQuiz 2\n\n\n\n\nUnit 4: Inference\n\n\n\n\n\n11/4\nTools for inference\n\nCP 12\n\n\n11/6\nSampling distributions + CLT\n\nCP 13\n\n\n11/11\nConfidence intervals\n\nCP 14\n\n\n11/13\nTowards hypothesis testing\n\nPP 6\n\n\n11/18\nHypothesis tests for 1 coefficient\n\nCP 15\n\n\n11/20\nConsiderations in hypothesis testing\n\nPP 7\n\n\n11/25\nF tests\n\nCP 16\n\n\n11/27\nThanksgiving break\n\n\n\n\n12/2\nP-values + project time\n\n\n\n\n12/4\nProject time\n\nPP 8\n\n\n12/9\nProject time\n\n\n\n\n12/16 (10:30am-12:30pm)\nQuiz 3\n\n\n\n\n\n\n\n\nDate\nTopic\nDue\n\n\n\n\n9/2\nWelcome!\nBefore class:\n\nReview the course syllabus\nFamiliarize yourself with Moodle and the course website\nComplete the Introductions survey\nDownload R and RStudio"
  },
  {
    "objectID": "tech_setup.html",
    "href": "tech_setup.html",
    "title": "Tech Setup",
    "section": "",
    "text": "Follow these instructions to set up the software that we’ll be using throughout the semester. Even if you’ve already downloaded both R and RStudio for past classes/projects, you’ll want to update your software to the most current versions.\n\nRequired: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\nRequired: Download R and RStudio.\n\nFIRST: Download R here.\n\nIn the top section, you will see three links “Download R for …”\nChoose the link that corresponds to your computer.\nAs of August 27, 2024, the latest version of R is 4.5.1.\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\nAs of August 27, 2024, the latest version of RStudio is 2025.05.1+513.\n\n\n\nSuggested: Watch this video describing key configuration options for RStudio.\n\nRequired: Install required packages.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\"))\n\n\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(tidyverse) and hit Enter.\nIf you see an error message, then there was a problem installing the package. Talk to the instructor or a preceptor for help.\nQuit RStudio. You’re done setting up!\n\n\nOptional: For a tour of RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio.\n\nRequired: Set essential RStudio options.\nGo to Tools -&gt; Global Options -&gt; General -&gt; Workplace. You’ll see 2 options:\n\nRestore .RData into workspace at startup: Leave this unchecked\nSave workspace to .RData on exit: Select “Never”\n\nWithout doing this RStudio will save and reload everything that you’ve been working on from the start of the semester. Since we’ll be working with new data each class, we want to keep our digital environment clean. Essentially, this is like an artist getting a clean canvas for each new painting rather than trying to paint all paintings on a single canvas."
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#learning-goals",
    "href": "activities/L24-hypothesis-testing-considerations.html#learning-goals",
    "title": "Hypothesis testing: additional considerations",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nDifferentiate between more and less accurate interpretations of p-values\nExplain how different factors affect statistical power\nExplain the difference between practical and statistical significance\nExplain how multiple testing impacts the conduct and interpretation of statistical research"
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#readings-and-videos",
    "href": "activities/L24-hypothesis-testing-considerations.html#readings-and-videos",
    "title": "Hypothesis testing: additional considerations",
    "section": "Readings and videos",
    "text": "Readings and videos\nNo new readings or videos for today."
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#exercise-1-conceptual-understanding",
    "href": "activities/L24-hypothesis-testing-considerations.html#exercise-1-conceptual-understanding",
    "title": "Hypothesis testing: additional considerations",
    "section": "Exercise 1: Conceptual understanding",
    "text": "Exercise 1: Conceptual understanding\n\nSuppose that you and a friend are in two different sections (each with the same number of students) of the same class. On your respective midterm exams, you each obtained 85%, and the class average in both of your classes was 80%. Could one of you or your friend still be considered further above the class average than the other? Briefly explain.\nNow suppose that your section’s test scores were more tightly packed around 80%: maybe the standard deviation of your section’s scores was 2.5, whereas the standard deviation of your friend’s section’s scores was 5. Which of you or your friend was further above the class average? Explain/justify your answer.\nBroadly speaking, does a p-value measure the chance of a hypothesis being true, or, the chance of the data having occurred?\nWhy can’t a p-value measure the other quantity that you didn’t choose in Part c?\nExplain in words why, in calculating a p-value, we need to assume that the null hypothesis is true.\nSuppose that a hypothesis test yields a p-value of 1e-6 (\\(1\\times 10^{-6}\\)). What can you tell about the magnitude of the effect or the uncertainty of the effect from this p-value? (i.e., What can you tell about the coefficient estimate or the standard error?)"
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#exercise-2-statistical-vs.-practical-significance",
    "href": "activities/L24-hypothesis-testing-considerations.html#exercise-2-statistical-vs.-practical-significance",
    "title": "Hypothesis testing: additional considerations",
    "section": "Exercise 2: Statistical vs. practical significance",
    "text": "Exercise 2: Statistical vs. practical significance\nMusic researchers compiled information on 16,216 Spotify songs. They looked at the relationship between a song’s genre (latin vs. not latin) and song duration in seconds. Their modeling code and output is below:\nspotify_model &lt;- lm(duration ~ latin_genre, data = spotify)\ncoef(summary(spotify_model))\n##                   Estimate Std. Error   t value   Pr(&gt;|t|)\n## (Intercept)     212.673908  0.4165491 510.56143 0.00000000\n## latin_genreTRUE   1.555355  0.7435700   2.09174 0.03647731\n\nInterpret the latin_genreTRUE coefficient.\nIn the context of song listening, is this a large or small effect size?\nReport and interpret the p-value for the latin_genreTRUE coefficient.\nUse the p-value to make a yes/no decision about the evidence for a relationship between genre and song duration.\nThis exercise highlights the difference between statistical significance and practical significance—explain how. That is, when might we observe statistically significant results that aren’t practically significant?"
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#exercise-3-power",
    "href": "activities/L24-hypothesis-testing-considerations.html#exercise-3-power",
    "title": "Hypothesis testing: additional considerations",
    "section": "Exercise 3: Power",
    "text": "Exercise 3: Power\nStatistical power is the probability of rejecting the null hypothesis when the alternative hypothesis is true. We are frequently testing hypotheses to investigate differences or relationships, so in this context, statistical power is the probability of detecting a relationship when there truly is a relationship.\nNavigate to this page to look at an interactive visualization of the factors that influence statistical power.\nUnder “Settings”, next to the “Solve for?” text, click “Power”. You will vary the 3 different parameters (significance level, sample size, and effect size) one at a time to understand how these factors affect power.\nSome context behind this interactive visualization:\n\nVisualization is based on a one sample Z-test:\nThis is a test for whether the true population mean equals a particular value. (e.g., true mean = 30)\nThe effect size slider is measured with a metric called Cohen’s d:\n\nCohen’s d = magnitude of effect/standard deviation of response variable\nHere: how far is the true mean from the null value in units of SD?\ne.g., If the null value is 30, true mean is 40, and the true population SD of the quantity is 5, the Cohen’s d effect size is (40-30)/5 = 2.\n\n\n\nWhat is your intuition about how changing the significance level will change power? Check your intuition with the visualization and explain why this happens.\nRepeat Part a for the sample size.\nRepeat Part a for the effect size."
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#exercise-4-ethical-considerations",
    "href": "activities/L24-hypothesis-testing-considerations.html#exercise-4-ethical-considerations",
    "title": "Hypothesis testing: additional considerations",
    "section": "Exercise 4: Ethical considerations",
    "text": "Exercise 4: Ethical considerations\n\nVisit this page and look at both the comic at the top and the various ways in which researchers have described p-values that do not fall below the \\(\\alpha = 0.05\\) significance level threshold. What ethical consideration is arising here? (Just for fun: a related xkcd comic)\nTake a look at the xkcd comic here. What ethical consideration is arising here?"
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#exercise-1-conceptual-understanding-1",
    "href": "activities/L24-hypothesis-testing-considerations.html#exercise-1-conceptual-understanding-1",
    "title": "Hypothesis testing: additional considerations",
    "section": "Exercise 1: Conceptual understanding",
    "text": "Exercise 1: Conceptual understanding\n\nSuppose that you and a friend are in two different sections (each with the same number of students) of the same class. On your respective midterm exams, you each obtained 85%, and the class average in both of your classes was 80%. Could one of you or your friend still be considered further above the class average than the other? Briefly explain.\n\n\nResponse: Yes! How well you do relative to the rest of the class depends on both the class average AND the variability of scores in each section. In this case, if your section was more variable, 85% wouldn’t be as far above the class average than in your friend’s section.\n\n\nNow suppose that your section’s test scores were more tightly packed around 80%: maybe the standard deviation of your section’s scores was 2.5, whereas the standard deviation of your friend’s section’s scores was 5. Which of you or your friend was further above the class average? Explain/justify your answer.\n\n\nResponse: In this case, we could note that your score of 85 was 2 standard deviations above the class average (85-80)/2.5 = 2, whereas your friend’s score was only one standard devation above the class average (85-80)/5 = 1. Here, your score would be considered more extreme, and therefore further above the class average than your friend’s score.\n\n\nBroadly speaking, does a p-value measure the chance of a hypothesis being true, or, the chance of the data having occurred?\nWhy can’t a p-value measure the other quantity that you didn’t choose in Part c?\n\n\nResponse: Broadly speaking, the latter is more correct. By definition, a p-value measures the probability that an observation (as or more extreme that what did observe) would occur over repeated sampling under the null hypothesis (if the null hypothesis were true). This does NOT measure the chance of a hypothesis being true, but rather, tries to make a statement about the null hypothesis through indirect means.\n\n\nExplain in words why, in calculating a p-value, we need to assume that the null hypothesis is true.\n\n\nResponse: In order to make probabilistic statements about repeatedly sampled measures (as p-values do), we need to first be able to define a probability distribution. The null hypothesis tells us where this probability distribution is centered. As a concrete example, we can’t answer questions like “what is the chance we observed this data?” without making some assumption about what the underlying truth is, or sometimes, where the truth is unlikely to be. For example, if we observe a regression coefficient of 2.3, we don’t know if this is likely or not. We can say, however, how likely it is we would observe 2.3 if the true population coefficient were 2 compared to if the true population coefficient were 0.5.\n\n\nSuppose that a hypothesis test yields a p-value of 1e-6 (\\(1\\times 10^{-6}\\)). What can you tell about the magnitude of the effect or the uncertainty of the effect from this p-value? (i.e., What can you tell about the coefficient estimate or the standard error?)\n\n\nResponse: A p-value tells us nothing about the coefficient estimate or the standard error because it only tells us about the test statistic. A small p-value only indicates that the test statistic is large. A large test statistic could have come about from a large effect (large coefficient) or from a small coefficient with a very small standard error. This is why reporting a confidence interval is more informative than only reporting a p-value. We get a sense of both the magnitude of the estimate and the amount of uncertainty with a CI, and with just a p-value, we don’t know either."
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#exercise-2-statistical-vs.-practical-significance-1",
    "href": "activities/L24-hypothesis-testing-considerations.html#exercise-2-statistical-vs.-practical-significance-1",
    "title": "Hypothesis testing: additional considerations",
    "section": "Exercise 2: Statistical vs. practical significance",
    "text": "Exercise 2: Statistical vs. practical significance\nMusic researchers compiled information on 16,216 Spotify songs. They looked at the relationship between a song’s genre (latin vs. not latin) and song duration in seconds. Their modeling code and output is below:\nspotify_model &lt;- lm(duration ~ latin_genre, data = spotify)\ncoef(summary(spotify_model))\n##                   Estimate Std. Error   t value   Pr(&gt;|t|)\n## (Intercept)     212.673908  0.4165491 510.56143 0.00000000\n## latin_genreTRUE   1.555355  0.7435700   2.09174 0.03647731\n\nInterpret the latin_genreTRUE coefficient.\n\n\nResponse: On average, latin genre songs tend to be 1.56 seconds longer than non-latin songs.\n\n\nIn the context of song listening, is this a large or small effect size?\n\n\nResponse: Seems rather small—1.56 seconds in a song is really short.\n\n\nReport and interpret the p-value for the latin_genreTRUE coefficient.\n\n\nResponse: If there were truly no difference in the duration of latin vs non-latin songs (in the broader population of songs), there’s only a 3.6% chance that we would have obtained a sample in which the observed difference was so large relative to the amount of uncertainty in the estimate (the standard error).\n\n\nUse the p-value to make a yes/no decision about the evidence for a relationship between genre and song duration.\n\n\nResponse: We do have statistically significant evidence that latin genre songs tend to be longer than non-latin songs.\n\n\nThis exercise highlights the difference between statistical significance and practical significance—explain how. That is, when might we observe statistically significant results that aren’t practically significant?\n\n\nResponse: Our large sample size of over 16,000 songs is relevant. The more data we have, the smaller our standard errors. (Recall that standard errors are inversely proportionaly to the square root of sample size: std error = \\(c/\\sqrt{n}\\), where \\(c\\) is a constant from complicated formulas.) Larger sample sizes lead to narrower CIs, larger test staistics, and smaller p-values. With large sample sizes, it is easier to find statistically significant results even when the results aren’t practically significant."
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#exercise-3-power-1",
    "href": "activities/L24-hypothesis-testing-considerations.html#exercise-3-power-1",
    "title": "Hypothesis testing: additional considerations",
    "section": "Exercise 3: Power",
    "text": "Exercise 3: Power\nOverall notes about the power investigations:\n\nBecause power is the probability of correctly rejecting the null hypothesis (rejecting the null when the alternative hypothesis is true), parameter changes that increase the frequency of rejecting the null hypothesis will increase power. Keep this in mind as you work through. Visually, power corresponds to the light blue area under the distribution on the right. The distribution on the left is our familiar sampling distribution of the test statistic (here called \\(Z_{\\text{crit}}\\)) under the null. The distribution on the right is very closely related but is the sampling distribution of the test statistics under the alternative hypothesis (which is why the \\(H_A\\) label is above it). Power corresponds to the light blue area under the \\(H_A\\) distribution because this area actually corresponds to the test statistics for which we would reject the null. The area represents the probability that we would obtain such test statistics if indeed the alternative were true. That is, the area represents the percentage of samples that would generate test statistics large enough to reject the null (if the alternative hypothesis were true).\n\nEffect of significance level:\n\nIf the significance level increases, there is a “less stringent” threshold for rejecting the null (p-value only has to be less than some higher threshold). Increasing the significance level will result in more frequent rejections of the null, and thus higher power (but at the price of a higher type 1 error rate).\n\nEffect of sample size:\n\nIf sample size increases, power should increase because higher sample size will decrease standard error, which will increase the test statistic, which more likely leads to rejecting the null.\n\nEffect of effect size:\n\nIf the magnitude of the effect (numerator of Cohen’s d) increases, power should increase because it is easier (we are more likely) to detect large effects. It is harder (we are less likely) to detect very small effects.\nIf the variability of the response variable decreases (denominator of Cohen’s d), power should increase because any “signal” from our predictors being picked up by our coefficient estimates will rise far enough above the “noise” in the small variability of the response. The variability of the response variable also contributes to the standard error for the coefficient. With low variability of the response, we will have lower standard errors because there will be lower spread in the estimates across samples. And with lower standard errors, test statistics should increase, resulting in greater frequency of rejecting the null.\nA large effect magnitude and small variability in the response result in a large effect size, and increasing effect size results in higher power."
  },
  {
    "objectID": "activities/L24-hypothesis-testing-considerations.html#exercise-4-ethical-considerations-1",
    "href": "activities/L24-hypothesis-testing-considerations.html#exercise-4-ethical-considerations-1",
    "title": "Hypothesis testing: additional considerations",
    "section": "Exercise 4: Ethical considerations",
    "text": "Exercise 4: Ethical considerations\n\nVisit this page and look at both the comic at the top and the various ways in which researchers have described p-values that do not fall below the \\(\\alpha = 0.05\\) significance level threshold. What ethical consideration is arising here? (Just for fun: a related xkcd comic)\n\n\nResponse: The comic is an illustration of something called the file drawer phenomenon. There is a culture that has arisen when using hypothesis testing in statistical analysis to only appreciate rejections of the null hypothesis as meaningful results. Any results for which investigators were not able to reject the null were filed away, never to be reported. Investigators would keep trying until their p-values were lower than the significance level.\nThere are serious ethical considerations behind this phenomenon. Who ever said that rejecting the null hypothesis was the only way to get meaningful scientific results? There is immense benefit in knowing when there are no effects / no relationships. A very important public health example of this is the relationships between vaccination and autism risk in children. Time and time again, studies have not been able to detect any causal relationship. What would our society look like if those “null” results had been filed away, never to be reported?\n\n\nTake a look at the xkcd comic here. What ethical consideration is arising here?\n\n\nResponse: The idea here is that many, many hypothesis tests are being conducted, which is an idea called multiple testing. As more and more tests are being conducted, there is a higher and higher overall chance that the null hypothesis will be rejected - because we’re just trying so many times. If the null hypothesis is in fact true, testing more and more times is going to increase the probability of making at least one type 1 error.\nIn this comic, we would likely be inclined to believe that the null hypothesis is true (no true association between jelly bean eating and acne). But the sheer number of times that this hypothesis was tested (20 times) means that the scientists ended up finding an association just by chance. That is, the association found for green jelly beans was quite likely a type 1 error. And in fact one null hypothesis rejection among 20 tests is exactly a 5% error rate - in other words, exactly the number of null hypothesis rejections we would expect to make if indeed the null were true (exactly the expected number of type 1 errors)."
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#learning-goals",
    "href": "activities/L19-sampling-dist-clt.html#learning-goals",
    "title": "Sampling distributions & the CLT",
    "section": "Learning goals",
    "text": "Learning goals\nLet \\(\\beta\\) be some population parameter and \\(\\hat{\\beta}\\) be a sample estimate of \\(\\beta\\). Our goals for the day are to:\n\nuse simulation to solidify our understanding of sampling distributions and standard errors\nexplore the appropriateness of the Central Limit Theorem in approximating a sampling distribution\nexplore the impact of sample size on sampling distributions and standard errors"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#readings-and-videos",
    "href": "activities/L19-sampling-dist-clt.html#readings-and-videos",
    "title": "Sampling distributions & the CLT",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease watch the following videos and readings before class:\n\nReading: Section 6.7 in the STAT 155 Notes\nVideo 1: sampling distributions\nVideo 2: Central Limit Theorem"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-1-500-samples-of-size-10",
    "href": "activities/L19-sampling-dist-clt.html#exercise-1-500-samples-of-size-10",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 1: 500 samples of size 10",
    "text": "Exercise 1: 500 samples of size 10\nRecall that we can sample 10 counties using sample_n():\n\n# Run this chunk a few times to explore the different samples you get\ncounty_clean %&gt;% \n  sample_n(size = 10, replace = FALSE)\n\nWe can also take a sample and then use the data to estimate the model:\n\n# Run this chunk a few times to explore the different sample models you get\ncounty_clean %&gt;% \n  sample_n(size = 10, replace = FALSE) %&gt;% \n  with(lm(pci_2019 ~ pci_2017))\n\nWe can also take multiple unique samples and build a sample model from each.\nThe code below obtains 500 separate samples of 10 counties, and stores the model estimates from each:\n\n# Set the seed so that we all get the same results\nset.seed(155)\n\n# Store the sample models\nsample_models_10 &lt;- mosaic::do(500)*(\n  county_clean %&gt;% \n    sample_n(size = 10, replace = FALSE) %&gt;% \n    with(lm(pci_2019 ~ pci_2017))\n)\n\n# Check it out\nhead(sample_models_10)\ndim(sample_models_10)\n\nReflect\n\nWhat’s the point of the do() function?!? If you’ve taken any COMP classes, what process do you think do() is a shortcut for?\nWhat is stored in the Intercept, pci_2017, and r.squared columns of the results?"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-2-sampling-distribution",
    "href": "activities/L19-sampling-dist-clt.html#exercise-2-sampling-distribution",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 2: Sampling distribution",
    "text": "Exercise 2: Sampling distribution\nCheck out the resulting 500 sample models:\n\ncounty_clean %&gt;% \n  ggplot(aes(x = pci_2017, y = pci_2019)) + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_abline(data = sample_models_10, \n              aes(intercept = Intercept, slope = pci_2017), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nLet’s focus on the slopes of these 500 sample models. A plot of the 500 slopes approximates the sampling distribution of the sample slopes.\n\nsample_models_10 %&gt;% \n  ggplot(aes(x = pci_2017)) + \n  geom_density() + \n  geom_vline(xintercept = 1.027, color = \"red\") + \n  xlim(0.3, 1.7)\n\nReflect: Describe the sampling distribution. What’s its general shape? Where is it centered? Roughly what’s its spread / i.e. what’s the range of estimates you observed?"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-3-standard-error",
    "href": "activities/L19-sampling-dist-clt.html#exercise-3-standard-error",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 3: Standard error",
    "text": "Exercise 3: Standard error\nFor a more rigorous assessment of the spread among the sample slopes, let’s calculate their standard deviation:\n\nsample_models_10 %&gt;% \n  summarize(sd(pci_2017))\n\nRecall: The standard deviation of sample estimates is called a “standard error”.\nIt measures the typical distance of a sample estimate from the actual population value."
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-4-central-limit-theorem-clt",
    "href": "activities/L19-sampling-dist-clt.html#exercise-4-central-limit-theorem-clt",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 4: Central Limit Theorem (CLT)",
    "text": "Exercise 4: Central Limit Theorem (CLT)\nRecall that the CLT assumes that, so long as our sample size is “big enough”, the sampling distribution of the sample slope will be Normal.\nSpecifically, all possible sample slopes will vary Normally around the population slope.\n\nDo your simulation results support this assumption?\nWant more intuition into the CLT? Watch this video explanation using bunnies and dragons: https://www.youtube.com/watch?v=jvoxEYmQHNM"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-5-using-the-clt",
    "href": "activities/L19-sampling-dist-clt.html#exercise-5-using-the-clt",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 5: Using the CLT",
    "text": "Exercise 5: Using the CLT\nLet \\(\\hat{\\beta}_1\\) be an estimate of the population slope parameter \\(\\beta_1\\) calculated from a sample of 10 counties.\nIn exercise 3, you approximated that \\(\\hat{\\beta}_1\\) has a standard error of roughly 0.16.\nThus, by the CLT, the sampling distribution of \\(\\hat{\\beta}_1\\) is:\n\\[\\hat{\\beta}_1 \\sim N(\\beta_1, 0.16^2)\\]\nUse this result with the 68-95-99.7 property of the Normal model to understand the potential error in a slope estimate.\n\nThere are many possible samples of 10 counties. What percent of these will produce an estimate \\(\\hat{\\beta}_1\\) that’s within 0.32, i.e. 2 standard errors, of the actual population slope \\(\\beta_1\\)?\nMore than 2 standard errors from \\(\\beta_1\\)?\nMore than 0.48, i.e. 3 standard errors, above \\(\\beta_1\\)?"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-6-clt-and-the-68-95-99.7-rule",
    "href": "activities/L19-sampling-dist-clt.html#exercise-6-clt-and-the-68-95-99.7-rule",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 6: CLT and the 68-95-99.7 Rule",
    "text": "Exercise 6: CLT and the 68-95-99.7 Rule\nFill in the blanks below to complete some general properties assumed by the CLT:\n\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 1 st. err. of \\(\\beta_1\\)\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 2 st. err. of \\(\\beta_1\\)\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 3 st. err. of \\(\\beta_1\\)"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-7-increasing-sample-size",
    "href": "activities/L19-sampling-dist-clt.html#exercise-7-increasing-sample-size",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 7: Increasing sample size",
    "text": "Exercise 7: Increasing sample size\nNow that we have a sense of the potential variability and error in sample estimates, let’s consider the impact of sample size. Suppose we were to increase our sample size from n = 10 to n = 50 or n = 200 counties. What impact do you anticipate this having on our sample estimates of the population parameters:\n\nDo you expect there to be more or less variability among the sample model lines?\nAround what value would you expect the sampling distribution of sample slopes to be centered?\nWhat general shape would you expect that sampling distribution to have?\nIn comparison to estimates based on the samples of size 10, do you think the estimates based on samples of size 50 will be closer to or farther from the true slope (on average)?"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-8-500-samples-of-size-n",
    "href": "activities/L19-sampling-dist-clt.html#exercise-8-500-samples-of-size-n",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 8: 500 samples of size n",
    "text": "Exercise 8: 500 samples of size n\nLet’s increase the sample size in our simulation. Fill in the blanks to take 500 samples of size 50, and build a sample model from each. Once you complete the code, remove eval = FALSE.\n\nset.seed(155)\nsample_models_50 &lt;- mosaic::do(___)*(\n  county_clean %&gt;% \n    ___(size = ___, replace = FALSE) %&gt;% \n    ___(___(pci_2019 ~ pci_2017))\n)\n\n# Check it out\nhead(sample_models_50)\n\nSimilarly, take 500 samples of size 200, and build a sample model from each. Once you complete the code, remove eval = FALSE.\n\nset.seed(155)\nsample_models_200 &lt;- mosaic::do(___)*(\n  county_clean %&gt;% \n    ___(size = ___, replace = FALSE) %&gt;% \n    ___(___(pci_2019 ~ pci_2017))\n)\n\n# Check it out\nhead(sample_models_200)"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-9-impact-of-sample-size-part-i",
    "href": "activities/L19-sampling-dist-clt.html#exercise-9-impact-of-sample-size-part-i",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 9: Impact of sample size (part I)",
    "text": "Exercise 9: Impact of sample size (part I)\nCompare and contrast the 500 sets of sample models when using samples of size 10, 50, and 200.\n\n# Remove eval = FALSE\n# 500 sample models using samples of size 10\ncounty_clean %&gt;% \n  ggplot(aes(x = pci_2017, y = pci_2019)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_10, \n              aes(intercept = Intercept, slope = pci_2017), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n# Remove eval = FALSE\n# 500 sample models using samples of size 50\ncounty_clean %&gt;% \n  ggplot(aes(x = pci_2017, y = pci_2019)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_50, \n              aes(intercept = Intercept, slope = pci_2017), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n# Remove eval = FALSE\n# 500 sample models using samples of size 200\ncounty_clean %&gt;% \n  ggplot(aes(x = pci_2017, y = pci_2019)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_200, \n              aes(intercept = Intercept, slope = pci_2017), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nReflect: What happens to our sample models as sample size increases? Was this what you expected?"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-10-impact-of-sample-size-part-ii",
    "href": "activities/L19-sampling-dist-clt.html#exercise-10-impact-of-sample-size-part-ii",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 10: Impact of sample size (part II)",
    "text": "Exercise 10: Impact of sample size (part II)\nLet’s focus on just the sampling distributions of our 500 slope estimates \\(\\hat{\\beta}_1\\). For easy comparison, plot the estimates based on samples of size 10, 50, and 200 on the same frame:\n\n# Remove eval = FALSE\n\n# Don't think too hard about this code!\n# Combine the estimates & sample size into a new data set\n# Then plot it\ndata.frame(estimates = c(sample_models_10$pci_2017, sample_models_50$pci_2017, sample_models_200$pci_2017),\n           sample_size = rep(c(\"10\",\"50\",\"200\"), each = 500)) %&gt;% \n  mutate(sample_size = fct_relevel(sample_size, c(\"10\", \"50\", \"200\"))) %&gt;% \n  ggplot(aes(x = estimates, color = sample_size)) + \n  geom_density() + \n  geom_vline(xintercept = 1.027, color = \"red\", linetype = \"dashed\") + \n  labs(title = \"Sampling distributions of the sample slope\")\n\nReflect: How do the shapes, centers, and spreads of these sampling distributions compare? Was this what you expected?"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-11-properties-of-sampling-distributions",
    "href": "activities/L19-sampling-dist-clt.html#exercise-11-properties-of-sampling-distributions",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 11: Properties of sampling distributions",
    "text": "Exercise 11: Properties of sampling distributions\nIn light of your observations, complete the following statements about the sampling distribution of the sample slope.\n\nFor all sample sizes, the shape of the sampling distribution is roughly ___ and the sampling distribution is roughly centered around ___, the true population slope.\nAs sample size increases:\nThe average sample slope estimate INCREASES / DECREASES / IS FAIRLY STABLE.\nThe standard error of the sample slopes INCREASES / DECREASES / IS FAIRLY STABLE.\nThus, as sample size increases, our sample slopes become MORE RELIABLE / LESS RELIABLE."
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-1-500-samples-of-size-10-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-1-500-samples-of-size-10-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 1: 500 samples of size 10",
    "text": "Exercise 1: 500 samples of size 10\nReflect\n\ndo() repeats the code within the parentheses as many times as you tell it. do()` is a shortcut for a for loop.\n500 different sample estimates of the model"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-2-sampling-distribution-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-2-sampling-distribution-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 2: Sampling distribution",
    "text": "Exercise 2: Sampling distribution\nThe 500 sample slopes are normally distributed around the population slope and range from roughly 0.4 to 1.6."
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-3-standard-error-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-3-standard-error-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 3: Standard error",
    "text": "Exercise 3: Standard error\nFor example, for samples of size 10, we expect estimates of the sample slope (the expected change in pci_2019 per $1k increase in pci_2017) to be off by 0.16. The standard errors decrease as sample size increases."
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-4-central-limit-theorem-clt-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-4-central-limit-theorem-clt-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 4: Central Limit Theorem (CLT)",
    "text": "Exercise 4: Central Limit Theorem (CLT)\nyes"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-5-using-the-clt-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-5-using-the-clt-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 5: Using the CLT",
    "text": "Exercise 5: Using the CLT\n\n95%\n5%\n0.15% ((100 - 99.7%)/2)"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-6-clt-and-the-68-95-99.7-rule-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-6-clt-and-the-68-95-99.7-rule-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 6: CLT and the 68-95-99.7 Rule",
    "text": "Exercise 6: CLT and the 68-95-99.7 Rule\n68%, 95%, 99.7%"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-7-increasing-sample-size-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-7-increasing-sample-size-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 7: Increasing sample size",
    "text": "Exercise 7: Increasing sample size\nintuition. no wrong answer."
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-8-500-samples-of-size-n-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-8-500-samples-of-size-n-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 8: 500 samples of size n",
    "text": "Exercise 8: 500 samples of size n\n\nset.seed(155)\nsample_models_50 &lt;- mosaic::do(500)*(\n  county_clean %&gt;% \n    sample_n(size = 50, replace = FALSE) %&gt;% \n    with(lm(pci_2019 ~ pci_2017))\n)\n\n# Check it out\nhead(sample_models_50)\n##   Intercept  pci_2017    sigma r.squared        F numdf dendf .row .index\n## 1 1.2445147 1.0206258 1.996879 0.8827145 361.2578     1    48    1      1\n## 2 2.0351324 0.9993395 1.578092 0.9248192 590.4612     1    48    1      2\n## 3 3.3140440 0.9590203 1.457254 0.9446582 819.3372     1    48    1      3\n## 4 1.5031974 1.0400601 2.173192 0.8890306 384.5518     1    48    1      4\n## 5 2.2960437 0.9795596 1.759872 0.9320475 658.3761     1    48    1      5\n## 6 0.1674985 1.0487638 2.425859 0.9095534 482.6998     1    48    1      6\n\n\nset.seed(155)\nsample_models_200 &lt;- mosaic::do(500)*(\n  county_clean %&gt;% \n    sample_n(size = 200, replace = FALSE) %&gt;% \n    with(lm(pci_2019 ~ pci_2017))\n)\n\n# Check it out\nhead(sample_models_200)\n##     Intercept  pci_2017    sigma r.squared        F numdf dendf .row .index\n## 1  1.55222839 1.0133282 2.013702 0.9160050 2159.282     1   198    1      1\n## 2  1.67853251 0.9994033 2.288979 0.8658330 1277.772     1   198    1      2\n## 3  0.85803178 1.0394611 1.811912 0.9301205 2635.448     1   198    1      3\n## 4  0.79740594 1.0414248 2.597108 0.8769687 1404.219     1   197    1      4\n## 5 -0.05186957 1.0751463 2.563725 0.8845190 1516.568     1   198    1      5\n## 6  1.06340006 1.0337143 2.094655 0.9126476 2068.681     1   198    1      6"
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-9-impact-of-sample-size-part-i-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-9-impact-of-sample-size-part-i-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 9: Impact of sample size (part I)",
    "text": "Exercise 9: Impact of sample size (part I)\nThe sample model lines become less and less variable from sample to sample."
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-10-impact-of-sample-size-part-ii-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-10-impact-of-sample-size-part-ii-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 10: Impact of sample size (part II)",
    "text": "Exercise 10: Impact of sample size (part II)\nNo matter the sample size, the sample estimates are normally distributed around the population slope. But as sample size increases, the variability of the sample estimates decreases."
  },
  {
    "objectID": "activities/L19-sampling-dist-clt.html#exercise-11-properties-of-sampling-distributions-1",
    "href": "activities/L19-sampling-dist-clt.html#exercise-11-properties-of-sampling-distributions-1",
    "title": "Sampling distributions & the CLT",
    "section": "Exercise 11: Properties of sampling distributions",
    "text": "Exercise 11: Properties of sampling distributions\n\nFor all sample sizes, the shape of the sampling distribution is roughly normal and the sampling distribution is roughly centered around 1.027, the true population slope.\nAs sample size increases:\nThe average sample slope estimate IS FAIRLY STABLE.\nThe standard error of the sample slopes DECREASES / IS FAIRLY STABLE.\nThus, as sample size increases, our sample slopes become MORE RELIABLE."
  },
  {
    "objectID": "activities/L11-mlr-interaction-explore.html#learning-goals",
    "href": "activities/L11-mlr-interaction-explore.html#learning-goals",
    "title": "Multiple linear regression: exploring interaction",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nDescribe when it would be useful to include an interaction term to a model\nWrite a model formula for an interaction model\nInterpret the coefficients in an interaction model in the data context"
  },
  {
    "objectID": "activities/L11-mlr-interaction-explore.html#readings-and-videos",
    "href": "activities/L11-mlr-interaction-explore.html#readings-and-videos",
    "title": "Multiple linear regression: exploring interaction",
    "section": "Readings and videos",
    "text": "Readings and videos\nToday is a day to discover ideas, so no readings or videos to go through before class.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L11-mlr-interaction-explore.html#exercise-1-wages-across-all-industries",
    "href": "activities/L11-mlr-interaction-explore.html#exercise-1-wages-across-all-industries",
    "title": "Multiple linear regression: exploring interaction",
    "section": "Exercise 1: Wages across all industries",
    "text": "Exercise 1: Wages across all industries\nThe plot below illustrates the relationship between wage and education for all of the industries in our cps dataset.\n\n# Plot\nggplot(cps, aes(y = wage, x = education, color = industry)) + \n    geom_smooth(method = \"lm\", se = FALSE)\n\n\nWhat about this plot indicates that it would be a good idea to fit an interaction model?\nWhat industry will R use as the reference category?\n(Challenge!) Before fitting the model in R, write down what you think the model formula will look like.\nFit a model that includes an interaction term between education and industry.\n\n\n# Fit an interaction model called wage_model\n\n\n# Display summarized model output\n\n\nIn what industry do wages increase the most per additional year of education? What is this increase?\nSimilarly, in what industry do wages increase the least per additional year of education? What is this increase?"
  },
  {
    "objectID": "activities/L11-mlr-interaction-explore.html#exercise-2-thinking-beyond",
    "href": "activities/L11-mlr-interaction-explore.html#exercise-2-thinking-beyond",
    "title": "Multiple linear regression: exploring interaction",
    "section": "Exercise 2: Thinking beyond",
    "text": "Exercise 2: Thinking beyond\nDo you think there are other variables (which may or may not be in our cps data) that have an interaction with industry in affecting wages? If you were to fit an interaction model, what results might you expect to find?"
  },
  {
    "objectID": "activities/L11-mlr-interaction-explore.html#reflection",
    "href": "activities/L11-mlr-interaction-explore.html#reflection",
    "title": "Multiple linear regression: exploring interaction",
    "section": "Reflection",
    "text": "Reflection\nThrough the exercises above, we developed ideas about when to fit interaction models and how to interpret results. Describe what makes sense and what is still unclear about this topic.\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L11-mlr-interaction-explore.html#exercise-1-wages-across-all-industries-1",
    "href": "activities/L11-mlr-interaction-explore.html#exercise-1-wages-across-all-industries-1",
    "title": "Multiple linear regression: exploring interaction",
    "section": "Exercise 1: Wages across all industries",
    "text": "Exercise 1: Wages across all industries\nThe plot below illustrates the relationship between wage and education for all of the industries in our cps dataset.\n\n# Plot\nggplot(cps, aes(y = wage, x = education, color = industry)) + \n    geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\nThe industry-specific lines all have different slopes.\nag (first in alphabetical order)\nThis is a challenge! Compare your prediction to what you see when fitting the model in part d.\n\n\n\n# Fit an interaction model called wage_model\nwage_model &lt;- lm(wage ~ education*industry, data = cps)\n\n# Display summarized model output\ncoef(summary(wage_model))\n##                                               Estimate Std. Error     t value\n## (Intercept)                                31475.87521  22370.504  1.40702574\n## education                                     61.95396   2039.257  0.03038065\n## industryconstruction                      -14427.01189  25740.953 -0.56046923\n## industryinstallation_production           -33208.72359  25346.017 -1.31021469\n## industrymanagement                        -97066.48097  23305.235 -4.16500759\n## industryservice                           -55462.76415  23229.134 -2.38763810\n## industrytransportation                     -6834.25066  27495.549 -0.24855844\n## education:industryconstruction              2295.51232   2297.659  0.99906577\n## education:industryinstallation_production   3759.05906   2244.792  1.67456904\n## education:industrymanagement                8616.31984   2080.190  4.14208220\n## education:industryservice                   4384.72036   2092.523  2.09542317\n## education:industrytransportation            1036.09210   2409.093  0.43007562\n##                                               Pr(&gt;|t|)\n## (Intercept)                               1.594509e-01\n## education                                 9.757641e-01\n## industryconstruction                      5.751720e-01\n## industryinstallation_production           1.901533e-01\n## industrymanagement                        3.139604e-05\n## industryservice                           1.697551e-02\n## industrytransportation                    8.037075e-01\n## education:industryconstruction            3.177870e-01\n## education:industryinstallation_production 9.405013e-02\n## education:industrymanagement              3.470009e-05\n## education:industryservice                 3.615851e-02\n## education:industrytransportation          6.671499e-01\n\n\nIn the management industry, wages increase the most per year of education. The increase is 61.95396 + 8616.31984 = $8678.274 per year. That is, every additional year of education is associated with an average increase of $8678.27 in yearly wages in the management industry.\nIn the agriculture industry, wages increase the least per year of education. The increase is $61.95 per year. That is, every additional year of education is associated with an average increase of $61.95 in yearly wages in the ag industry."
  },
  {
    "objectID": "activities/L11-mlr-interaction-explore.html#exercise-2-thinking-beyond-1",
    "href": "activities/L11-mlr-interaction-explore.html#exercise-2-thinking-beyond-1",
    "title": "Multiple linear regression: exploring interaction",
    "section": "Exercise 2: Thinking beyond",
    "text": "Exercise 2: Thinking beyond\nIf a variable x has an interaction with the industry variable in affecting wages, then the relationship between x and wages must be different by industry. We might suspect that this could be the case for hours worked per week. We can make a plot to verify that this is actually the case:\n\nggplot(cps, aes(y = wage, x = hours, color = industry)) + \n    geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#learning-goals",
    "href": "activities/L14-mlr-model-building-2.html#learning-goals",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nExplain when variables are redundant or multicollinear.\nRelate redundancy and multicollinearity to coefficient estimates and \\(R^2\\).\nExplain why adjusted \\(R^2\\) is preferable to multiple \\(R^2\\) when comparing models with different numbers of predictors."
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#readings-and-videos",
    "href": "activities/L14-mlr-model-building-2.html#readings-and-videos",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Readings and videos",
    "text": "Readings and videos\nToday is a day to discover ideas, so no readings or videos to go through before class, but if you want to see today’s ideas presented in a different way, you can take a look at the following after class:\n\nReading: Section 3.9.5 in the STAT 155 Notes\nVideo: Redundancy and Multicollinearity\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-1-modeling-bill-length-by-flipper-length",
    "href": "activities/L14-mlr-model-building-2.html#exercise-1-modeling-bill-length-by-flipper-length",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 1: Modeling bill length by flipper length",
    "text": "Exercise 1: Modeling bill length by flipper length\nWhat can a penguin’s flipper (arm) length tell us about their bill length? To answer this question, we’ll consider 3 of our models:\n\n\n\nmodel\npredictors\n\n\n\n\npenguin_model_1\nflipper_length_mm\n\n\npenguin_model_2\nflipper_length_cm\n\n\npenguin_model_3\nflipper_length_mm + flipper_length_cm\n\n\n\nPlots of the first two models are below:\n\nggplot(penguins, aes(y = bill_length_mm, x = flipper_length_mm)) + \n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE)\n\nggplot(penguins, aes(y = bill_length_mm, x = flipper_length_cm)) + \n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE)\n\n\nBefore examining the model summaries, check your intuition. Do you think the penguin_model_2 R-squared will be less than, equal to, or more than that of penguin_model_1? Similarly, how do you think the penguin_model_3 R-squared will compare to that of penguin_model_1?\nCheck your intuition: Examine the R-squared values for the three penguin models and summarize how these compare.\n\n\nsummary(penguin_model_1)$r.squared\nsummary(penguin_model_2)$r.squared\nsummary(penguin_model_3)$r.squared\n\n\nExplain why your observation in part b makes sense. Support your reasoning with a plot of just the 2 predictors: flipper_length_mm vs flipper_length_cm.\n\n\nOPTIONAL challenge: In summary(penguin_model_3), the flipper_length_cm coefficient is NA. Explain why this makes sense. HINT: Thinking about what you learned about controlling for covariates, why wouldn’t it make sense to interpret this coefficient? BONUS: For those of you that have taken MATH 236, this has to do with matrices that are not of full rank!"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-2-incorporating-body_mass_g",
    "href": "activities/L14-mlr-model-building-2.html#exercise-2-incorporating-body_mass_g",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 2: Incorporating body_mass_g",
    "text": "Exercise 2: Incorporating body_mass_g\nIn this exercise you’ll consider 3 models of bill_length_mm:\n\n\n\nmodel\npredictors\n\n\n\n\npenguin_model_1\nflipper_length_mm\n\n\npenguin_model_4\nbody_mass_g\n\n\npenguin_model_5\nflipper_length_mm + body_mass_g\n\n\n\n\nWhich is the better predictor of bill_length_mm: flipper_length_mm or body_mass_g? Provide some numerical evidence.\npenguin_model_5 incorporates both flipper_length_mm and body_mass_g as predictors. Before examining a model summary, ask your gut: Will the penguin_model_5 R-squared be close to 0.35, close to 0.43, or greater than 0.6?\nCheck your intuition. Report the penguin_model_5 R-squared and summarize how this compares to that of penguin_model_1 and penguin_model_4.\nExplain why your observation in part c makes sense. Support your reasoning with a plot of the 2 predictors: flipper_length_mm vs body_mass_g."
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-3-redundancy-and-multicollinearity",
    "href": "activities/L14-mlr-model-building-2.html#exercise-3-redundancy-and-multicollinearity",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 3: Redundancy and Multicollinearity",
    "text": "Exercise 3: Redundancy and Multicollinearity\nThe exercises above have illustrated special phenomena in multivariate modeling:\n\ntwo predictors are redundant if they contain the same exact information\ntwo predictors are multicollinear if they are strongly associated (they contain very similar information) but are not completely redundant.\n\nRecall that we examined 5 models:\n\n\n\nmodel\npredictors\n\n\n\n\npenguin_model_1\nflipper_length_mm\n\n\npenguin_model_2\nflipper_length_cm\n\n\npenguin_model_3\nflipper_length_mm + flipper_length_cm\n\n\npenguin_model_4\nbody_mass_g\n\n\npenguin_model_5\nflipper_length_mm + body_mass_g\n\n\n\n\nWhich model had redundant predictors and which predictors were these?\nWhich model had multicollinear predictors and which predictors were these?\nIn general, what happens to the R-squared value if we add a redundant predictor to a model: will it decrease, stay the same, increase by a small amount, or increase by a significant amount?\nSimilarly, what happens to the R-squared value if we add a multicollinear predictor to a model: will it decrease, stay the same, increase by a small amount, or increase by a significant amount?"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-4-considerations-for-strong-models",
    "href": "activities/L14-mlr-model-building-2.html#exercise-4-considerations-for-strong-models",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 4: Considerations for strong models",
    "text": "Exercise 4: Considerations for strong models\nLet’s dive deeper into important considerations when building a strong model. We’ll use a subset of the penguins data for exploring these ideas.\n\n# For illustration purposes only, take a sample of 10 penguins.\n# We'll discuss this code later in the course!\nset.seed(155)\npenguins_small &lt;- sample_n(penguins, size = 10) %&gt;%\n  mutate(flipper_length_mm = jitter(flipper_length_mm))\n\nConsider 3 models of bill length:\n\n# A model with one predictor (flipper_length_mm)\npoly_mod_1 &lt;- lm(bill_length_mm ~ flipper_length_mm, penguins_small)\n\n# A model with two predictors (flipper_length_mm and flipper_length_mm^2)\npoly_mod_2 &lt;- lm(bill_length_mm ~ poly(flipper_length_mm, 2), penguins_small)\n\n# A model with nine predictors (flipper_length_mm, flipper_length_mm^2, ... on up to flipper_length_mm^9)\npoly_mod_9 &lt;- lm(bill_length_mm ~ poly(flipper_length_mm, 9), penguins_small)\n\n\nBefore doing any analysis, which of the three models do you think will be best?\nCalculate the R-squared values of these 3 models. Which model do you think is best?\n\n\nsummary(poly_mod_1)$r.squared\nsummary(poly_mod_2)$r.squared\nsummary(poly_mod_9)$r.squared\n\n\nCheck out plots depicting the relationship estimated by these 3 models. Which model do you think is best?\n\n\n# A plot of model 1\nggplot(penguins_small, aes(y = bill_length_mm, x = flipper_length_mm)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE)\n\n\n# A plot of model 2\nggplot(penguins_small, aes(y = bill_length_mm, x = flipper_length_mm)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), se = FALSE)\n\n\n# A plot of model 9\nggplot(penguins_small, aes(y = bill_length_mm, x = flipper_length_mm)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", formula = y ~ poly(x, 9), se = FALSE)"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-5-reflecting-on-these-investigations",
    "href": "activities/L14-mlr-model-building-2.html#exercise-5-reflecting-on-these-investigations",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 5: Reflecting on these investigations",
    "text": "Exercise 5: Reflecting on these investigations\n\nList 3 of your favorite foods. Now imagine making a dish that combines all of these foods. Do you think it would taste good?\nToo many good things doesn’t make necessarily make a better thing. Model 9 demonstrates that it’s always possible to get a perfect R-squared of 1, but there are drawbacks to putting more and more predictors into our model. Answer the following about model 9:\n\nHow easy would it be to interpret this model?\nWould you say that this model captures the general trend of the relationship between bill_length_mm and flipper_length_mm?\nHow well do you think this model would generalize to penguins that were not included in the penguins_small sample? For example, would you expect these new penguins to fall on the wiggly model 9 curve?"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-6-overfitting",
    "href": "activities/L14-mlr-model-building-2.html#exercise-6-overfitting",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 6: Overfitting",
    "text": "Exercise 6: Overfitting\nModel 9 provides an example of a model that is overfit to our sample data. That is, it picks up the tiny details of our data at the cost of losing the more general trends of the relationship of interest. Check out the following xkcd comic. Which plot pokes fun at overfitting?\n\nSome other goodies:"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-7-questioning-r-squared",
    "href": "activities/L14-mlr-model-building-2.html#exercise-7-questioning-r-squared",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 7: Questioning R-squared",
    "text": "Exercise 7: Questioning R-squared\nZooming out, explain some limitations of relying on R-squared to measure the strength / usefulness of a model."
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-8-adjusted-r-squared",
    "href": "activities/L14-mlr-model-building-2.html#exercise-8-adjusted-r-squared",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 8: Adjusted R-squared",
    "text": "Exercise 8: Adjusted R-squared\nWe’ve seen that, unless a predictor is redundant with another, R-squared will increase. Even if that predictor is strongly multicollinear with another. Even if that predictor isn’t a good predictor! Thus if we only look at R-squared we might get overly greedy. We can check our greedy impulses a few ways. We take a more in depth approach in STAT 253, but one quick alternative is reported right in our model summary() tables. Adjusted R-squared includes a penalty for incorporating more and more predictors. Mathematically (where \\(n\\) is the sample size and \\(p\\) is the number of non-intercept coefficients):\n\\[\n\\text{Adjusted } R^2 = 1 - (1 - R^2) \\left( \\frac{n-1}{n-p-1} \\right)\n\\]\nThus unlike R-squared, Adjusted R-squared can decrease when the information that a predictor contributes to a model isn’t enough to offset the complexity it adds to that model. Consider two models:\n\nexample_1 &lt;- lm(bill_length_mm ~ species, penguins)\nexample_2 &lt;- lm(bill_length_mm ~ species + island, penguins)\n\n\nCheck out the summaries for the 2 example models. In general, how does a model’s Adjusted R-squared compare to the R-squared? Is it greater, less than, or equal to the R-squared?\nHow did the R-squared change from example model 1 to model 2? How did the Adjusted R-squared change?\nExplain what it is about island that resulted in a decreased Adjusted R-squared. Note: it’s not necessarily the case that island is a bad predictor on its own!"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#reflection",
    "href": "activities/L14-mlr-model-building-2.html#reflection",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Reflection",
    "text": "Reflection\nToday we looked at some cautions surrounding indiscriminately adding variables to a model. Summarize key takeaways.\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-1-modeling-bill-length-by-flipper-length-1",
    "href": "activities/L14-mlr-model-building-2.html#exercise-1-modeling-bill-length-by-flipper-length-1",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 1: Modeling bill length by flipper length",
    "text": "Exercise 1: Modeling bill length by flipper length\n\n\n\nmodel\npredictors\n\n\n\n\npenguin_model_1\nflipper_length_mm\n\n\npenguin_model_2\nflipper_length_cm\n\n\npenguin_model_3\nflipper_length_mm + flipper_length_cm\n\n\n\nPlots of the first two models are below:\n\nggplot(penguins, aes(y = bill_length_mm, x = flipper_length_mm)) + \n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(penguins, aes(y = bill_length_mm, x = flipper_length_cm)) + \n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\nYour intuition–answers will vary\nThe R-squared values are all the same!\n\n\nsummary(penguin_model_1)$r.squared\n## [1] 0.430574\nsummary(penguin_model_2)$r.squared\n## [1] 0.430574\nsummary(penguin_model_3)$r.squared\n## [1] 0.430574\n\n\nThe two variables are perfectly linearly correlated—they contain exactly the same information!\n\n\nggplot(penguins, aes(x = flipper_length_cm, y = flipper_length_mm)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nAn NA means that the coefficient couldn’t be estimated. In penguin_model_3, the interpretation of the flipper_length_cm coefficient is the average change in bill length per centimeter change in flipper length, while holding flipper length in millimeters constant…this is impossible! We can’t hold flipper length in millimeters fixed while varying flipper length in centimeters—if one changes the other must. (In linear algebra terms, the matrix underlying our data is not of full rank.)"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-2-incorporating-body_mass_g-1",
    "href": "activities/L14-mlr-model-building-2.html#exercise-2-incorporating-body_mass_g-1",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 2: Incorporating body_mass_g",
    "text": "Exercise 2: Incorporating body_mass_g\nIn this exercise you’ll consider 3 models of bill_length_mm:\n\n\n\nmodel\npredictors\n\n\n\n\npenguin_model_1\nflipper_length_mm\n\n\npenguin_model_4\nbody_mass_g\n\n\npenguin_model_5\nflipper_length_mm + body_mass_g\n\n\n\n\nflipper_length_mm is a better predictor than body_mass_g because penguin_model_1 has an R-squared value of 0.4306 vs 0.3542 for penguin_model_4.\nIntuition check–answers will vary\nR-squared is for penguin_model_5 which is slightly higher than that of penguin_model_1 and penguin_model_4.\n\nd.flipper_length_mm and body_mass_g are positively correlated and thus contain related information, but not completely redundant information. There’s some information in flipper length in explaining bill length that isn’t captured by body mass, and vice-versa.\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point()"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-3-redundancy-and-multicollinearity-1",
    "href": "activities/L14-mlr-model-building-2.html#exercise-3-redundancy-and-multicollinearity-1",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 3: Redundancy and Multicollinearity",
    "text": "Exercise 3: Redundancy and Multicollinearity\n\n\n\nmodel\npredictors\n\n\n\n\npenguin_model_1\nflipper_length_mm\n\n\npenguin_model_2\nflipper_length_cm\n\n\npenguin_model_3\nflipper_length_mm + flipper_length_cm\n\n\npenguin_model_4\nbody_mass_g\n\n\npenguin_model_5\nflipper_length_mm + body_mass_g\n\n\n\n\npenguin_model_3 had redundant predictors: `flipper_length_mm and flipper_length_cm\npenguin_model_5 had multicollinear predictors: flipper_length_mm and body_mass_g were related but not redundant\nR-squared will stay the same if we add a redundant predictor to a model.\nR-squared will increase by a small amount if we add a multicollinear predictor to a model."
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-4-considerations-for-strong-models-1",
    "href": "activities/L14-mlr-model-building-2.html#exercise-4-considerations-for-strong-models-1",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 4: Considerations for strong models",
    "text": "Exercise 4: Considerations for strong models\n\nA gut check! Answers will vary\nBased on R-squared: recall that R-squared is interpreted as the proportion of variation in the outcome that our model explains. It would seem that higher is better, so poly_mod_9 might seem to be the best. BUT we’ll see where this reasoning is flawed soon!\nBased on the plots: Answers will vary"
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-5-reflecting-on-these-investigations-1",
    "href": "activities/L14-mlr-model-building-2.html#exercise-5-reflecting-on-these-investigations-1",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 5: Reflecting on these investigations",
    "text": "Exercise 5: Reflecting on these investigations\n\nsalmon, chocolate, samosas. Together? Yuck!\nRegarding model 9:\n\nNOT easy to interpret.\nNO. It’s much more wiggly than the general trend.\nNOT WELL. It is too tailored to our data."
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-6-overfitting-1",
    "href": "activities/L14-mlr-model-building-2.html#exercise-6-overfitting-1",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 6: Overfitting",
    "text": "Exercise 6: Overfitting\nThe bottom left plot pokes fun at overfitting."
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-7-questioning-r-squared-1",
    "href": "activities/L14-mlr-model-building-2.html#exercise-7-questioning-r-squared-1",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 7: Questioning R-squared",
    "text": "Exercise 7: Questioning R-squared\nIt measures how well our model explains / predicts our sample data, not how well it explains / predicts the broader population. It also has the feature that any non-redundant predictor added to a model will increase the R-squared."
  },
  {
    "objectID": "activities/L14-mlr-model-building-2.html#exercise-8-adjusted-r-squared-1",
    "href": "activities/L14-mlr-model-building-2.html#exercise-8-adjusted-r-squared-1",
    "title": "Multiple linear regression: model building (part 2)",
    "section": "Exercise 8: Adjusted R-squared",
    "text": "Exercise 8: Adjusted R-squared\n\nAdjusted R-squared is less than the R-squared\nFrom model 1 to 2, R-squared increased and Adjusted R-squared decreased.\nisland didn’t provide useful information about bill length beyond what was already provided by species."
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#learning-goals",
    "href": "activities/L05-slr-model-eval.html#learning-goals",
    "title": "Simple linear regression: model evaluation",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nUse residual plots to evaluate the correctness of a model\nExplain the rationale for the R-squared metric of model strength\nInterpret the R-squared metric\nThink about ethical implications of modeling by examining the impacts of biased data, power dynamics, the role of categorization, and the role of emotion and lived experience"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#readings-and-videos",
    "href": "activities/L05-slr-model-eval.html#readings-and-videos",
    "title": "Simple linear regression: model evaluation",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 1.7, 3.7, and 3.8 in the STAT 155 Notes\n\nNote: You do not need to focus on the “Ladder of Power” in Section 3.8. Transformations in general will be the focus of the next activity we do.\n\nVideos:\n\nModel evaluation: is the model wrong? (slides)\nModel evaluation: is the model strong? (slides)\nModel evaluation: is the model fair? (slides)\nR Code for Evaluating and Using a Linear Model"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#model-assumptions",
    "href": "activities/L05-slr-model-eval.html#model-assumptions",
    "title": "Simple linear regression: model evaluation",
    "section": "Model Assumptions",
    "text": "Model Assumptions\nOne way to think about model evaluation is to consider whether or not underlying assumptions of our regression models are being met (or not). Asking ourselves if our models are “wrong”, “strong”, and “fair” approaches this from one perspective. To the first question (whether our model is wrong), recall the following four assumptions of linear regression:\n\nLinearity\nIndependence\nNormality\nEqual Variance\n\nNote that they spell “LINE” (how convenient!).\nBy assumptions, we mean that the above four “things” are needed mathematically in order for linear regression to “work”.\nWhereas we can check some of these assumptions using a residual plot, we need to examine the context of our data collection when checking the Independence assumption. What we mean by independence, is that the residuals in our model do not depend on one another. This may seem like an unsatisfying definition, so here are some examples:\n\nSuppose I want to understand the association between a person’s high school GPA and their college GPA. I collect data from every graduating senior, at three different high schools. If I have college GPA as my outcome, and high school GPA as my predictor, are my residuals independent? Probably not! It is reasonable to believe that students from the same high school may have similar GPAs, due to resources their high school may have had available, or specific teachers grading differently at one school or another. This is an example of clustering, where we have clusters of students within schools. The independence assumption of our linear regression model would be violated. One way to address this would be to include which high school they went to as an additional covariate in our regression model (we’ll get to this with multiple linear regression), and more advanced methods are covered in a course on Correlated Data.\nSuppose I want to understand the association between a mouse’s weight and their water consumption across time. I collect data for 365 days for ten different mice, recording their weight and water consumption each day of the year. If I have weight as my predictor and water consumption as my outcome, are my residuals independent? Nope! This is an example of correlated data that is longitudinal in nature: I have multiple observations per individual (mouse) across time. A mouse’s weight one day is certainly not independent of it’s weight the following day. The independence assumption of our linear regression model would again be violated. One way to address this would be to include “Mouse ID” as a predictor in our regression model (again, we’ll get to this with multiple linear regression).\n\nAll types of data that will violate the independence assumption of linear regression will have some sort of correlation structure (within individual, across time, across space, etc.). Think about clusters. If your observations fall neatly into specific clusters, your data may violate the independence assumption of linear regression.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-1-is-the-model-correct",
    "href": "activities/L05-slr-model-eval.html#exercise-1-is-the-model-correct",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nLet’s revisit the Capital Bikeshare data:\n\n# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")\n\nWe previously explored a model of daily ridership among registered users as a function of temperature:\n\n# Fit a linear model\nbike_model &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n\n# Check it out\nsummary(bike_model)\n\nPlot this relationship with both a curved and linear trend line. Based on this plot, do you think the model is correct? If not, which of the LINE assumptions does it violate?\n\n# Plot temp_feel vs riders_registered with a model trend\n___(___, aes(x = ___, y = ___)) + \n    geom___() + \n    geom___(se = FALSE, color = \"red\") +\n    geom___(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-2-residual-plots",
    "href": "activities/L05-slr-model-eval.html#exercise-2-residual-plots",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 2: Residual plots",
    "text": "Exercise 2: Residual plots\nPlotting the residuals vs the predictions (also called “fitted values”) for each case can help us assess how wrong our model is. This will be a particularly important tool when evaluating models with multiple predictors. Construct the residual plot for bike_model. As with the scatterplot, this plot indicates that bike_model violates one of the LINE assumptions. Explain which assumption that is and how you can tell that from just the residual plot.\nNotes:\n\nInformation about the residuals (.resid) and predictions (.fitted) are stored within our model, thus we start our ggplot() with the model name as opposed to the raw dataset. We will rarely start ggplot() with a model instead of the data.\nWe can fix this model by adding a quadratic “transformation term”. We’ll discuss this idea in our next class.\n\n\n# Check out the residual plot for bike_model\nggplot(bike_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model",
    "href": "activities/L05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 3: What’s incorrect about this model?",
    "text": "Exercise 3: What’s incorrect about this model?\nConsider another example. The mammals data includes data on the average brain weight (g) and body weight (kg) for a variety of mammals:\n\n# Import the data\nmammals &lt;- read_csv(\"https://mac-stat.github.io/data/mammals.csv\")\n\n# Check it out\nhead(mammals)\n\nFit a model of brain vs body weight:\n\n# Construct the model\nmammal_model &lt;- lm(brain ~ body, mammals)\n\n# Check it out\nsummary(mammal_model)\n\n\nConstruct two plots that will help us evaluate mammal_model:\n\n\n# Scatterplot of brain weight (y) vs body weight (x)\n# Include a model trend line (i.e. a representation of mammal_model)\n\n\n# Residual plot for mammal_model\n\n\nThese two plots confirm that our model is wrong. What is wrong? That is, which of the LINE assumptions are violated? (NOTE: We again can fix this model by “transforming” one or both of the brain and body variables. We’ll discuss this idea in our next class.)"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-4-exploring-mammals",
    "href": "activities/L05-slr-model-eval.html#exercise-4-exploring-mammals",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 4: Exploring mammals",
    "text": "Exercise 4: Exploring mammals\nJust for fun, let’s dig into the mammals data. Discuss what you observe:\n\n# Label the points by the animal name!\n# Discuss: What 2 things are new in this code?\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    geom_smooth(method = \"lm\", se = FALSE) \n\n\n# Zoom in\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    lims(y = c(0, 1500), x = c(0, 600))\n\n\n# Zoom in more\nggplot(mammals, aes(x = body, y = brain, label = animal)) + \n    geom_text() + \n    lims(y = c(0, 500), x = c(0, 200))"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "href": "activities/L05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the variation in the predictors.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that’s explained by the model (the variance of the predictions) and the variability that’s left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\nStrong models have residuals that don’t deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe two rows of plots show a stronger and a weaker model. Just by looking at the blue trend line and the dispersion of the points about the line, which row corresponds to the stronger model? How can you tell? Which row would you expect to have a higher correlation?\nWhat is different about the variance of the residuals from the first to the second row?\n\n\nPutting this together, the R-squared compares Var(predicted) to Var(response):\n\\[R^2 = \\frac{\\text{variance of predicted values}}{\\text{variance of observed response values}} = 1 - \\frac{\\text{variance of residuals}}{\\text{variance of observed response values}}\\] ::: {.callout-note collapse=“true”} ## R-squared\n\\[\nR^2 = 1 - \\frac{SSE}{SSTO} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n\\] where \\(y_i\\) are our observed outcomes, \\(i = 1, \\dots, n\\), \\(\\hat{y}_i\\) are our fitted values/predictions, and \\(\\bar{y}\\) is our observed average outcome. :::"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-6-r-squared-interpretations",
    "href": "activities/L05-slr-model-eval.html#exercise-6-r-squared-interpretations",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 6: R-squared Interpretations",
    "text": "Exercise 6: R-squared Interpretations\nRecall bikemod1 from Exercise 3, where we predicted registered riders by what the temperature felt like on a given day. Use the summary function to look out the model output for bikemod1, and interpret the \\(R^2\\) value for this model, in the context of the problem. (NOTE: \\(R^2\\) is reported in output here as “Multiple R-squared”).\n\n# Get R-squared\nsummary(bike_model)"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-7-further-exploring-r-squared",
    "href": "activities/L05-slr-model-eval.html#exercise-7-further-exploring-r-squared",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 7: Further exploring R-squared",
    "text": "Exercise 7: Further exploring R-squared\nIn this exercise, we’ll look at data from a synthetic dataset called Anscombe’s quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\n\nThe anscombe data is actually 4 datasets in one: x1 and y1 go together, and so forth. Examine the coefficient estimates (in the “Estimate” column of the “Coefficients:” part) and the “Multiple R-squared” value on the second to last line. What do you notice? How do these models compare?\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\nsummary(anscombe_mod2)\nsummary(anscombe_mod3)\nsummary(anscombe_mod4)\n\nNow take a look at the following scatterplots of the 4 pairs of variables. What do you notice? What takeaway can we draw from this exercise?\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-8-biased-data-biased-results-example-1",
    "href": "activities/L05-slr-model-eval.html#exercise-8-biased-data-biased-results-example-1",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 8: Biased data, biased results: example 1",
    "text": "Exercise 8: Biased data, biased results: example 1\nDATA ARE NOT NEUTRAL. Data can reflect personal biases, institutional biases, power dynamics, societal biases, the limits of our knowledge, and so on. In turn, biased data can lead to biased analyses. Consider an example.\n\nDo a Google image search for “statistics professor.” What do you observe?\nThese search results are produced by a search algorithm / model. Explain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the search results produced from this biased data?"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-9-biased-data-biased-results-example-2",
    "href": "activities/L05-slr-model-eval.html#exercise-9-biased-data-biased-results-example-2",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 9: Biased data, biased results: example 2",
    "text": "Exercise 9: Biased data, biased results: example 2\nConsider the example of a large company that developed a model / algorithm to review the résumés of applicants for software developer & other tech positions. The model then gave each applicant a score indicating their hireability or potential for success at the company. You can think of this model as something like:\n\\[\\text{potential for success } = \\beta_0 + \\beta_1 (\\text{features from the résumé})\\]\nSkim this Reuter’s article about the company’s résumé model.\n\nExplain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the results produced from this biased data?"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-10-rigid-data-collection-systems",
    "href": "activities/L05-slr-model-eval.html#exercise-10-rigid-data-collection-systems",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 10: Rigid data collection systems",
    "text": "Exercise 10: Rigid data collection systems\nWhen working with categorical variables, we’ve seen that our units of observation fall into neat groups. Reality isn’t so discrete. For example, check out questions 6 and 9 on page 2 of the 2020 US Census. With your group, discuss the following:\n\nWhat are a couple of issues you see with these questions?\nWhat impact might this type of data collection have on a subsequent analysis of the census responses and the policies it might inform?\nCan you think of a better way to write these questions while still preserving the privacy of respondents?\n\nFOR A DEEPER DISCUSSION: Read Chapter 4 of Data Feminism on “What gets counted counts”."
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "href": "activities/L05-slr-model-eval.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 11: Presenting data: “Elevating emotion and embodiment”",
    "text": "Exercise 11: Presenting data: “Elevating emotion and embodiment”\nNote: The following example highlights work done by W.E.B. Du Bois in the late 1800s / early 1900s. His work uses language common to that time period and addresses the topic of slavery.\nThe types of visualizations we’ve been learning in this course are standard practice, hence widely understood. Yet these standard visualizations can also suppress the lived experiences of people represented in the data, hence can miss the larger point. W.E.B. Du Bois (1868–1963), a “sociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer, and editor”1, was a pioneer in elevating emotion and embodiment in data visualization. For the Paris World Fair of 1900, Du Bois and his team of students from Atlanta University presented 60 data visualizations of the Black experience in America, less than 50 years after the abolishment of slavery. To this end, Du Bois noted that “I wanted to set down its aim and method in some outstanding way which would bring my work to notice by the thinking world.” That is, he wanted to increase the impact of his work by partnering technical visualizations with design that better connects to lived experiences. Check out:\n\nAn article by Allen Hillery (@AlDatavizguy).\nA complete set of the data visualizations provided by Anthony Starks (@ajstarks).\n\nDiscuss your observations. In what ways do you think the W.E.B. Du Bois visualizations might have been more effective at sharing his work than, say, plainer bar charts?\nFOR A DEEPER DISCUSSION AND MORE MODERN EXAMPLES: Read Chapter 3 of Data Feminism on the principle of elevating emotion and embodiment, i.e. the value of “multiple forms of knowledge, including the knowledge that comes from people as living, feeling bodies in the world.”"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#reflection",
    "href": "activities/L05-slr-model-eval.html#reflection",
    "title": "Simple linear regression: model evaluation",
    "section": "Reflection",
    "text": "Reflection\nWhat has stuck with you most in our exploration of model evaluation? Why\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-1-is-the-model-correct-1",
    "href": "activities/L05-slr-model-eval.html#exercise-1-is-the-model-correct-1",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nThe red curved trend line shows a clear downward trend around 85 degrees, which contextually makes plenty of sense—extremely hot days would naturally see less riders. Overall the combination of the upward trend and downward trend makes for a curved relationship that is not captured well by a straight line of best fit. Specifically, a simple linear regression model would violate the Linearity assumption.\n\n# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE, color = \"red\") +\n    geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-2-residual-plots-1",
    "href": "activities/L05-slr-model-eval.html#exercise-2-residual-plots-1",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 2: Residual plots",
    "text": "Exercise 2: Residual plots\nThe residual plot shows a lingering trend in the residuals—the blue curve traces the trend in the residuals, and it does not lie flat on the y = 0 line. This again suggests that the Linearity assumption is violated.\n\nbike_model &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n\n# Check out the residual plot for bike_model\nggplot(bike_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model-1",
    "href": "activities/L05-slr-model-eval.html#exercise-3-whats-incorrect-about-this-model-1",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 3: What’s incorrect about this model?",
    "text": "Exercise 3: What’s incorrect about this model?\n\n# Import the data\nmammals &lt;- read_csv(\"https://mac-stat.github.io/data/mammals.csv\")\n\n# Check it out\nhead(mammals)\n## # A tibble: 6 × 4\n##    ...1 animal            body brain\n##   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n## 1     1 Arctic fox        3.38  44.5\n## 2     2 Owl monkey        0.48  15.5\n## 3     3 Mountain beaver   1.35   8.1\n## 4     4 Cow             465    423  \n## 5     5 Grey wolf        36.3  120. \n## 6     6 Goat             27.7  115\n\n# Construct the model\nmammal_model &lt;- lm(brain ~ body, mammals)\n\n# Check it out\nsummary(mammal_model)\n## \n## Call:\n## lm(formula = brain ~ body, data = mammals)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -810.07  -88.52  -79.64  -13.02 2050.33 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 91.00440   43.55258    2.09   0.0409 *  \n## body         0.96650    0.04766   20.28   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 334.7 on 60 degrees of freedom\n## Multiple R-squared:  0.8727, Adjusted R-squared:  0.8705 \n## F-statistic: 411.2 on 1 and 60 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n# Scatterplot of brain weight (y) vs body weight (x)\n# Include a model trend line (i.e. a representation of mammal_model)\nggplot(mammals, aes(y = brain, x = body)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n# Residual plot for mammal_model\nggplot(mammal_model, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\nThe biggest issue here is that the assumption of equal variance is violated. There’s much greater variability in the residuals as the predictions increase. This is because there’s much greater variability in the brain weights (y) as body weights (x) increase."
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-4-exploring-mammals-1",
    "href": "activities/L05-slr-model-eval.html#exercise-4-exploring-mammals-1",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 4: Exploring mammals",
    "text": "Exercise 4: Exploring mammals\nAnswers will vary."
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition-1",
    "href": "activities/L05-slr-model-eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition-1",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the model.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that’s explained by the model (the variance of the predictions) and the variability that’s left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\n“Good” models have residuals that don’t deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe first row corresponds to the weaker model. We can tell because the points are much more dispersed from the trend line than in the second row. Recall that the correlation metric measures how closely clustered points are about a straight line of best fit, so we would expect the correlation to be lower for the first row than the second row.\nThe variance of the residuals is much lower for the second row—the residuals are all quite small. This indicates a stronger model."
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-6-r-squared-interpretations-1",
    "href": "activities/L05-slr-model-eval.html#exercise-6-r-squared-interpretations-1",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 6: R-squared Interpretations",
    "text": "Exercise 6: R-squared Interpretations\n\nsummary(bike_model)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3607.1  -959.2  -153.8   998.2  3304.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -667.916    251.608  -2.655  0.00811 ** \n## temp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1310 on 729 degrees of freedom\n## Multiple R-squared:  0.2961, Adjusted R-squared:  0.2952 \n## F-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16\n\nMultiple R-squared: 0.2961\nInterpretation: 29.61% of the variation in number of registered riders on any given day can be explained by the variation in temperature (specifically, what temperature it “feels” like it is)."
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercise-7-further-exploring-r-squared-1",
    "href": "activities/L05-slr-model-eval.html#exercise-7-further-exploring-r-squared-1",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 7: Further exploring R-squared",
    "text": "Exercise 7: Further exploring R-squared\nIn this exercise, we’ll look at data from a synthetic dataset called Anscombe’s quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\nhead(anscombe)\n##   x1 x2 x3 x4   y1   y2    y3   y4\n## 1 10 10 10  8 8.04 9.14  7.46 6.58\n## 2  8  8  8  8 6.95 8.14  6.77 5.76\n## 3 13 13 13  8 7.58 8.74 12.74 7.71\n## 4  9  9  9  8 8.81 8.77  7.11 8.84\n## 5 11 11 11  8 8.33 9.26  7.81 8.47\n## 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nAll of these models have close to the same intercept, slope, and R-squared!\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\n## \n## Call:\n## lm(formula = y1 ~ x1, data = anscombe)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.92127 -0.45577 -0.04136  0.70941  1.83882 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0001     1.1247   2.667  0.02573 * \n## x1            0.5001     0.1179   4.241  0.00217 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6665, Adjusted R-squared:  0.6295 \n## F-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\nsummary(anscombe_mod2)\n## \n## Call:\n## lm(formula = y2 ~ x2, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.9009 -0.7609  0.1291  0.9491  1.2691 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)    3.001      1.125   2.667  0.02576 * \n## x2             0.500      0.118   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.237 on 9 degrees of freedom\n## Multiple R-squared:  0.6662, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\nsummary(anscombe_mod3)\n## \n## Call:\n## lm(formula = y3 ~ x3, data = anscombe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.1586 -0.6146 -0.2303  0.1540  3.2411 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0025     1.1245   2.670  0.02562 * \n## x3            0.4997     0.1179   4.239  0.00218 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6663, Adjusted R-squared:  0.6292 \n## F-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\nsummary(anscombe_mod4)\n## \n## Call:\n## lm(formula = y4 ~ x4, data = anscombe)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -1.751 -0.831  0.000  0.809  1.839 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   3.0017     1.1239   2.671  0.02559 * \n## x4            0.4999     0.1178   4.243  0.00216 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.236 on 9 degrees of freedom\n## Multiple R-squared:  0.6667, Adjusted R-squared:  0.6297 \n## F-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nBut when we look at the scatterplots, they all look substantially different, and we would want to approach our modeling differently for each one:\n\nx1 and y1: A linear model seems appropriate for this data.\nx2 and y2: The scatterplot is clearly curved—a “linear” regression model with squared terms, for example, would be more appropriate for this data. (We’ll talk more about ways to handle nonlinear relationships soon!)\nx3 and y3: There is a very clear outlier at about x3 = 13 that we would want to dig into to better understand the context. After that investigation, we might consider removing this outlier and refitting the model.\nx4 and y4: There is clearly something strange going on with most of the cases having an x4 value of exactly 8. We would not want to jump straight into modeling. Instead, we should dig deeper to find out more about this data.\n\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)"
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#exercises-8---11",
    "href": "activities/L05-slr-model-eval.html#exercises-8---11",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercises 8 - 11",
    "text": "Exercises 8 - 11\nNo solutions for these exercises. These require longer discussions, not discrete answers."
  },
  {
    "objectID": "activities/L05-slr-model-eval.html#footnotes",
    "href": "activities/L05-slr-model-eval.html#footnotes",
    "title": "Simple linear regression: model evaluation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://en.wikipedia.org/wiki/W._E._B._Du_Bois↩︎"
  },
  {
    "objectID": "activities/L25-f-tests.html#nested-models",
    "href": "activities/L25-f-tests.html#nested-models",
    "title": "Nested Models & F-Tests",
    "section": "Nested Models",
    "text": "Nested Models\n“Nested models” are models where the covariates of one model are a subset of another model. As an example, consider the following models for estimating the association between forced expiratory volume (FEV) and smoking status:\nModel 1:\n\\[\nE[FEV \\mid smoke] = \\beta_0 + \\beta_1 smoke\n\\]\nModel 2:\n\\[\nE[FEV \\mid smoke, age] = \\beta_0 + \\beta_1 smoke + \\beta_2 age\n\\] Here, Model 1 is “nested” inside Model 2, since the covariates included in Model 1 (only smoke) are a subset of those in Model 2 (both smoke and age).\nAn example of non-nested models are…\nModel 3:\n\\[\nE[FEV \\mid smoke, height] = \\beta_0 + \\beta_1 smoke + \\beta_2 height\n\\]\nModel 4:\n\\[\nE[FEV \\mid smoke, sex] = \\beta_0 + \\beta_1 smoke + \\beta_2 sex\n\\]\nHere, even though Model 3 and Model 4 both contain smoke as explanatory variables, neither is nested in the other, since sex is not a part of Model 3, and height is not a part of Model 4."
  },
  {
    "objectID": "activities/L25-f-tests.html#learning-goals",
    "href": "activities/L25-f-tests.html#learning-goals",
    "title": "Nested Models & F-Tests",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this activity, you should be able to:\n\nDetermine if one model is nested within another\nDetermine which null and alternative hypotheses require an f-test\nDetermine which f-tests require the use of the anova function in R vs. the overall f-test given in regular regression output\nInterpret the results of an f-test in context"
  },
  {
    "objectID": "activities/L25-f-tests.html#readings-and-videos",
    "href": "activities/L25-f-tests.html#readings-and-videos",
    "title": "Nested Models & F-Tests",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease read the following notes and watch the following video before class:\n\nReading: Section 7.3.4 in the STAT 155 Notes\nVideo: F-Tests (script)"
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-1-nested-models",
    "href": "activities/L25-f-tests.html#exercise-1-nested-models",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 1: Nested Models",
    "text": "Exercise 1: Nested Models\n\nWhich of the following models are nested in the model \\(E[A \\mid B, C, D] = \\beta_0 + \\beta_1 D + \\beta_2 B + \\beta_3 C + \\beta_4 B * C\\)?\n\n\nModel 1: \\(E[A \\mid B] = \\beta_0 + \\beta_1 B\\)\nModel 2: \\(E[A \\mid B, D] = \\beta_0 + \\beta_1 B + \\beta_2 D\\)\nModel 3: \\(E[B \\mid C] = \\beta_0 + \\beta_1 C\\)\nModel 4: \\(E[A \\mid B, C, D] = \\beta_0 + \\beta_1 B + \\beta_2 C + \\beta_3 D\\)\nModel 5: \\(E[A \\mid B, C, D] = \\beta_0 + \\beta_1 C + \\beta_2 B + \\beta_3 D + \\beta_4 B * D\\)\nModel 6: \\(E[A \\mid D] = \\beta_0 + \\beta_1 D\\)\n\n\nConsider the following models involving variables A, B, C, and D:\n\n\nModel 1: \\(E[A \\mid B] = \\beta_0 + \\beta_1 B\\)\nModel 2: \\(E[A \\mid B, C] = \\beta_0 + \\beta_1 B + \\beta_2 C\\)\nModel 3: \\(E[A \\mid B, C] = \\beta_0 + \\beta_1 B + \\beta_2 C + \\beta_3 BC\\)\nModel 4: \\(E[A \\mid C, D] = \\beta_0 + \\beta_1 C + \\beta_2 D\\)\nModel 5: \\(E[B \\mid A] = \\beta_0 + \\beta_1 A\\)\nModel 6: \\(E[B \\mid A, C] = \\beta_0 + \\beta_1 A + \\beta_2 C + \\beta_3 AC\\)\n\nDetermine for each of the following statements whether that statement is True or False.\n\nModel 1 is nested in Model 2\nModel 1 is nested in Model 3\nModel 1 is nested in Model 4\nModel 2 is nested in Model 3\nModel 3 is nested in Model 2\nModel 2 is nested in Model 6\n\n\nWhat is one (numeric) way to compare nested models? Explain how you would determine which model is “better” based on this metric."
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-2-f-tests",
    "href": "activities/L25-f-tests.html#exercise-2-f-tests",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 2: F-Tests",
    "text": "Exercise 2: F-Tests\nThis exercise involves the MacGrades.csv dataset, which contains a sub-sample (to help preserve anonymity) of every grade assigned to a former Macalester graduating class. For each of the 6414 rows of data, the following information is provided (with a few missing values):\n\nsessionID: A section ID number\nsid: A student ID number\ngrade: The grade obtained, as a numerical value (i.e. an A is a 4, an A- is a 3.67, etc.)\ndept: A department identifier (these have been made ambiguous to maintain anonymity)\nlevel: The course level (e.g. 100-, 200-, 300-, and 600-)\nsem: A semester identifier\nenroll: The section enrollment\niid: An instructor identifier (these have been made ambiguous to maintain anonymity)\n\n\n# load necessary packages\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readr)\n\n# load datasets\nMacGrades &lt;- read_csv(\"https://mac-stat.github.io/data/MacGrades.csv\")\n\nNOTE: Questions (a) and (b), since they are exploratory in nature, can suck up a lot of time if you let them! For the sake of getting to the rest of the activity, please spend no more than ~5 minutes on them.\n\nHypothesize two relationships between the variables in the dataset (pick any two relationships you want!). Your response should be written in a paragraph form.\n\n\nResponse Put your response here\n\n\nExplore the relationship between course grades and other variables in the data. Make two visualizations, and describe any patterns you observe.\nNote that the level variable is currently quantitative. For this activity, we’d like to treat it as categorical. Create a new variable level_cat so that we can consider level categorically in the following analysis.\nSuppose we are interested in the relationship between course level (categorical) and student grades. Using grade as your outcome variable, fit a linear regression model to investigate this question.\n\nComment on the nature of the relationship between course level and student grades (this should not be a coefficient interpretation, but instead a description of a general trend, or lack thereof).\n\nState the null and alternative hypotheses associated with the research question in part (d).\n\n\\[\nH_0:\n\\]\n\\[\nH_1:\n\\]\n\nWhat is the p-value associated with this hypothesis test? Do we have enough evidence to reject the null hypothesis, using a significance threshold of 0.05?\nSuppose we are interested in the relationship between course enrollment and student grades. Again, use grade as your outcome variable, and fit a linear regression model to investigate this question.\nState the null and alternative hypotheses associated with the research question in part (g).\n\n\\[\nH_0:\n\\]\n\\[\nH_1:\n\\]\n\nWhat is the p-value associated with this hypothesis test? Do we have enough evidence to reject the null hypothesis, using a significance threshold of 0.05?\n\n\nDo we need to conduct a nested F-test using the anova function to complete our hypothesis testing procedure for the research question posed in part (g)? Explain why or why not."
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-3-more-f-tests",
    "href": "activities/L25-f-tests.html#exercise-3-more-f-tests",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 3: More F-tests",
    "text": "Exercise 3: More F-tests\n\nSuppose we are now interested in the association between course grade and enrollment for classes of the same level. Write a model statement in the form \\(E[Y | X] = ...\\) that will produce a statistical model that will allow us to answer our scientific question. Replace Y and X, where appropriate, with response and predictor variables.\n\n\\[\nE[Y | X] = ___\n\\]\nWhich coefficient(s) in your model is the one that is relevant to your research question?\n\nWhat are the relevant null and alternative hypotheses that address the scientific question in part (a)?\nFit the model you wrote in part (a), calculate a p-value, and report the results of the hypothesis test in part (b)."
  },
  {
    "objectID": "activities/L25-f-tests.html#reflection",
    "href": "activities/L25-f-tests.html#reflection",
    "title": "Nested Models & F-Tests",
    "section": "Reflection",
    "text": "Reflection\nF-tests are useful when the null hypothesis you wish to test is such that more than one covariate is simultaneously equal to a specific number (typically zero). What scenarios, outside of those shown in this example, can you think of where a relevant scientific hypothesis you want to test involves more than one covariate being simultaneously equal to zero?\n\nResponse Put your response here."
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-4",
    "href": "activities/L25-f-tests.html#exercise-4",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 4",
    "text": "Exercise 4\nRepeat Exercise 3, supposing we are instead interested in the association between course grade and course level for classes of the same enrollment."
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-5-reference-categories",
    "href": "activities/L25-f-tests.html#exercise-5-reference-categories",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 5: Reference categories",
    "text": "Exercise 5: Reference categories\nOur final research question pertains to whether or not there is a relationship between course grade and department. Again, use course grade as the outcome variable in your linear regression model.\n\nState the null and alternative hypotheses in colloquial language associated with the relevant hypothesis test.\n\nH0:\nH1:\n\nFit a linear regression model, and conduct your hypothesis testing procedure to answer the research question posed in this Exercise. State your conclusions accordingly (you do not need to interpret any regression coefficients, just state and interpret the results of your hypothesis test!).\nAre any of the individual department p-values significant?\n\nWhat do these p-values tell us, and why is this not contradictory to your answer in part (b)?"
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-1-nested-models-1",
    "href": "activities/L25-f-tests.html#exercise-1-nested-models-1",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 1: Nested Models",
    "text": "Exercise 1: Nested Models\n\nModels 1, 2, 4 and 6.\n\n\n\nModel 1 is nested in Model 2 TRUE\nModel 1 is nested in Model 3 TRUE\nModel 1 is nested in Model 4 FALSE\nModel 2 is nested in Model 3 TRUE\nModel 3 is nested in Model 2 FALSE\nModel 2 is nested in Model 6 FALSE\n\n\nYou could compare the Adjusted \\(R^2\\) values from each model, and note that the one with a higher adjusted \\(R^2\\) is better by this metric. Multiple \\(R^2\\) would not be a good metric, because the larger model (within the nesting structure) will always have a higher \\(R^2\\) value."
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-2-f-tests-1",
    "href": "activities/L25-f-tests.html#exercise-2-f-tests-1",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 2: F-Tests",
    "text": "Exercise 2: F-Tests\n\nIt is reasonable to assume that course grade varies by department as well as course level and instructor. Certain instructors may grade more strictly (or curve more) than others, and similarly, this can vary across department due to cultural norms within the department. As the level of a course gets higher, I would expect grades to perhaps get lower, since courses with higher numbers are expected to be more difficult. Then again, students perhaps “care” more about such courses, and may put in more effort to get a higher grade. I doubt semester plays a significant role in determining course grades, though it is possible that Fall semester first-years or Spring semester seniors have worse grades, on average. We don’t have course year as a variable in our data, so we would be unable to examine this relationship. As enrollment in a course goes up, I would expect grades to decrease, since professors have less time to dedicate to individual students when course enrollment is high.\nExplore the relationship between course grades and other variables in the data. Make at least four visualizations, and describe any patterns you observe.\n\n\nlibrary(stringr)\n# Exploratory plots\n\n# course grade vs. enrollment\nMacGrades %&gt;%\n  ggplot(aes(enroll, grade)) +\n  geom_jitter() +\n  theme_classic() +\n  ggtitle(\"Course grades by enrollment numbers\")\n\n\n\n\n\n\n\n\n# course grade vs. level\nMacGrades %&gt;%\n  mutate(level = factor(level)) %&gt;%\n  ggplot(aes(y = grade, x = level)) +\n  geom_boxplot() +\n  ggtitle(\"Course grades by course level\")\n\n\n\n\n\n\n\n\n# course grade vs. level (treating grade as categorical)\nMacGrades %&gt;%\n  filter(!is.na(grade)) %&gt;%\n  mutate(level = factor(level),\n         grade = factor(grade)) %&gt;%\n  ggplot(aes(x = level, fill = grade)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_viridis_d(option = \"H\") +\n  theme_classic() +\n  ggtitle(\"Course grades by course level\")\n\n\n\n\n\n\n\n\n# course grade vs. semester\nMacGrades %&gt;%\n  filter(!is.na(grade)) %&gt;%\n  mutate(grade = factor(grade)) %&gt;%\n  ggplot(aes(x = sem, fill = grade)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_viridis_d(option = \"H\") +\n  theme_classic() +\n  ggtitle(\"Course grades by semester\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n# Let's do something fancy and check out how grades have changed over time... this will require\n# some string manipulation\n\nMacGrades$year &lt;- MacGrades$sem %&gt;%\n  str_replace(\"FA\", \"\") %&gt;%\n  str_replace(\"SP\", \"\") %&gt;%\n  str_replace(\"S1\", \"\") %&gt;%\n  str_replace(\"S2\", \"\") %&gt;% \n  str_replace(\"IT\", \"\") %&gt;% as.numeric()\n\nMacGrades %&gt;%\n  ggplot(aes(year, grade)) +\n  geom_jitter() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_classic() +\n  ggtitle(\"Course grades by year, with least-squares line\")\n\n\n\n\n\n\n\n\nIn general, course grades seem to be associated with enrollment numbers. Specifically, when enrollments are greater than 50, we see very few students receiving a course grade lower than a 2.0, which is different than when enrollments are fewer than 50 students. There does not appear to be a clear relationship between course grade and course level, with the exception of 600-level courses. In these cases, every student received either an A or A-. It does seem like the proportion of students who received lower than a 2.67 is greater for 100-level courses than the other course levels.\n\n\n\n\n# Make level categorical\nMacGrades &lt;- MacGrades %&gt;%\n  mutate(level = factor(level))\n\n\n\n\n\nmod &lt;- lm(grade ~ level, data = MacGrades)\nsummary(mod)\n## \n## Call:\n## lm(formula = grade ~ level, data = MacGrades)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.4776 -0.3492  0.2089  0.5224  0.6508 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  3.34924    0.01208 277.166  &lt; 2e-16 ***\n## level200     0.11183    0.01995   5.606 2.17e-08 ***\n## level300     0.09078    0.01949   4.659 3.25e-06 ***\n## level400     0.12835    0.03168   4.052 5.15e-05 ***\n## level600     0.63339    0.13624   4.649 3.41e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.5915 on 5704 degrees of freedom\n##   (437 observations deleted due to missingness)\n## Multiple R-squared:  0.01085,    Adjusted R-squared:  0.01016 \n## F-statistic: 15.65 on 4 and 5704 DF,  p-value: 9.713e-13\n\nWe observe that as course level goes up, course grades also tend to increase on average.\n\nState the null and alternative hypotheses associated with the research question in part (d).\n\n\\[\nH_0: \\beta_1 = \\beta_2 = \\beta_3 = \\beta_4 = 0\n\\]\n\\[\nH_1: \\text{One of } \\beta_1, \\beta_2, \\beta_3, \\beta_4 \\neq 0\n\\] In words, the null is that there is no relationship between course level and course grades, and the alternative is that there is some relationship (either positive or negative) between course level and course grades.\n\nThe p-value associated with this hypothesis test is 9.713 x \\(10^{-13}\\). We do have enough evidence to reject the null hypothesis.\n\n\n\nmod &lt;- lm(grade ~ enroll, data = MacGrades)\nsummary(mod)\n## \n## Call:\n## lm(formula = grade ~ enroll, data = MacGrades)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.4529 -0.3871  0.2265  0.5534  0.8448 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  3.4842350  0.0173790 200.485  &lt; 2e-16 ***\n## enroll      -0.0031336  0.0006683  -4.689 2.81e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.5934 on 5707 degrees of freedom\n##   (437 observations deleted due to missingness)\n## Multiple R-squared:  0.003838,   Adjusted R-squared:  0.003664 \n## F-statistic: 21.99 on 1 and 5707 DF,  p-value: 2.806e-06\n\n\n\n\n\\[\nH_0: \\beta_1 = 0\n\\]\n\\[\nH_1: \\beta_1 \\neq 0\n\\]\n\nThe p-value associated with this hypothesis test is 2.806 x \\(10^{-06}\\). We do have enough evidence to reject the null hypothesis. Note that this p-value could be obtained from either the overall model fit or from the individual coefficient for enroll (they are the same). They may be ever so slightly different when there are few observations in your dataset, but when there are a lot, they will be exactly identical.\n\n\nWe do not need to conduct an F-test, because our hypothesis test involves only a single regression coefficient, and therefore is readily obtained from the summary output of our linear model in R."
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-3-more-f-tests-1",
    "href": "activities/L25-f-tests.html#exercise-3-more-f-tests-1",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 3: More F-tests",
    "text": "Exercise 3: More F-tests\n\n\n\n\\[\nE[grade | enroll, level] = \\beta_0 + \\beta_1 enroll + \\beta_2 level200 + \\beta_3 level300 + \\beta_4 level400 + \\beta_5 level600\n\\]\nThe relevant coefficient that answers our scientific question is \\(\\beta_1\\), or the coefficient that corresponds to enrollment.\n\n\n\nThe relevant null and alternative hypotheses are:\n\\[\nH_0: \\beta_1 = 0\n\\] \\[\nH_1: \\beta_1 \\neq 0\n\\] We do not need to conduct an F-test to complete this hypothesis testing procedure, since our hypothesis involves only a single regression coefficient.\n\n\n\n\nmod &lt;- lm(grade ~ enroll + level, data = MacGrades)\nsummary(mod)\n## \n## Call:\n## lm(formula = grade ~ enroll + level, data = MacGrades)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.4916 -0.3481  0.1907  0.5162  0.7764 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  3.4091632  0.0219143 155.568  &lt; 2e-16 ***\n## enroll      -0.0022628  0.0006907  -3.276 0.001058 ** \n## level200     0.1040873  0.0200701   5.186 2.22e-07 ***\n## level300     0.0743387  0.0201066   3.697 0.000220 ***\n## level400     0.1118660  0.0320492   3.490 0.000486 ***\n## level600     0.6182478  0.1361974   4.539 5.76e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.591 on 5703 degrees of freedom\n##   (437 observations deleted due to missingness)\n## Multiple R-squared:  0.01271,    Adjusted R-squared:  0.01185 \n## F-statistic: 14.69 on 5 and 5703 DF,  p-value: 2.453e-14\n\nWe have statistically significant evidence of a relationship between enrollment and course grade, for courses of the same level (p = 0.001058). We reject the null hypothesis that there is no relationship between enrollment and course grade, adjusting for course level."
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-4-1",
    "href": "activities/L25-f-tests.html#exercise-4-1",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 4",
    "text": "Exercise 4\nOur model statement is identical to that in Exercise 3, but the relevant coefficients are \\(\\beta_2, \\beta_3, \\beta_4\\), and \\(\\beta_5\\).\nThe relevant null and alternative hypotheses are:\n\\[\nH_0: \\beta_2 = \\beta_3 = \\beta_4 = \\beta_5 = 0\n\\]\n\\[\nH_1: \\text{At least one of } \\beta_2, \\beta_3, \\beta_4, \\beta_5 \\neq 0\n\\]\nWe do need to conduct an F-test to complete this hypothesis testing procedure, since our hypothesis involves more than one regression coefficient.\n\n# Same model as in Question 10, we just now need to do an F-test!\nmod &lt;- lm(grade ~ enroll + level, data = MacGrades)\nsmaller_mod &lt;- lm(grade ~ enroll, data = MacGrades)\n\nanova(smaller_mod, mod)\n## Analysis of Variance Table\n## \n## Model 1: grade ~ enroll\n## Model 2: grade ~ enroll + level\n##   Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)    \n## 1   5707 2009.8                                 \n## 2   5703 1991.9  4    17.904 12.815 2.19e-10 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nWe have statistically significant evidence of a relationship between course level and course grade, for courses of the same enrollment (\\(p = 2.19 \\times 10^{-10}\\)). We reject the null hypothesis that there is no relationship between course level and course grade, adjusting for enrollment."
  },
  {
    "objectID": "activities/L25-f-tests.html#exercise-5-reference-categories-1",
    "href": "activities/L25-f-tests.html#exercise-5-reference-categories-1",
    "title": "Nested Models & F-Tests",
    "section": "Exercise 5: Reference categories",
    "text": "Exercise 5: Reference categories\n\n\n\nH0: There is no relationship between course grade and department.\nH1: There is some relationship between course grade and department.\n\n\n\n\nmod &lt;- lm(grade ~ dept, data = MacGrades)\nsummary(mod)\n## \n## Call:\n## lm(formula = grade ~ dept, data = MacGrades)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.5268 -0.2749  0.1475  0.4515  0.9039 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  3.5000000  0.4088676   8.560   &lt;2e-16 ***\n## deptb       -0.2536066  0.4155163  -0.610    0.542    \n## deptB       -0.2614286  0.4278948  -0.611    0.541    \n## deptC        0.0268398  0.4106338   0.065    0.948    \n## deptd       -0.1825995  0.4098240  -0.446    0.656    \n## deptD        0.0617623  0.4105399   0.150    0.880    \n## depte       -0.0162500  0.4122607  -0.039    0.969    \n## deptE        0.1391667  0.4416275   0.315    0.753    \n## deptF       -0.2251373  0.4104679  -0.548    0.583    \n## deptg        0.0956522  0.4176615   0.229    0.819    \n## deptG       -0.3303306  0.4105537  -0.805    0.421    \n## deptH       -0.0307813  0.4120495  -0.075    0.940    \n## depti       -0.1474011  0.4111711  -0.358    0.720    \n## deptI        0.0011538  0.4243020   0.003    0.998    \n## deptj       -0.0625248  0.4108867  -0.152    0.879    \n## deptJ       -0.2815172  0.4116777  -0.684    0.494    \n## deptk        0.0124521  0.4104311   0.030    0.976    \n## deptK       -0.2431624  0.4123474  -0.590    0.555    \n## deptL        0.0468000  0.4169648   0.112    0.911    \n## deptm        0.0224798  0.4099682   0.055    0.956    \n## deptM       -0.4039440  0.4099067  -0.985    0.324    \n## deptn        0.1487363  0.4111080   0.362    0.718    \n## deptN        0.1670000  0.4139469   0.403    0.687    \n## depto       -0.3616667  0.4255629  -0.850    0.395    \n## deptO        0.0066856  0.4100242   0.016    0.987    \n## deptp       -0.0139370  0.4120744  -0.034    0.973    \n## deptP       -0.1140000  0.4249077  -0.268    0.788    \n## deptq        0.0001132  0.4104076   0.000    1.000    \n## deptQ       -0.0644094  0.4120744  -0.156    0.876    \n## deptR       -0.0381579  0.4110139  -0.093    0.926    \n## depts       -0.0154839  0.4218507  -0.037    0.971    \n## deptS       -0.0247500  0.4139469  -0.060    0.952    \n## deptt       -0.0126923  0.4166562  -0.030    0.976    \n## deptT       -0.2733962  0.4165106  -0.656    0.512    \n## deptU       -0.1136842  0.4298486  -0.264    0.791    \n## deptV       -0.0242500  0.4189646  -0.058    0.954    \n## deptW       -0.0507164  0.4100863  -0.124    0.902    \n## deptX       -0.1189865  0.4116209  -0.289    0.773    \n## deptY        0.0814894  0.4174763   0.195    0.845    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.5782 on 5670 degrees of freedom\n##   (437 observations deleted due to missingness)\n## Multiple R-squared:  0.06037,    Adjusted R-squared:  0.05407 \n## F-statistic: 9.586 on 38 and 5670 DF,  p-value: &lt; 2.2e-16\n\nWe have statistically significant evidence of a relationship between department and course grades at a significance level of 0.05 (p-value &lt; 2.2 x \\(10^{-16}\\)). We reject the null hypothesis that there is no relationship between course grade and department.\n\n\n\nNone of the individual p-values for department are significant! These p-values tell us about whether or not there is a statistically significant difference in course grades between each respective department and the reference department (Department “A”). This doesn’t contradict our answer to part (b) because there are different hypothesis tests that answer different questions!"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#learning-goals",
    "href": "activities/L18-sampling-normal.html#learning-goals",
    "title": "The Normal model & sampling variation",
    "section": "Learning goals",
    "text": "Learning goals\n\nRecognize the difference between a population parameter and a sample estimate.\nReview the Normal probability model, a tool we’ll need to turn information in our sample data into inferences about the broader population.\nExplore the ideas of randomness, sampling distributions, and standard error through a class experiment. (We’ll define these more formally in the next class.)"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#readings-and-videos",
    "href": "activities/L18-sampling-normal.html#readings-and-videos",
    "title": "The Normal model & sampling variation",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease do the following videos and reading before class.\n\nReading: Section 6 Introduction, and Section 6.6 in the STAT 155 Notes\nVideo 1: exploration vs inference\nVideo 2: Normal probability model"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-1-using-the-normal-model",
    "href": "activities/L18-sampling-normal.html#exercise-1-using-the-normal-model",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 1: Using the Normal model",
    "text": "Exercise 1: Using the Normal model\nSuppose that the speeds of cars on a highway, in miles per hour, can be reasonably represented by the Normal model with a mean of 55mph and a standard deviation of 5mph from car to car:\n\\[\nX \\sim N(55, 5^2)\n\\]\n\nshaded_normal(mean = 55, sd = 5)\n\n\nProvide the (approximate) range of the middle 68% of speeds, and shade in the corresponding region on your Normal curve. NOTE: a is the lower end of the range and b is the upper end.\n\n\nshaded_normal(mean = 55, sd = 5, a = ___, b = ___)\n\n\nUse the 68-95-99.7 rule to estimate the probability that a car’s speed exceeds 60mph.\n\n\nYour response here\n\n\n# Visualize\nshaded_normal(mean = 55, sd = 5, a = 60)\n\n\nWhich of the following is the correct range for the probability that a car’s speed exceeds 67mph? Explain your reasoning.\n\n\nless than 0.0015\nbetween 0.0015 and 0.025\nbetween 0.025 and 0.16\ngreater than 0.16\n\n\nExplain your reasoning here\n\n\n# Visualize\nshaded_normal(mean = 55, sd = 5, a = 67)"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-2-z-scores",
    "href": "activities/L18-sampling-normal.html#exercise-2-z-scores",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 2: Z-scores",
    "text": "Exercise 2: Z-scores\nInherently important to all of our calculations above is how many standard deviations a value “X” is from the mean.\nThis distance is called a Z-score and can be calculated as follows:\n\\[\n\\text{Z-score} = \\frac{X - \\text{mean}}{\\text{sd}}\n\\]\nFor example (from Exercise 1), if I’m traveling 40 miles an hour, my Z-score is -3. That is, my speed is 3 standard deviations below the average speed:\n\n(40 - 55) / 5\n\n\nConsider 2 other drivers. Both drivers are speeding. Who do you think is speeding more, relative to the distributions of speed in their area?\n\nDriver A is traveling at 60mph on the highway where speeds are N(55, 5^2) and the speed limit is 55mph.\nDriver B is traveling at 36mph on a residential road where speeds are N(30, 3^2) and the speed limit is 30mph.\n\n\n\nPut your best guess (hypothesis) here\n\n\nCalculate the Z-scores for Drivers A and B.\n\n\n# Driver A\n\n\n# Driver B\n\n\nNow, based on the Z-scores, who is speeding more? NOTE: The below plots might provide some insights.\n\n\n# Driver A\nshaded_normal(mean = 55, sd = 5) + \n  geom_vline(xintercept = 60)\n\n# Driver B\nshaded_normal(mean = 30, sd = 3) + \n  geom_vline(xintercept = 36)  \n\n\nYour response here"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-3-parameter-vs-estimate",
    "href": "activities/L18-sampling-normal.html#exercise-3-parameter-vs-estimate",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 3: Parameter vs estimate",
    "text": "Exercise 3: Parameter vs estimate\nIt’s important to note that this dataset is by no means a comprehensive collection of films and their review scores–it does not contain every film that was released from 2014-2015, nor films released outside of that date range. The review scores are also frozen in time–all of these films have almost certainly accumulated additional reviews since the data were first collected.\nHowever, our stated goal is to make inferences about the overarching relationship between critic reviews and user reviews for all films (relatedly, we may want to use our model to make predictions about how user reviews are affected by critic reviews for films that may not even exist yet!). Can we actually make these inferences/predictions about a potentially infinite collection of films when all we have is a fairly limited subset of these?\n\nPopulations and Samples\nThis question points to two of the most important concepts in the field of statistical inference: populations and samples. Statisticians have many different ways of defining a population (depending on the questions they are asking), but for the purposes of this exercise, we can think of the population as the set of all possible films and all possible review scores that have been or could be catalogued on RottenTomatoes.\nOur dataset of 146 films is considered a sample of this population. A sample is simply a subset of observations taken from that population.\n\n\n\n\n\n\nSampling Criteria\n\n\n\n\n\nWhen we take a sample of data from a population, there is always some set of criteria used to determine how a sample is taken. This could be as simple as “we randomly selected 1% of all films catalogued on RottenTomatoes as of 4/1/2025”, or a more complex set of specific criteria (for this dataset, the sample was taken by selecting all films that had tickets for sale on Fandango on 8/24/2015, then further filtering to include films that have a Rotten Tomatoes rating, a RT User rating, a Metacritic score, a Metacritic User score, an IMDb score, and at least 30 fan reviews on Fandango.)\n\n\n\n\n\n“True” parameters versus estimates\nIn order to conduct statistical inference using linear regression, we must assume that there is some true, underlying, fixed intercept and slope \\(\\beta_0\\) and \\(\\beta_1\\), that describe the true linear relationship in the overall population that we’re interested in.\nIf we are modeling the relationship between UserScore and CriticScore on RottenTomatoes, The “true” underlying model we assume is thus:\n\\[\nUserScore_i = \\beta_0 + \\beta_1 CriticScore_i + e_i\n\\]\nHowever, the “true” values of \\(\\beta_0\\) and \\(\\beta_1\\) are typically impossible to know, because knowing them requires access to our entire population of interest (in this case, the review scores for every film that has been or will be released). When we fit a regression model using the sample that we do have, we are actually obtaining estimates of those true population parameters (note the notation change of putting a \\(\\hat{ }\\) on top of the Betas, to indicate that this is an estimate):\n\\[\nE[UserScore \\mid CriticScore] = \\hat{\\beta}_0 + \\hat{\\beta}_1 CriticScore\n\\]\nwhere our estimates are given by our model as \\(\\hat{\\beta}_0 = 32.3%\\), \\(\\hat{\\beta}_1 = 0.52%\\)\nFor the sake of this activity, let’s assume that these estimates are identical to the true population parameters.\n🚩🚩🚩 HOWEVER, be very careful not to make this assumption in other models you encounter.For this dataset, recall the specific sampling criteria that were used, which means these 146 films likely aren’t representative of the full population of films we’re interested in. This means that the estimates we obtained probably don’t match the true population parameters–they may or may not be close, but we don’t know for certain! 🚩🚩🚩\nBelow, we’ll simulate how parameter estimates are impacted by taking different samples. You’ll each take a random sample of 10 films in the dataset, and we’ll see if we can recover the presumed population parameters (i.e., the coefficient estimates we obtained from our model using all 146 films that were initially sampled).\nFirst, fill in your intuition below:\n\nDo you think every student will get the same set of 10 films?\n\n\nYour response here\n\n\nDo you think that your coefficient estimates will be the same as your neighbors’?\n\n\nYour responses here"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-4-random-sampling",
    "href": "activities/L18-sampling-normal.html#exercise-4-random-sampling",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 4: Random sampling",
    "text": "Exercise 4: Random sampling\n\nUse the sample_n() function to take a random sample of 2 films\n\n\n# Try running the following chunk A FEW TIMES\nsample_n(fandango, size = 2, replace = FALSE)\n\nReflect:\n\nHow do your results compare to your neighbors’?\n\n\nYour response here\n\n\nWhat is the role of size = 2? HINT: Remember you can look at function documentation by running ?sample_n in the console!\n\n\nYour response here\n\n\nWhat is the role of replace = FALSE? HINT: Remember you can look at function documentation by running ?sample_n in the console!\n\n\nYour response here\n\n\nNow, “set the seed” to 155 and re-try your sampling.\n\n\n# Try running the following FULL chunk A FEW TIMES\nset.seed(155)\nsample_n(fandango, size = 2, replace = FALSE)\n\nWhat changed?\n\nYour response here"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-5-take-your-own-sample",
    "href": "activities/L18-sampling-normal.html#exercise-5-take-your-own-sample",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 5: Take your own sample",
    "text": "Exercise 5: Take your own sample\nThe underlying random number generator plays a role in the random sample we happen to get. If we set.seed(some positive integer) before taking a random sample, we’ll get the same results.\nThis reproducibility is important:\n\nwe get the same results every time we render our qmd\nwe can share our work with others & ensure they get our same answers\nit wouldn’t be great if you submitted your work to, say, a journal and weren’t able to back up / confirm / reproduce your results!\n\nFollow the chunks below to obtain and use your own unique sample.\n\n# DON'T SKIP THIS STEP! \n# Set the random number seed to the digits of your own phone number (just the numbers)\nset.seed()\n\n# Take a sample of 10 films\nmy_sample &lt;- sample_n(fandango, size = 10, replace = FALSE)\nmy_sample                       \n\n\n# Plot the relationship of UserScore with CriticScore among your sample\nmy_sample %&gt;% \n  ggplot(aes(y = userscore_rt, x = criticscore_rt)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n# Model the relationship among your sample\nmy_model &lt;- lm(userscore_rt ~ criticscore_rt, data = my_sample)\ncoef(summary(my_model))[,1]\n\nREPORT YOUR WORK\nLog your intercept and slope sample estimates in this survey."
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-6-sampling-variation",
    "href": "activities/L18-sampling-normal.html#exercise-6-sampling-variation",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 6: Sampling variation",
    "text": "Exercise 6: Sampling variation\nRecall that we are assuming the population parameters are equal to the estimates we obtained from the model we fit using the initial sample of 146 films:\n\\[\nE[UserScore \\mid CriticScore] = 32.3 + 0.52 CriticScore\n\\]\nLet’s explore how our sample estimates of these parameters varied from student to student:\n\n# Import the experiment results\nlibrary(gsheet)\nresults &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/11OT1VnLTTJasp5BHSKulgJiCbSLiutv8mKDOfvvXZSo/edit?usp=sharing')\n\nPlot each student’s sample estimate of the model line (gray). How do these compare to the assumed population model (red)?\n\nfandango %&gt;% \n  ggplot(aes(y = userscore_rt, x = criticscore_rt)) +\n  geom_abline(data = results, aes(intercept = sample_intercept, slope = sample_slope, linetype=section), color = \"gray\") + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-7-sample-intercepts",
    "href": "activities/L18-sampling-normal.html#exercise-7-sample-intercepts",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 7: Sample intercepts",
    "text": "Exercise 7: Sample intercepts\nLet’s focus on just the sample estimates of the intercept parameter:\n\nresults %&gt;% \n  ggplot(aes(x = sample_intercept)) + \n  geom_density() + \n  geom_vline(xintercept = 32.3, color = \"red\")\n\nComment on the shape, center, and spread of these sample estimates and how they relate to the (assumed) population intercept (red line).\n\nYour response here"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-8-slopes",
    "href": "activities/L18-sampling-normal.html#exercise-8-slopes",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 8: Slopes",
    "text": "Exercise 8: Slopes\nSuppose we were to construct a density plot of the sample estimates of the criticscore_rt coefficient (i.e. the slopes).\n\nIntuitively, what shape do you think this plot will have?\n\n\nYour response here\n\n\nIntuitively, around what value do you think this plot will be centered?\n\n\nYour response here\n\n\nCheck your intuition:\n\n\nresults %&gt;% \n  ggplot(aes(x = sample_slope)) + \n  geom_density() + \n  geom_vline(xintercept = 0.52, color = \"red\")\n\n\nThinking back to the 68-95-99.7 rule, visually approximate the standard deviation among the sample slopes.\n\n\nYour response here"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-9-standard-error",
    "href": "activities/L18-sampling-normal.html#exercise-9-standard-error",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 9: Standard error",
    "text": "Exercise 9: Standard error\nYou’ve likely observed that the typical or mean slope estimate is roughly equal to the (assumed) population slope parameter of 0.52:\n\nresults %&gt;% \n  summarize(mean(sample_slope))\n\nThus the standard deviation of the slope estimates measures how far we might expect an estimate to fall from the (assumed) population slope parameter.\nThat is, it measures the typical or standard error in our sample estimates:\n\nresults %&gt;% \n  summarize(sd(sample_slope))\n\n\nRecall your sample estimate of the slope. How far is it from the population slope, 0.52?\n\n\nHow many standard errors does your estimate fall from the population slope? That is, what’s your Z-score?\n\n\nReflecting upon your Z-score, do you think your sample estimate was one of the “lucky” ones, or one of the “unlucky” ones?\n\n\nYour response here"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-1-using-the-normal-model-1",
    "href": "activities/L18-sampling-normal.html#exercise-1-using-the-normal-model-1",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 1: Using the Normal model",
    "text": "Exercise 1: Using the Normal model\n\n.\n\n\nshaded_normal(mean = 55, sd = 5, a = 50, b = 60)\n\n\n\n\n\n\n\n\n\n16% (32/2)\nbetween 0.0015 and 0.025"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-2-z-scores-1",
    "href": "activities/L18-sampling-normal.html#exercise-2-z-scores-1",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 2: Z-scores",
    "text": "Exercise 2: Z-scores\n\nintuition\n.\n\n\n# Driver A\n(60 - 55) / 5\n## [1] 1\n\n# Driver B\n(36 - 30) / 3\n## [1] 2\n\n\nB, they are 2 standard deviations above the mean (the speed limit)"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-3-parameter-vs-estimate-1",
    "href": "activities/L18-sampling-normal.html#exercise-3-parameter-vs-estimate-1",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 3: Parameter vs estimate",
    "text": "Exercise 3: Parameter vs estimate\nintuition"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-4-random-sampling-1",
    "href": "activities/L18-sampling-normal.html#exercise-4-random-sampling-1",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 4: Random sampling",
    "text": "Exercise 4: Random sampling\n\n# Observe that the 2 films change every time & differ from your neighbors' samples\nsample_n(fandango, size = 2, replace = FALSE)\n## # A tibble: 2 × 3\n##   film                userscore_rt criticscore_rt\n##   &lt;chr&gt;                      &lt;int&gt;          &lt;int&gt;\n## 1 Song of the Sea               92             99\n## 2 The Last Five Years           60             60\n\n\n# Observe that the 2 films are the same every time & are the same as your neighbors' samples\nset.seed(155)\nsample_n(fandango, size = 2, replace = FALSE)\n## # A tibble: 2 × 3\n##   film            userscore_rt criticscore_rt\n##   &lt;chr&gt;                  &lt;int&gt;          &lt;int&gt;\n## 1 Unbroken                  70             51\n## 2 Project Almanac           46             34"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-5-take-your-own-sample-1",
    "href": "activities/L18-sampling-normal.html#exercise-5-take-your-own-sample-1",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 5: Take your own sample",
    "text": "Exercise 5: Take your own sample\nwill vary from student to student"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-6-sampling-variation-1",
    "href": "activities/L18-sampling-normal.html#exercise-6-sampling-variation-1",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 6: Sampling variation",
    "text": "Exercise 6: Sampling variation\nThe sample estimates vary around the population model:\n\n# Import the experiment results\nlibrary(gsheet)\nresults &lt;- gsheet2tbl('https://docs.google.com/spreadsheets/d/11OT1VnLTTJasp5BHSKulgJiCbSLiutv8mKDOfvvXZSo/edit?usp=sharing')\n\nfandango %&gt;% \n  ggplot(aes(y = userscore_rt, x = criticscore_rt)) +\n  geom_abline(data = results, aes(intercept = sample_intercept, slope = sample_slope, linetype=section), color = \"gray\") + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-7-sample-intercepts-1",
    "href": "activities/L18-sampling-normal.html#exercise-7-sample-intercepts-1",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 7: Sample intercepts",
    "text": "Exercise 7: Sample intercepts\nThe intercepts are roughly normal, centered around the intercept of the larger sample (32.3), and range from roughly 15.88 to 50.106:\n\nresults %&gt;% \n  ggplot(aes(x = sample_intercept)) + \n  geom_density() + \n  geom_vline(xintercept = 32.3, color = \"red\")"
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-8-slopes-1",
    "href": "activities/L18-sampling-normal.html#exercise-8-slopes-1",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 8: Slopes",
    "text": "Exercise 8: Slopes\n\nintuition\nintuition\nCheck your intuition:\n\n\nresults %&gt;% \n  ggplot(aes(x = sample_slope)) + \n  geom_density() + \n  geom_vline(xintercept = 0.52, color = \"red\")\n\n\n\n\n\n\n\n\n\nWill vary, but should roughly be 0.14."
  },
  {
    "objectID": "activities/L18-sampling-normal.html#exercise-9-standard-error-1",
    "href": "activities/L18-sampling-normal.html#exercise-9-standard-error-1",
    "title": "The Normal model & sampling variation",
    "section": "Exercise 9: Standard error",
    "text": "Exercise 9: Standard error\n\nFor example, suppose my estimate were 0.7:\n\n\n0.7 - 0.52\n## [1] 0.18\n\n\nFor example, suppose my estimate were 0.7. Then my Z-score is (0.7 - 0.52) / 0.14 = 1.2857143\nThis is somewhat subjective. But we’ll learn that if your estimate is within 2 sd of the actual slope, i.e. your Z-score is between -2 and 2, you’re pretty “lucky”."
  },
  {
    "objectID": "activities/L15-prob-odds.html#learning-goals",
    "href": "activities/L15-prob-odds.html#learning-goals",
    "title": "Probability & Odds",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nDistinguish between probabilities and odds, and convert one to the other\nMake appropriate visualizations for displaying relationships between multiple categorical variables (mosaic plots, stacked bar plots, etc.)"
  },
  {
    "objectID": "activities/L15-prob-odds.html#readings-and-videos",
    "href": "activities/L15-prob-odds.html#readings-and-videos",
    "title": "Probability & Odds",
    "section": "Readings and videos",
    "text": "Readings and videos\nGo through the following reading or videos before class:\n\nReading: Sections 2.5, and the Section 6.2 introduction in the STAT 155 Notes\nVideos:\n\nProb vs. Odds vs. Log Odds (script)\nCalculating Probability and Odds from 2x2 Tables (script)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L15-prob-odds.html#exercise-1-exploring-first-steps-enrollment-and-gestational-age",
    "href": "activities/L15-prob-odds.html#exercise-1-exploring-first-steps-enrollment-and-gestational-age",
    "title": "Probability & Odds",
    "section": "Exercise 1: Exploring First Steps enrollment and Gestational Age",
    "text": "Exercise 1: Exploring First Steps enrollment and Gestational Age\nA baby born prior to 37 weeks is considered premature. In figuring out whether we have evidence that the First Steps program is associated with better birth outcomes than those not in the First Steps program, we can look at whether the individuals in the program are more likely to have preterm babies.\nBelow, we make a 2x2 table in R:\n\n# 2x2 Table: preterm vs. First Steps\nfirststeps %&gt;% \n    count(preterm, firstep)\n\nYou may be wondering why this is called a 2x2 table, when it looks as though the table has four rows and three columns. The data can be re-arranged (and usually is, in a formal report) as follows…\n\ntable(firststeps$preterm, firststeps$firstep)\n\n… but it’s much cleaner to code up the original way!\n\nHow many birth parents were enrolled in the First Steps program? Which rows did you use to calculate this number?\nWhat percentage of people in the study were enrolled in the First Steps program? Recall: there were 2500 participants! You can confirm this by adding up the entire third column of the table\nHow many birth parents who were enrolled in First Steps had a premature baby?\nWhat percentage of birth parents in First Steps had a premature baby? Think carefully about the numerator and denominator you use to calculate this!\nWhat percentage of birth parents who had a premature baby were enrolled in First Steps? Think carefully about the numerator and denominator you use to calculate this!\n\nCongratulations! If you’ve made it to this point, you already intuitively know what marginal and conditional probabilities are. Formally,\n\na marginal probability, denoted \\(P(A)\\) for an event \\(A\\), is the probability that \\(A\\) occurs overall. You calculated the marginal probability that people were enrolled in First Steps in part (b)! In this case, the denominator used to calculate the probability was the total number of people in the study.\na conditional probability, denoted \\(P(A | B)\\) for events \\(A\\) and \\(B\\), is the probability that \\(A\\) occurs given that event \\(B\\) occurs. You calculated the conditional probability that a premature baby was born given that a parent was in First Steps in part (d)! In this case, the denominator used to calculate the probability was the total number of birth parents in the First Steps program. You also calculated a conditional probability in part (e).\n\nUsing formal probability notation, write the probabilities you calculated in parts (b), (d), and (e) as\n\n\n\\(P(\\text{First Steps})\\) = ___\n\n\n\n\n\\(P(\\text{Preterm} | \\text{First Steps})\\) = ___\n\n\n\n\n\\(P(___ | ___)\\) = __\n\n\nNote that the conditional probabilities calculated in parts (d) and (e) are not the same! This is because which event you condition on alters the denominator, and the event you’re interested in alters the numerator.\n\nTo determine if gestational age differed by enrollment in First Steps, we’ll want to calculate the conditional probability that a baby is born prematurely given First Steps enrollment (done!), and given that a parent is not enrolled in First Steps. Use the 2x2 table to calculated this conditional probability.\n\n\n\\(P(\\text{Preterm} |\\text{Not in First Steps})\\) = ___\n\n\nA ratio of conditional probabilities, where the conditioning event is the same for both, tells us how many times more likely an event is to occur for one group compared to another. Calculate how many times more likely a birth parent enrolled in First Steps is to have a premature baby compared to birth parents not enrolled in First Steps.\n\n\\[\n\\frac{(\\text{Preterm} | \\text{First Steps})}{P(\\text{Preterm} | \\text{Not in First Steps})} =\n\\]\n\nWrite a two-sentence summary, appropriate for a general audience, summarizing your results in terms of a ratio of probabilities. Does gestational age appear to differ greatly by First Steps enrollment? What does this imply about the effectiveness of the First Steps program, if anything?\nTo go along with your summary, let’s make a visualization! There are three basic options for visualization two categorical variables. All are perfectly valid, but some may be more useful to read than others, and display different information.\n\nYou’ll see one other fancier option (called a mosaic plot) in the next activity.\n\n# Side-by-side bar chart\nfirststeps %&gt;%\n  ggplot(aes(firstep, fill = preterm)) +\n  geom_bar(position = \"dodge\") +\n  theme_classic()\n\n# Stacked bar chart\nfirststeps %&gt;%\n  ggplot(aes(firstep, fill = preterm)) +\n  geom_bar() +\n  theme_classic()\n\n# Stacked relative frequency bar chart\nfirststeps %&gt;%\n  ggplot(aes(firstep, fill = preterm)) +\n  geom_bar(position = \"fill\") +\n  theme_classic()\n\nBonus Question: Which of the above three plots allows you to directly see the conditional probabilities we calculated previously?\n\nPlace your answer here"
  },
  {
    "objectID": "activities/L15-prob-odds.html#exercise-2-exploring-first-steps-enrollment-and-low-birthweights",
    "href": "activities/L15-prob-odds.html#exercise-2-exploring-first-steps-enrollment-and-low-birthweights",
    "title": "Probability & Odds",
    "section": "Exercise 2: Exploring First Steps enrollment and Low birthweights",
    "text": "Exercise 2: Exploring First Steps enrollment and Low birthweights\nAnother birth outcome we can consider when comparing those enrolled in the First Steps program to those not enrolled is birth weight. A baby is considered to have low birth weight when birth weight is less than 2500 grams.\n\nFill in the code below to make a table comparing low_bwt to firsteps.\n\n\n# 2x2 Table: low_bwt vs. First Steps\n\n\nUsing the table from part (a), calculate the following conditional probabilities:\n\n\n\\(P(\\text{Low birth weight} | \\text{First Steps})\\) = ___\n\n\n\\(P(\\text{Normal birth weight} | \\text{First Steps})\\) = ___\n\n\n\\(P(\\text{Low birth weight} | \\text{Not in First Steps})\\) = ___\n\n\n\\(P(\\text{Normal birth weight} | \\text{Not in First Steps})\\) = ___\n\nAn additional numerical summary that is often useful when working with indicator variables is odds. Odds are defined as\n\\[\nOdds = \\frac{p}{1 - p}\n\\]\nwhere \\(p\\) is the probability that an event occurs. Therefore, if we know \\(p\\), we can calculate the odds that an event happens! Similarly, if we know the odds, we can calculate \\(p\\) using\n\\[\np = Odds / (1 + Odds)\n\\]\nWe can also calculate odds from our 2x2 (or 3x2, 4x2, …) tables. In colloquial terms, probabilities are “yes”’s over “total”’s, and odds are “yes”’s over “no’s”. In pseudo-math:\n\\[\np = \\frac{Yes}{Total}, \\quad Odds = \\frac{Yes}{No}\n\\] We’ll see why odds are especially useful when we have binary outcome variables in a regression model in the next activity. For now, note that they’re also commonly used in lots of contexts: sports, gambling, case-control studies, etc.\n\nUsing your answer to part (b), calculate the following odds\n\n\n\\(Odds(\\text{Low birth weight} | \\text{First Steps})\\) = ___\n\n\n\\(Odds(\\text{Normal birth weight} | \\text{First Steps})\\) = ___\n\n\n\\(Odds(\\text{Low birth weight} | \\text{Not in First Steps})\\) = ___\n\n\n\\(Odds(\\text{Normal birth weight} | \\text{Not in First Steps})\\) = ___\n\n\nA ratio of odds (called an odds ratio, unsurprisingly) tells us how many times higher or greater the odds are that an event occurs, comparing one group to another. This might sound irritatingly circular. The key here is that while odds ratios do allow us to compare binary/indicator outcomes from one group to one another, they do not tell us how much more likely an event is to occur comparing those same groups. This is distinct from ratios of probabilities!\n\nCalculate the ratio of the odds of having a low-birth-weight baby, comparing those in the First Steps program to those not in the First Steps program (i.e., how many times higher/lower is the odds of having a low-birth-weight baby among those in First Steps as compared to those not in First Steps?)\n\nWrite a two-sentence summary, appropriate for a general audience, summarizing your results in terms of an odds ratio. Does birth weight appear to differ greatly by First Steps enrollment? What does this imply about the effectiveness of the First Steps program, if anything?\nTo go along with your summary, add code below to make one of the three visualization options we tried out in Exercise 1.\n\n\n# Insert code here..."
  },
  {
    "objectID": "activities/L15-prob-odds.html#reflection",
    "href": "activities/L15-prob-odds.html#reflection",
    "title": "Probability & Odds",
    "section": "Reflection",
    "text": "Reflection\nPrompt\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L15-prob-odds.html#render-your-work",
    "href": "activities/L15-prob-odds.html#render-your-work",
    "title": "Probability & Odds",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check."
  },
  {
    "objectID": "activities/L15-prob-odds.html#exercise-3-conditional-vs.-marginal-probabilities",
    "href": "activities/L15-prob-odds.html#exercise-3-conditional-vs.-marginal-probabilities",
    "title": "Probability & Odds",
    "section": "Exercise 3: Conditional vs. Marginal probabilities",
    "text": "Exercise 3: Conditional vs. Marginal probabilities\nSuppose we select a person at random from the entire global population. For each of the following probabilities, which do you think is bigger? Explain your reasoning.\n\nP(lung cancer) or P(lung cancer | smoker)\n\n\nYour response here\n\n\nP(likes McDonald’s) or P(likes McDonald’s | vegetarian)\n\n\nYour response here\n\n\nP(smart | Mac grad) or P(Mac grad | smart)\n\n\nYour response here"
  },
  {
    "objectID": "activities/L15-prob-odds.html#exercise-4-probability-practice",
    "href": "activities/L15-prob-odds.html#exercise-4-probability-practice",
    "title": "Probability & Odds",
    "section": "Exercise 4: Probability practice",
    "text": "Exercise 4: Probability practice\nLet’s explore whether birthweight of a baby varies by whether or not it was the first child that a mother had, and whether this relationship differs by First Steps enrollment. We make a table below:\n\nfirststeps %&gt;%\n  count(firstchild, low_bwt, firstep)\n\n\nWhat is the probability that a mother enrolled in First steps who is having their first child, has a baby who is born at a low birthweight? Calculate your answer, and write it using formal probability notation.\n\n\nP(___ | ___) = ?\n\n\nWhat is the probability that a mother not enrolled in First steps who is having their first child, has a baby who is born at a low birthweight? Calculate your answer, and write it using formal probability notation.\n\n\nP(___ | ___) = ?\n\n\nWhat is the probability that a mother’s first child has a low birthweight? Calculate your answer, and write it using formal probability notation.\n\n\nP(___ | ___) = ?\n\n\nHow many times more likely is a child to be born at a low birthweight, comparing children who are the first born to those not first born?\n\n\nP(___ | ) / P( | ___) = ?"
  },
  {
    "objectID": "activities/L15-prob-odds.html#exercise-1-exploring-first-steps-enrollment-and-gestational-age-1",
    "href": "activities/L15-prob-odds.html#exercise-1-exploring-first-steps-enrollment-and-gestational-age-1",
    "title": "Probability & Odds",
    "section": "Exercise 1: Exploring First Steps enrollment and Gestational Age",
    "text": "Exercise 1: Exploring First Steps enrollment and Gestational Age\n\n# 2x2 Table: preterm vs. First Steps\nfirststeps %&gt;% \n    count(preterm, firstep)\n## # A tibble: 4 × 3\n##   preterm firstep     n\n##   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n## 1 No            0  1879\n## 2 No            1   343\n## 3 Yes           0   218\n## 4 Yes           1    60\n\n\n343 + 60 = 403 parents were enrolled in the First Steps program. I used both rows of the table where firstep = 1.\n16.12% of people in the study were enrolled in First Steps!\n\n\n403 / 2500\n## [1] 0.1612\n\n\n60 birth parents\n14.89% of birth parents in First Steps had a premature baby.\n\n\n60 / 403\n## [1] 0.1488834\n\n\nThe total number of birth parents who had a premature baby was 218 + 60 = 278. Of those. 60 were enrolled in First Steps. Therefore, 21.58% of birth parents who had a premature baby were enrolled in First Steps.\n\n\n60/278\n## [1] 0.2158273\n\nUsing formal probability notation, we can write\n\n\n\\(P(\\text{First Steps})\\) = .1612\n\n\n\n\n\\(P(\\text{Preterm} | \\text{First Steps})\\) = .1488\n\n\n\n\n\\(P(\\text{First Steps} | \\text{Preterm})\\) = .2158\n\n\n\n\n\n\n\\(P(\\text{Preterm} | \\text{Not in First Steps})\\) = 218 / (218 + 1879) = 0.103958\n\n\n\n\n\\[\n\\frac{(\\text{Preterm} | \\text{First Steps})}{P(\\text{Preterm} | \\text{Not in First Steps})} = .1488 / 0.103958 = 1.43\n\\]\n\nParents in this study in the First Steps program are 1.43 times more likely to have a premature birth than those not enrolled in the First Steps program, indicating that gestational age does differ by First Steps enrollment. This implies that enrollment in the First Steps program may not be associated with better birth outcomes, as measured by gestational age.\n\nNote: However, you may argue that this is not a fair comparison, or that this summary is not what researchers were actually interested in! Ideally, we would compare birth outcomes from mothers in the First Steps program to the birth outcomes from those same mothers not in the First Steps program, to determine if the program made a positive impact. This idea hints at a sub-field of statistics called causal inference and the idea of a counterfactual (“what would have happened if…”). Take more statistics classes to learn about other methods for approaching this question!\n\n\n\n\n# Side-by-side bar chart\nfirststeps %&gt;%\n  ggplot(aes(firstep, fill = preterm)) +\n  geom_bar(position = \"dodge\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n# Stacked bar chart\nfirststeps %&gt;%\n  ggplot(aes(firstep, fill = preterm)) +\n  geom_bar() +\n  theme_classic()\n\n\n\n\n\n\n\n\n# Stacked relative frequency bar chart\nfirststeps %&gt;%\n  ggplot(aes(firstep, fill = preterm)) +\n  geom_bar(position = \"fill\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nBonus Question: Which of the above three plots allows you to directly see the conditional probabilities we calculated previously?\n\nThe stacked relative frequency bar chart!"
  },
  {
    "objectID": "activities/L15-prob-odds.html#exercise-2-exploring-first-steps-enrollment-and-low-birthweights-1",
    "href": "activities/L15-prob-odds.html#exercise-2-exploring-first-steps-enrollment-and-low-birthweights-1",
    "title": "Probability & Odds",
    "section": "Exercise 2: Exploring First Steps enrollment and Low birthweights",
    "text": "Exercise 2: Exploring First Steps enrollment and Low birthweights\n\n\n\n\n# 2x2 Table: low_bwt vs. First Steps\nfirststeps %&gt;%\n  count(low_bwt, firstep)\n## # A tibble: 4 × 3\n##   low_bwt firstep     n\n##   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n## 1 low           0   102\n## 2 low           1    25\n## 3 not low       0  1995\n## 4 not low       1   378\n\n\n\n\n\n\\(P(\\text{Low birth weight} | \\text{First Steps})\\) = 25 / (25 + 378) = 0.062\n\n\n\\(P(\\text{Normal birth weight} | \\text{First Steps})\\) = 378 / (25 + 378) = 0.938\n\n\n\\(P(\\text{Low birth weight} | \\text{Not in First Steps})\\) = 102 / (102 + 1995) = 0.049\n\n\n\\(P(\\text{Normal birth weight} | \\text{Not in First Steps})\\) = 1995 / (102 + 1995) = 0.951\n\n\n\n\n\n\\(Odds(\\text{Low birth weight} | \\text{First Steps})\\) = 0.062 / (1 - 0.062) = 0.06609808\n\n\n\\(Odds(\\text{Normal birth weight} | \\text{First Steps})\\) = 0.938 / (1 - 0.938) = 15.12903\n\n\n\\(Odds(\\text{Low birth weight} | \\text{Not in First Steps})\\) = 0.049 / (1 - 0.049) = 0.05152471\n\n\n\\(Odds(\\text{Normal birth weight} | \\text{Not in First Steps})\\) = 0.951 / (1 - 0.951) = 19.40816\n\n\n\n\n\n0.06609808 / 0.05152471\n## [1] 1.282842\n\n\nThe odds of having a low birth weight baby are 1.28 times higher for those enrollment in First Steps compared to those not in First Steps. Just as in Exercise 1, this implies that the First Steps program may not be associated with improved birth outcomes (with the same caveats as given in the answer to 1 (h)).\nTo go along with your summary, add code below to make one of the three visualization options we tried out in Exercise 1.\n\n\n# Stacked relative frequency bar chart (with some fancy aesthetics)\nfirststeps %&gt;%\n  mutate(Birthweight = low_bwt %&gt;% str_to_title()) %&gt;%\n  ggplot(aes(firstep, fill = Birthweight)) +\n  geom_bar(position = \"fill\") +\n  theme_classic() +\n  scale_fill_viridis_d(option = \"H\") +\n  labs(x = \"First Steps\", title = \"Birthweight by First Steps Enrollment\") +\n  scale_x_continuous(breaks = c(0,1), labels = c(\"Not Enrolled\", \"Enrolled\"))"
  },
  {
    "objectID": "activities/L15-prob-odds.html#exercise-3-conditional-vs.-marginal-probabilities-1",
    "href": "activities/L15-prob-odds.html#exercise-3-conditional-vs.-marginal-probabilities-1",
    "title": "Probability & Odds",
    "section": "Exercise 3: Conditional vs. Marginal probabilities",
    "text": "Exercise 3: Conditional vs. Marginal probabilities\nSuppose we select a person at random from the entire global population. For each of the following probabilities, which do you think is bigger? Explain your reasoning.\n\nP(lung cancer | smoker) is likely bigger, since lung cancer is more rare in the general population than it is among smokers.\nP(likes McDonald’s) is likely bigger, since vegetarians don’t likely like McDonald’s very much (few options that they can eat).\nP(smart | Mac grad) is likely bigger, because there are very few Mac grads relative to the global population. Lots of people are smart, few are Mac grads."
  },
  {
    "objectID": "activities/L15-prob-odds.html#exercise-4-probability-practice-1",
    "href": "activities/L15-prob-odds.html#exercise-4-probability-practice-1",
    "title": "Probability & Odds",
    "section": "Exercise 4: Probability practice",
    "text": "Exercise 4: Probability practice\nLet’s explore whether birth weight of a baby varies by whether or not it was the first child that a mother had, and whether this relationship differs by First Steps enrollment. We make a table below:\n\nfirststeps %&gt;%\n  count(firstchild, low_bwt, firstep)\n## # A tibble: 8 × 4\n##   firstchild low_bwt firstep     n\n##   &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n## 1 No         low           0    43\n## 2 No         low           1    13\n## 3 No         not low       0  1080\n## 4 No         not low       1   198\n## 5 Yes        low           0    59\n## 6 Yes        low           1    12\n## 7 Yes        not low       0   915\n## 8 Yes        not low       1   180\n\n\nWhat is the probability that a mother enrolled in First steps who is having their first child, has a baby who is born at a low birthweight? Calculate your answer, and write it using formal probability notation.\n\n\nP( | , ) = 12 / (12 + 180) = 0.0625\n\n\nWhat is the probability that a mother not enrolled in First steps who is having their first child, has a baby who is born at a low birthweight? Calculate your answer, and write it using formal probability notation.\n\n\nP( | , ) = 59 / (59 + 915) = 0.06057495\n\n\nWhat is the probability that a mother’s first child has a low birthweight? Calculate your answer, and write it using formal probability notation.\n\n\nP( | ) = (59 + 12) / (59 + 12 + 915 + 180) = 0.06089194\n\n\nHow many times more likely is a child to be born at a low birthweight, comparing children who are the first born to those not first born?\n\n\nP( | ) / P( | ) = ((59 + 12) / (59 + 12 + 915 + 180)) / ((43 + 13) / (43 + 13 + 1080 + 198)) = 1.450533"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#learning-goals",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#learning-goals",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Learning goals",
    "text": "Learning goals\nLet \\(\\beta\\) be some population parameter and \\(\\hat{\\beta}\\) be a sample estimate of \\(\\beta\\). Our goals for the day are to:\n\nuse simulation to solidify our understanding of sampling distributions and standard errors\nexplore and compare two approaches to approximating the sampling distribution of \\(\\hat{\\beta}\\):\n\nCentral Limit Theorem (CLT)\nbootstrapping\n\nexplore the impact of sample size on sampling distributions and standard errors"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#readings-and-videos",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#readings-and-videos",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease watch/do the following videos and readings before class:\n\nReading: Section 6.7 in the STAT 155 Notes\nVideo 1: sampling distributions\nVideo 2: Central Limit Theorem\nVideo 3: bootstrapping"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#reflect",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#reflect",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "REFLECT",
    "text": "REFLECT\nGreat! We have two options. Here are some things to think about / reflect on:\n\nWe can approximate the sampling distribution and standard error using the CLT. BUT:\n\nthe quality of this approximation hinges upon the validity of the Central Limit theorem which hinges upon the validity of the theoretical model assumptions, as well as a large sample size\nthe CLT uses theoretical formulas for the standard error estimates, thus can feel a little mysterious without a solid foundation in probability theory\n\nWe can approxiate the sampling distribution and standard error using bootstrapping. BUT:\n\nit feels magical. The statistical theory behind bootstrapping is quite complicated, and there are certain obscure cases (none that we will encounter in Stat 155) where the assumptions underlying bootstrapping fail to hold\n\n\nNeither approach is perfect, but they complement one another. Bootrapping in particular, while it cannot and should not replace the CLT, gives us some nice intuition behind the idea of resampling, which is fundamental for hypothesis testing (which we’ll get to shortly!).\n\nReflect: Before testing them out, what questions do you have about either approach? What do you think would help you build more intuition for the CLT and/or bootstrapping? Does one approach resonate with you more than the other?"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-1-500-samples-of-size-10",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-1-500-samples-of-size-10",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 1: 500 samples of size 10",
    "text": "Exercise 1: 500 samples of size 10\nRecall that we can sample 10 observations from our dataset using sample_n():\n\n# Run this chunk a few times to explore the different samples you get\nfish %&gt;% \n  sample_n(size = 10, replace = TRUE)\n\nWe can also take a sample and then use the data to estimate the model:\n\n# Run this chunk a few times to explore the different sample models you get\nfish %&gt;% \n  sample_n(size = 10, replace = TRUE) %&gt;% \n  with(lm(Concen ~ Length))\n\nWe can also take multiple unique samples and build a sample model from each.\nThe code below obtains 500 separate samples of 10 fish, and stores the model estimates from each:\n\n# Set the seed so that we all get the same results\nset.seed(155)\n\n# Store the sample models\nsample_models_10 &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 10, replace = TRUE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n\n# Check it out\nhead(sample_models_10)\ndim(sample_models_10)\n\n\nWhat’s the point of the do() function?!? If you’ve taken any COMP classes, what process do you think do() is a shortcut for?\nWhat is stored in the Intercept, Length, and r.squared columns of the results?\nWe’ll obtain a bootstrapping distribution of \\(\\hat{\\beta}_1\\) by taking many (500, in this case) different samples of every fish in our dataset (171 of them) and exploring the degree to which \\(\\hat{\\beta}_1\\) varies from sample to sample.\n\nEdit the code below to obtain a bootstrapping distribution.\n\n# Set the seed so that we all get the same results\nset.seed(155)\n\n# Store the sample models\nsample_models_boot &lt;- mosaic::do(___)*(\n  fish %&gt;% \n    sample_n(size = ___, replace = TRUE) %&gt;% \n    with(lm(Concen ~ Length))\n)"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-2-why-resampling-replace-true",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-2-why-resampling-replace-true",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 2: Why “resampling” (replace = TRUE)?",
    "text": "Exercise 2: Why “resampling” (replace = TRUE)?\nLet’s wrap our minds around the idea of resampling, before coming back to our boostrapping distribution, using a small example of 5 fish:\n\n# Define data\nsmall_sample &lt;- data.frame(\n  id = 1:5,\n  Length = c(44, 43, 54, 52, 40))\n\nsmall_sample\n\nThis sample has a mean Length of 46.6 cm:\n\nsmall_sample %&gt;% \n  summarize(mean(Length))\n\n\nThe chunk below samples 5 fish without replacement from our small_sample of 5 fish, and calculates their mean length. Run it several times. How do the sample and resulting mean change?\n\n\nsample_1 &lt;- sample_n(small_sample, size = 5, replace = FALSE)\nsample_1\n\nsample_1 %&gt;% \n  summarize(mean(Length))\n\n\nSampling our sample without replacement merely returns our original sample. Instead, resample 5 fish from our small_sample with replacement. Run it several times. What do you notice about the samples? About their mean lengths?\n\n\nsample_2 &lt;- sample_n(small_sample, size = 5, replace = TRUE)\nsample_2\n\nsample_2 %&gt;% \n  summarize(mean(Length))\n\nResampling our sample provides insight into the variability, hence potential error, in our sample estimates. (This works better when we have a sample bigger than 5!) As you observed in part b, each resample might include some fish from the original sample several times and others not at all.\nBonus Fact: Sampling with replacement also ensures that our resampled observations are independent, which we need in order for bootstrapping to “work”!"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-3-sampling-distribution",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-3-sampling-distribution",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 3: Sampling distribution",
    "text": "Exercise 3: Sampling distribution\nCheck out the resulting 500 bootstrapped sample models:\n\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_abline(data = sample_models_boot, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nLet’s focus on the slopes of these 500 sample models.\nA plot of the 500 slopes approximates the sampling distribution of the sample slopes.\n\nsample_models_boot %&gt;% \n  ggplot(aes(x = Length)) + \n  geom_density() + \n  geom_vline(xintercept = 0.05813, color = \"red\") \n\nDescribe the sampling distribution:\n\nWhat’s its general shape?\nWhere is it roughly centered?\nRoughly what’s its spread / i.e. what’s the range of estimates you observed?"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-4-standard-error",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-4-standard-error",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 4: Standard error",
    "text": "Exercise 4: Standard error\nFor a more rigorous assessment of the spread among the sample slopes, let’s calculate their standard deviation:\n\nsample_models_boot %&gt;% \n  summarize(sd(Length))\n\nRecall: The standard deviation of sample estimates is called a “standard error”.\nIt measures the typical distance of a sample estimate from the actual population value.\nCompare the bootstrapped standard error to the standard error reported from our regression model (see the Std. Error column):\n\ncoef(summary(fish_model))\n\nAre they roughly equivalent?\n\nYour response here"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-5-central-limit-theorem-clt",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-5-central-limit-theorem-clt",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 5: Central Limit Theorem (CLT)",
    "text": "Exercise 5: Central Limit Theorem (CLT)\nRecall that the CLT assumes that, so long as our sample size is “big enough”, the sampling distribution of the sample slope will be Normal.\nSpecifically, all possible sample slopes will vary Normally around the population slope.\n\nDo your simulation results support this assumption? Why or why not?\nWant more intuition into the CLT? Watch this video explanation using bunnies and dragons: https://www.youtube.com/watch?v=jvoxEYmQHNM"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-6-using-the-clt",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-6-using-the-clt",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 6: Using the CLT",
    "text": "Exercise 6: Using the CLT\nLet \\(\\hat{\\beta}_1\\) be an estimate of the (super)population slope parameter \\(\\beta_1\\) calculated from a sample of 10 fish (sample_models_10).\nEstimate the standard error of the slope from these resampled estimates\n\n# Hint: Adapt the code from Exercise 5...\n\nYou should get a SE of roughly 0.026.\nThus, by the CLT, the sampling distribution of \\(\\hat{\\beta}_1\\) is:\n\\[\\hat{\\beta}_1 \\sim N(\\beta_1, 0.26^2)\\]\nUse this result with the 68-95-99.7 property of the Normal model to understand the potential error in a slope estimate.\n\nThere are many possible samples of 10 fish. What percent of these will produce an estimate \\(\\hat{\\beta}_1\\) that’s within 0.052, i.e. 2 standard errors, of the actual population slope \\(\\beta_1\\)?\nMore than 2 standard errors from \\(\\beta_1\\)?\nMore than 0.079, i.e. 3 standard errors, above \\(\\beta_1\\)?"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-7-clt-and-the-68-95-99.7-rule",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-7-clt-and-the-68-95-99.7-rule",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 7: CLT and the 68-95-99.7 Rule",
    "text": "Exercise 7: CLT and the 68-95-99.7 Rule\nFill in the blanks below to complete some general properties assumed by the CLT:\n\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 1 st. err. of \\(\\beta_1\\)\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 2 st. err. of \\(\\beta_1\\)\n___% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 3 st. err. of \\(\\beta_1\\)"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-8-increasing-sample-size",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-8-increasing-sample-size",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 8: Increasing sample size",
    "text": "Exercise 8: Increasing sample size\nNow that we have a sense of the potential variability and error in sample estimates, let’s consider the impact of sample size.\nSuppose we were to increase our sample size from n = 10 to n = 50 or n = 100 fish. What impact do you anticipate this having on our sample estimates of the population parameters:\n\nDo you expect there to be more or less variability among the sample model lines?\nAround what value would you expect the sampling distribution of sample slopes to be centered?\nWhat general shape would you expect that sampling distribution to have?\nIn comparison to estimates based on the samples of size 10, do you think the estimates based on samples of size 50 will be closer to or farther from the true slope (on average)?"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-9-500-samples-of-size-n",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-9-500-samples-of-size-n",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 9: 500 samples of size n",
    "text": "Exercise 9: 500 samples of size n\nLet’s increase the sample size in our simulation.\nFill in the blanks to take 500 samples of size 50, and build a sample model from each.\n\nset.seed(155)\nsample_models_50 &lt;- mosaic::do(___)*(\n  fish %&gt;% \n    ___(size = ___, replace = FALSE) %&gt;% \n    ___(___(Concen ~ Length))\n)\n\n# Check it out\nhead(sample_models_50)\n\nSimilarly, take 500 samples of size 100, and build a sample model from each.\n\nset.seed(155)\nsample_models_100 &lt;- mosaic::do(___)*(\n  fish %&gt;% \n    ___(size = ___, replace = FALSE) %&gt;% \n    ___(___(Concen ~ Length))\n)\n\n# Check it out\nhead(sample_models_100)"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-10-impact-of-sample-size-part-i",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-10-impact-of-sample-size-part-i",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 10: Impact of sample size (part I)",
    "text": "Exercise 10: Impact of sample size (part I)\nCompare and contrast the 500 sets of sample models when using samples of size 10, 50, and 100.\n\n# 500 sample models using samples of size 10\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_10, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n# 500 sample models using samples of size 50\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_50, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n# 500 sample models using samples of size 100\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_100, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\nWhat happens to our sample models as sample size increases? Was this what you expected?"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-11-impact-of-sample-size-part-ii",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-11-impact-of-sample-size-part-ii",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 11: Impact of sample size (part II)",
    "text": "Exercise 11: Impact of sample size (part II)\nLet’s focus on just the sampling distributions of our 500 slope estimates \\(\\hat{\\beta}_1\\).\nFor easy comparison, plot the estimates based on samples of size 10, 50, and 100 on the same frame:\n\n# Don't think too hard about this code!\n# Combine the estimates & sample size into a new data set\n# Then plot it\n\ndata.frame(estimates = c(sample_models_10$Length, sample_models_50$Length, sample_models_100$Length),\n           sample_size = rep(c(\"10\",\"50\",\"100\"), each = 500)) %&gt;% \n  mutate(sample_size = fct_relevel(sample_size, c(\"10\", \"50\", \"100\"))) %&gt;% \n  ggplot(aes(x = estimates, color = sample_size)) + \n  geom_density() + \n  geom_vline(xintercept = 0.05813, color = \"red\", linetype = \"dashed\") + \n  labs(title = \"Sampling distributions of the sample slope\")\n\n\nHow do the shapes, centers, and spreads of these sampling distributions compare? Was this what you expected?"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-12-properties-of-sampling-distributions",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-12-properties-of-sampling-distributions",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 12: Properties of sampling distributions",
    "text": "Exercise 12: Properties of sampling distributions\nIn light of your observations, complete the following statements about the sampling distribution of the sample slope.\n\nFor all sample sizes, the shape of the sampling distribution is roughly ___ and the sampling distribution is roughly centered around ___, the sample estimate from our original data.\nAs sample size increases:\nThe average sample slope estimate INCREASES / DECREASES / IS FAIRLY STABLE.\nThe standard error of the sample slopes INCREASES / DECREASES / IS FAIRLY STABLE.\nThus, as sample size increases, our sample slopes become MORE RELIABLE / LESS RELIABLE."
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-1-500-samples-of-size-10-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-1-500-samples-of-size-10-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 1: 500 samples of size 10",
    "text": "Exercise 1: 500 samples of size 10\n\ndo() repeats the code within the parentheses as many times as you tell it. do()` is a shortcut for a for loop.\n500 different sample estimates of the model\n\n\n\n# Set the seed so that we all get the same results\nset.seed(155)\n\n# Store the sample models\nsample_models_boot &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 171, replace = TRUE) %&gt;% \n    with(lm(Concen ~ Length))\n)"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-2-why-resampling-replace-true-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-2-why-resampling-replace-true-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 2: Why “resampling” (replace = TRUE)?",
    "text": "Exercise 2: Why “resampling” (replace = TRUE)?\n\nThe sample and the mean are the same every time!\nIf we rerun the code below multiple times, we’ll get different samples every time! Note that some of the observations are repeated (this is because of replace = TRUE), but we actually obtain variation in our samples and their mean lengths.\n\n\nsample_2 &lt;- sample_n(small_sample, size = 5, replace = TRUE)\nsample_2\n##   id Length\n## 1  2     43\n## 2  4     52\n## 3  2     43\n## 4  5     40\n## 5  2     43\n\nsample_2 %&gt;% \n  summarize(mean(Length))\n##   mean(Length)\n## 1         44.2"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-3-sampling-distribution-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-3-sampling-distribution-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 3: Sampling distribution",
    "text": "Exercise 3: Sampling distribution\n\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_abline(data = sample_models_boot, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\nsample_models_boot %&gt;% \n  ggplot(aes(x = Length)) + \n  geom_density() + \n  geom_vline(xintercept = 0.05813, color = \"red\") \n\n\n\n\n\n\n\n\n\nThe sampling distribution is symmetric, unimodal, and shaped like a bell curve!\nIt is roughly centered at the slope calculated from our entire sample!\nMost of the estimates lie within the range 0.04 to 0.075."
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-5-standard-error",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-5-standard-error",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 5: Standard error",
    "text": "Exercise 5: Standard error\n\n# boostrapped se\nsample_models_boot %&gt;% \n  summarize(sd(Length))\n##    sd(Length)\n## 1 0.005664586\n\n# CLT se\ncoef(summary(fish_model))\n##                Estimate  Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -1.13164542 0.213614796 -5.297598 3.617750e-07\n## Length       0.05812749 0.005227593 11.119359 6.641225e-22\n\nThey are basically identical! Both are about 0.005."
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-5-central-limit-theorem-clt-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-5-central-limit-theorem-clt-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 5: Central Limit Theorem (CLT)",
    "text": "Exercise 5: Central Limit Theorem (CLT)\nRecall that the CLT assumes that, so long as our sample size is “big enough”, the sampling distribution of the sample slope will be Normal.\nSpecifically, all possible sample slopes will vary Normally around the population slope.\n\nDo your simulation results support this assumption? Why or why not?\n\n\nYes! They support this assumption because the shape of sampling distribution is roughly normal (i.e. bell-shaped)."
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-6-using-the-clt-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-6-using-the-clt-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 6: Using the CLT",
    "text": "Exercise 6: Using the CLT\n\n# Hint: Adapt the code from Exercise 5...\nsample_models_10 %&gt;% \n  summarize(sd(Length))\n##   sd(Length)\n## 1 0.02532877\n\n\n95%\n100% - 95% = 5%\n(100 - 99.7)/2 = 0.15% (Note that we divide by two here, because we only want those above 3 SEs, not either above or below!)"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-7-clt-and-the-68-95-99.7-rule-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-7-clt-and-the-68-95-99.7-rule-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 7: CLT and the 68-95-99.7 Rule",
    "text": "Exercise 7: CLT and the 68-95-99.7 Rule\n\n68% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 1 st. err. of \\(\\beta_1\\)\n95% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 2 st. err. of \\(\\beta_1\\)\n99.7% of samples will produce \\(\\hat{\\beta}_1\\) estimates within 3 st. err. of \\(\\beta_1\\)"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-8-increasing-sample-size-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-8-increasing-sample-size-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 8: Increasing sample size",
    "text": "Exercise 8: Increasing sample size\nIntuition, no wrong answer."
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-9-500-samples-of-size-n-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-9-500-samples-of-size-n-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 9: 500 samples of size n",
    "text": "Exercise 9: 500 samples of size n\n\nset.seed(155)\nsample_models_50 &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 50, replace = FALSE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n\n# Check it out\nhead(sample_models_50)\n##   Intercept     Length     sigma r.squared        F numdf dendf .row .index\n## 1 -1.310864 0.06393644 0.5646473 0.4846643 45.14316     1    48    1      1\n## 2 -1.503983 0.06887405 0.6112830 0.5333146 54.85302     1    48    1      2\n## 3 -1.730214 0.07140026 0.5940694 0.4561970 40.26725     1    48    1      3\n## 4 -1.213346 0.05948225 0.5561451 0.4712989 42.78853     1    48    1      4\n## 5 -1.221643 0.05925447 0.5471569 0.5190808 51.80887     1    48    1      5\n## 6 -1.384057 0.06532957 0.5610290 0.5400105 56.35021     1    48    1      6\n\nSimilarly, take 500 samples of size 100, and build a sample model from each.\n\nset.seed(155)\nsample_models_100 &lt;- mosaic::do(500)*(\n  fish %&gt;% \n    sample_n(size = 100, replace = FALSE) %&gt;% \n    with(lm(Concen ~ Length))\n)\n\n# Check it out\nhead(sample_models_100)\n##    Intercept     Length     sigma r.squared         F numdf dendf .row .index\n## 1 -0.9745758 0.05400227 0.5965267 0.3361746  49.62917     1    98    1      1\n## 2 -1.1187614 0.05655020 0.5864780 0.4173361  70.19301     1    98    1      2\n## 3 -1.3507522 0.06512980 0.5629381 0.5332227 111.95023     1    98    1      3\n## 4 -1.5201200 0.06712467 0.5220515 0.5113787 102.56432     1    98    1      4\n## 5 -1.0181036 0.05525131 0.5746367 0.4031468  66.19447     1    98    1      5\n## 6 -1.1369532 0.05868566 0.5773007 0.4378596  76.33367     1    98    1      6"
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-10-impact-of-sample-size-part-i-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-10-impact-of-sample-size-part-i-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 10: Impact of sample size (part I)",
    "text": "Exercise 10: Impact of sample size (part I)\n\n# 500 sample models using samples of size 10\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_10, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\n\n# 500 sample models using samples of size 50\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_50, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\n\n# 500 sample models using samples of size 100\nfish %&gt;% \n  ggplot(aes(x = Length, y = Concen)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  geom_abline(data = sample_models_100, \n              aes(intercept = Intercept, slope = Length), \n              color = \"gray\", size = 0.25) + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\n\n\nThe sample model lines become less and less variable from sample to sample."
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-11-impact-of-sample-size-part-ii-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-11-impact-of-sample-size-part-ii-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 11: Impact of sample size (part II)",
    "text": "Exercise 11: Impact of sample size (part II)\n\n# Don't think too hard about this code!\n# Combine the estimates & sample size into a new data set\n# Then plot it\n\ndata.frame(estimates = c(sample_models_10$Length, sample_models_50$Length, sample_models_100$Length),\n           sample_size = rep(c(\"10\",\"50\",\"100\"), each = 500)) %&gt;% \n  mutate(sample_size = fct_relevel(sample_size, c(\"10\", \"50\", \"100\"))) %&gt;% \n  ggplot(aes(x = estimates, color = sample_size)) + \n  geom_density() + \n  geom_vline(xintercept = 0.05813, color = \"red\", linetype = \"dashed\") + \n  labs(title = \"Sampling distributions of the sample slope\")\n\n\n\n\n\n\n\n\n\nNo matter the sample size, the sample estimates are normally distributed around the population slope. But as sample size increases, the variability of the sample estimates decreases."
  },
  {
    "objectID": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-12-properties-of-sampling-distributions-1",
    "href": "activities/L19-20-sampling-dist-clt-bootstrap.html#exercise-12-properties-of-sampling-distributions-1",
    "title": "Sampling distributions, the CLT, and Bootstrapping",
    "section": "Exercise 12: Properties of sampling distributions",
    "text": "Exercise 12: Properties of sampling distributions\nIn light of your observations, complete the following statements about the sampling distribution of the sample slope.\n\nFor all sample sizes, the shape of the sampling distribution is roughly normal and the sampling distribution is roughly centered around 0.05813, the sample estimate from our original data.\nAs sample size increases:\nThe average sample slope estimate IS FAIRLY STABLE.\nThe standard error of the sample slopes DECREASES.\nThus, as sample size increases, our sample slopes become MORE RELIABLE."
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#learning-goals",
    "href": "activities/L21-confidence-intervals.html#learning-goals",
    "title": "Confidence intervals",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nConstruct (approximate) confidence intervals by hand using the 68-95-99.7 rule\nConstruct exact confidence intervals in R\nInterpret confidence intervals in context by referring to the coefficient of interest\nUse confidence intervals to make statements about whether there appear to be true population relationships, changes, and differences"
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#readings-and-videos",
    "href": "activities/L21-confidence-intervals.html#readings-and-videos",
    "title": "Confidence intervals",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease complete the following reading before class.\n\nReading: Section 7 Introduction, Section 7.1, Section 7.2 (stop when you get to 7.2.4.3 Confidence Intervals for Prediction) in the STAT 155 Notes\n\nOptionally you can use the following videos as a companion to the reading (not in place of the reading):\n\nVideo 1: Introduction to Confidence Intervals\nVideo 2: Confidence Intervals: Construction and Interpretation"
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#exercise-1",
    "href": "activities/L21-confidence-intervals.html#exercise-1",
    "title": "Confidence intervals",
    "section": "Exercise 1",
    "text": "Exercise 1\nResearch question: Is the relationship between wind speed (windspeed) (in miles per hour) and number of riders (riders_total) different across weekdays and weekends?\n\nPart a\nConstruct and interpret a visualization that would address this question.\n\n\nPart b\nFit a regression model that would address our research question. (Should it be a linear or a logistic regression model?) Interpret only the coefficient of interest.\n\nmod_bikes &lt;- ___\n\n\n\nPart c\n\nConstruct an approximate 95% confidence interval (CI) for the coefficient of interest by hand using the 68-95-99.7 rule.\nCompare your confidence interval to the one given by confint() which gives an exact confidence interval. (The columns give the lower and upper ends of the CI for each coefficient.)\nInterpret the exact confidence interval in context.\nIs zero in the interval? Do we have evidence for a real difference in the windspeed-riders relationship across weekends and weekdays?\n\n\n# By hand (you fill in)\n\n\n# Using confint()\nconfint(mod_bikes, level = 0.95)\n\n\n\nPart d\nLet’s see if these results agree when looking at adjusted R-squared.\nFit another regression model that does not have the coefficient of interest from your Part b model. Compare the adjusted R-squared values between this model and the Part b model. Explain your findings."
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#exercise-2",
    "href": "activities/L21-confidence-intervals.html#exercise-2",
    "title": "Confidence intervals",
    "section": "Exercise 2",
    "text": "Exercise 2\nResearch question: How different is holiday ridership from non-holidays, after accounting for confounding factors?\n\nPart a\nWe believe that weather category (weather_cat), temperature (temp_actual), and wind speed (windspeed) confound the relationship of interest.\n\nDraw a causal graph that shows the 5 variables of interest. Based on your graph do you believe that the 3 potential confounders are indeed confounders (and not mediators or colliders)?\nConstruct visualizations that allow you how each potential confounder relates to riders_total and to holiday.\n\n\n\nPart b\nBased on your Part a explorations, fit an appropriate regression model to answer our research question. Interpret only the coefficient of interest.\nA note about scientific notation in R: Sometimes you may see numbers with the letter e in the middle. This is R’s way of expressing scientific notation. Whenever you see e, replace that with 10 to the power of .... So:\n\n1.234e+02 is 1.234 x 10^2 = 123.4\n1.234e-02 is 1.234 x 10^(-2) = 0.01234\n\n\n\nPart c\n\nUse confint() to construct a 95% confidence interval for the coefficient of interest.\nInterpret this confidence interval in context.\nIs zero in the interval? Do we have evidence for a real holiday effect on ridership?"
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#exercise-3",
    "href": "activities/L21-confidence-intervals.html#exercise-3",
    "title": "Confidence intervals",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe Western Collaborative Group Study (WCGS) was designed in order to investigate a possible link between Type A behavior and coronary heart disease (CHD), and to develop a framework to select patients for intervention in order to decrease risk of CHD. The study contained 3154 cis men between the ages of 39 and 59 in California who had no history of CHD. They were enrolled in the study in 1960 and 1961, underwent a medical examination and covered their medical history, and they were re-examined annually for interim cardiovascular history.\nA full codebook is available here. We will focus on the following variables:\n\nchd: Presence (1) or absence (0) of CHD over followup (outcome)\ntabp: Presence (1) or absence (0) of Type A behavior (main variable of interest)\nage: Age at time of enrollment in the study (years)\nsbp: Systolic blood pressure\ndbp: Diastolic blood pressure\nchol: Cholesterol (mg/dL)\nncigs: Number of cigarettes smoked per day\narcus: Presence (1) or absence (0) of arcus senilis (a colored ring around the cornea made up of lipids like cholesterol and believed to be a risk factor for CHD)\nbmi: BMI = weight * 703 / height^2\n\nResearch question: Is there a causal effect of Type A/B personality on developing coronary heart disease?\n\nwcgs &lt;- read_csv(\"https://mac-stat.github.io/data/wcgs.csv\")\n\n\nPart a\nWe believe that the following variables are confounders of the relationship between Type A/B personality tabp and coronary heart disease (CHD): age + sbp + dbp + chol + ncigs + arcus + bmi.\nFit a regression model that would address our research question. (Should it be a linear or a logistic regression model?) Interpret only the coefficient of interest.\n\ntypea_mod &lt;- ___\n\n\n\nPart b\n\nConstruct a 95% confidence interval for the odds ratio of interest using the following code.\nInterpret the confidence interval in context.\nIs 1 contained in the interval? Why is 1 a relevant value to look for here?\n\n\n\nPart c\n(On your own time)\nThe data context in this exercise has a fraught history with the smoking industry. Read this article for some context about how the Type A personality came to be defined and studied. (One big takeaway: The smoking industry had a large incentive to find something to blame health problems on other than smoking!)"
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#exercise-4",
    "href": "activities/L21-confidence-intervals.html#exercise-4",
    "title": "Confidence intervals",
    "section": "Exercise 4",
    "text": "Exercise 4\nFor each of the following MISINTERPRETATIONS of a 95% confidence interval (a,b), explain why the statement is a misinterpretation.\n\nMisinterpretation 1: “There is a 95% probability that the population parameter is within (a,b).”\n\nResponse: The population parameter is not random. It is either in the interval or not, so the probability is 1 or 0. The 95% means that 95% of random samples (that are representative of the population of interest) are expected to contain the true population parameter—“95% confidence” is describing confidence in the interval construction process.\n\nMisinterpretation 2: “There is a 5% probability that the population parameter is not within (a,b).”\n\nResponse: This is incorrect for the same reason as the first misinterpretation.\n\nMisinterpretation 3: “There is a 95% chance that the sample estimate in (a,b).”\n\nResponse: The sample estimate is always in the interval by construction."
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#reflection",
    "href": "activities/L21-confidence-intervals.html#reflection",
    "title": "Confidence intervals",
    "section": "Reflection",
    "text": "Reflection\nHow are you feeling about your ability to translate research questions into appropriate statistical investigations and addressing those questions using output from those investigations? What has gotten easier? What remains challenging?\n\nResponse:"
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#exercise-1-1",
    "href": "activities/L21-confidence-intervals.html#exercise-1-1",
    "title": "Confidence intervals",
    "section": "Exercise 1",
    "text": "Exercise 1\nResearch question: Is the relationship between wind speed (windspeed) (in miles per hour) and number of riders (riders_total) different across weekdays and weekends?\n\nPart a\nConstruct and interpret a visualization that would address this question.\n\nResponse: Overall, windier days seem to have less riders (negative slope). The slope for weekends seems slightly steeper than for weekdays, but overall weekdays and weekends have similar slopes.\n\n\nggplot(bikes, aes(x = windspeed, y = riders_total, col = weekend)) + \n    geom_point(alpha = 0.2) +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    theme_classic() +\n    labs(x = \"Windspeed (miles per hour)\", y = \"Total daily riders\")\n\n\n\n\n\n\n\n\n\n\nPart b\nFit a regression model that would address our research question. (Should it be a linear or a logistic regression model?) Interpret only the coefficient of interest.\n\nResponse: We need to fit a linear regression model (because outcome is quantitative) with an interaction term to answer this question. The interaction coefficient is of interest.\nInterpretation of interaction coefficient: The average decrease in ridership associated with a 1 mph increase in wind speed is 26.82 rides/mph lower on weekends than for weekdays. Put another way, on weekdays, a 1 mph increase in wind speed is associated with a decrease of 79.47 riders. On weekends, that decrease is 106.29 riders.\n\n\nmod_bikes &lt;- lm(riders_total ~ windspeed*weekend, data = bikes)\nsummary(mod_bikes)\n## \n## Call:\n## lm(formula = riders_total ~ windspeed * weekend, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4523.2 -1317.9   -46.9  1443.3  4715.7 \n## \n## Coefficients:\n##                       Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)            5560.31     219.07  25.382  &lt; 2e-16 ***\n## windspeed               -79.47      15.97  -4.976 8.09e-07 ***\n## weekendTRUE             200.56     409.72   0.489    0.625    \n## windspeed:weekendTRUE   -26.82      29.56  -0.907    0.365    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1885 on 727 degrees of freedom\n## Multiple R-squared:  0.05721,    Adjusted R-squared:  0.05332 \n## F-statistic:  14.7 on 3 and 727 DF,  p-value: 2.638e-09\n\n\n\nPart c\n\nConstruct an approximate 95% confidence interval (CI) for the coefficient of interest by hand using the 68-95-99.7 rule.\nCompare your confidence interval to the one given by confint() which gives an exact confidence interval. (The columns give the lower and upper ends of the CI for each coefficient.)\nInterpret the exact confidence interval in context.\nIs zero in the interval? Do we have evidence for a real difference in the windspeed-riders relationship across weekends and weekdays?\n\n\nResponse:\n\nOur manual calculation is pretty close to the CI given by confint().\nInterpretation in context:\n\nPreferred interpretation: It is plausible that the true population difference in the relationship between riders and wind speed comparing weekends to weekdays ranges from an average decrease of 84 riders/mph to an average increase of 31.21 riders/mph.\nNot as preferred interpretation (but you’ll see this wording across disciplines): We are 95% confident that the difference in riders vs. wind speed slopes between weekends and weekdays is between -84 riders/mph to +31.21 riders/mph. (The instructors don’t like this interpretation as much because saying “95% confident” is rather vague. We are confident about the interval construction process across random samples, and this interpretation doesn’t make that clear.)\n\nZero is in the CI. This means that the difference in slopes could plausibly be zero. Therefore we do not have evidence for a real difference in the windspeed-riders relationship across weekends and weekdays.\n\n\n\n# By hand\n-26.82 - 2*29.56\n## [1] -85.94\n-26.82 + 2*29.56\n## [1] 32.3\n\n# By hand using 1.96, which is closer to the exact normal distribution quantile to use\n-26.82 - 1.96*29.56\n## [1] -84.7576\n-26.82 + 1.96*29.56\n## [1] 31.1176\n\n# Using confint()\nconfint(mod_bikes, level = 0.95)\n##                            2.5 %     97.5 %\n## (Intercept)           5130.23243 5990.38552\n## windspeed             -110.81588  -48.11605\n## weekendTRUE           -603.82472 1004.93649\n## windspeed:weekendTRUE  -84.84192   31.21156\n\n\n\nPart d\nLet’s see if these results agree when looking at adjusted R-squared.\nFit another regression model that does not have the coefficient of interest from your Part b model. Compare the adjusted R-squared values between this model and the Part b model. Explain your findings.\n\nResponse:\n\nThe adjusted R-squared for the interaction model was 0.05332, compared to 0.05355 for the model without the interaction.\nAdding the interaction term actually decreased the adjusted R-squared, suggesting that it didn’t really improve the model.\nThis agrees with what our CI interpretation: zero was a plausible value for the difference in slopes. If zero is a plausible value for the difference in slopes, allowing the slopes to be different in our model might not be necessary.\n\n\n\nmod_bikes_noint &lt;- lm(riders_total ~ windspeed+weekend, data = bikes)\nsummary(mod_bikes)\n## \n## Call:\n## lm(formula = riders_total ~ windspeed * weekend, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4523.2 -1317.9   -46.9  1443.3  4715.7 \n## \n## Coefficients:\n##                       Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)            5560.31     219.07  25.382  &lt; 2e-16 ***\n## windspeed               -79.47      15.97  -4.976 8.09e-07 ***\n## weekendTRUE             200.56     409.72   0.489    0.625    \n## windspeed:weekendTRUE   -26.82      29.56  -0.907    0.365    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1885 on 727 degrees of freedom\n## Multiple R-squared:  0.05721,    Adjusted R-squared:  0.05332 \n## F-statistic:  14.7 on 3 and 727 DF,  p-value: 2.638e-09\nsummary(mod_bikes_noint)\n## \n## Call:\n## lm(formula = riders_total ~ windspeed + weekend, data = bikes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4563.0 -1323.1   -67.4  1445.2  4645.8 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  5659.76     189.64  29.845  &lt; 2e-16 ***\n## windspeed     -87.29      13.44  -6.497 1.52e-10 ***\n## weekendTRUE  -143.87     154.07  -0.934    0.351    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1885 on 728 degrees of freedom\n## Multiple R-squared:  0.05614,    Adjusted R-squared:  0.05355 \n## F-statistic: 21.65 on 2 and 728 DF,  p-value: 7.346e-10"
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#exercise-2-1",
    "href": "activities/L21-confidence-intervals.html#exercise-2-1",
    "title": "Confidence intervals",
    "section": "Exercise 2",
    "text": "Exercise 2\nResearch question: How different is holiday ridership from non-holidays, after accounting for confounding factors?\n\nPart a\nWe believe that weather category (weather_cat), temperature (temp_actual), and wind speed (windspeed) confound the relationship of interest.\n\nDraw a causal graph that shows the 5 variables of interest. Based on your graph do you believe that the 3 potential confounders are indeed confounders (and not mediators or colliders)?\nConstruct visualizations that allow you how each potential confounder relates to riders_total and to holiday.\n\n\nResponse: A causal graph might look like below (the double-headed arrows represent lines connecting the variables without a direction of causation). The variables that we’re considering putting in the model aren’t mediators or colliders. The visualizations support that weather_cat, temp_actual, and windspeed are causes of ridership, but only weather_cat and temp_actual seem to have noticeable differences between holidays and non-holidays.\n\n\ndag &lt;- dagitty::dagitty('\ndag {\nbb=\"0,0,1,1\"\nholiday [exposure,pos=\"0.123,0.550\"]\nriders_total [outcome,pos=\"0.668,0.545\"]\ntemp_actual [pos=\"0.110,0.246\"]\nweather_cat [pos=\"0.439,0.260\"]\nwindspeed [pos=\"0.276,0.157\"]\nholiday -&gt; riders_total\nholiday &lt;-&gt; temp_actual\nholiday &lt;-&gt; weather_cat\nholiday &lt;-&gt; windspeed\ntemp_actual -&gt; riders_total\ntemp_actual -&gt; weather_cat\nweather_cat -&gt; riders_total\nwindspeed -&gt; riders_total\nwindspeed -&gt; weather_cat\n}\n')\nplot(dag)\n\n\n\n\n\n\n\n\n\nggplot(bikes, aes(x = weather_cat, y = riders_total)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\nggplot(bikes, aes(x = temp_actual, y = riders_total)) +\n    geom_point() +\n    geom_smooth()\n\n\n\n\n\n\n\n\nggplot(bikes, aes(x = windspeed, y = riders_total)) +\n    geom_point() +\n    geom_smooth()\n\n\n\n\n\n\n\n\n\nggplot(bikes, aes(x = holiday, fill = weather_cat)) +\n    geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nggplot(bikes, aes(x = holiday, y = temp_actual)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\nggplot(bikes, aes(x = holiday, y = windspeed)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nPart b\nBased on your Part a explorations, fit an appropriate regression model to answer our research question. Interpret only the coefficient of interest.\nA note about scientific notation in R: Sometimes you may see numbers with the letter e in the middle. This is R’s way of expressing scientific notation. Whenever you see e, replace that with 10 to the power of .... So:\n\n1.234e+02 is 1.234 x 10^2 = 123.4\n1.234e-02 is 1.234 x 10^(-2) = 0.01234\n\n\nResponse: Clear confounders from Part a include weather_cat and temp_actual. windspeed might be a precision variable because it don’t seem to be very different between holidays and non-holidays. We try models with just the confounders and with confounders+precision variable. Because temperature has a curved relationships with riders, we include a squared term.\nThe coefficient on holiday is of interest.\nmod_bikes_smaller interpretation: Among days that have the same weather category and temperature, holidays have 731 fewer riders on average than non-holidays.\nmod_bikes_larger interpretation: Among days that have the same weather category, temperature, and wind speed, holidays have 725 fewer riders on average than non-holidays.\n\n\nbikes_new &lt;- bikes %&gt;% \n    mutate(\n        temp_actual_squared = temp_actual^2\n    )\nmod_bikes_smaller &lt;- lm(riders_total ~ holiday + weather_cat + temp_actual_squared, data = bikes_new)\nmod_bikes_larger &lt;- lm(riders_total ~ holiday + weather_cat + temp_actual_squared + windspeed, data = bikes_new)\n\nsummary(mod_bikes_smaller)\n## \n## Call:\n## lm(formula = riders_total ~ holiday + weather_cat + temp_actual_squared, \n##     data = bikes_new)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4225.5 -1200.7  -111.8  1057.8  3608.9 \n## \n## Coefficients:\n##                       Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)          1.872e+03  1.660e+02  11.280  &lt; 2e-16 ***\n## holidayyes          -7.311e+02  3.263e+02  -2.240   0.0254 *  \n## weather_catcateg2   -5.708e+02  1.168e+02  -4.885 1.27e-06 ***\n## weather_catcateg3   -2.571e+03  3.297e+02  -7.799 2.18e-14 ***\n## temp_actual_squared  5.980e-01  2.973e-02  20.116  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1472 on 726 degrees of freedom\n## Multiple R-squared:  0.4257, Adjusted R-squared:  0.4225 \n## F-statistic: 134.5 on 4 and 726 DF,  p-value: &lt; 2.2e-16\nsummary(mod_bikes_larger)\n## \n## Call:\n## lm(formula = riders_total ~ holiday + weather_cat + temp_actual_squared + \n##     windspeed, data = bikes_new)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4050.0 -1109.6  -120.6  1068.0  3699.8 \n## \n## Coefficients:\n##                       Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)          2.577e+03  2.281e+02  11.294  &lt; 2e-16 ***\n## holidayyes          -7.246e+02  3.222e+02  -2.249   0.0248 *  \n## weather_catcateg2   -5.924e+02  1.155e+02  -5.131 3.71e-07 ***\n## weather_catcateg3   -2.422e+03  3.272e+02  -7.403 3.70e-13 ***\n## temp_actual_squared  5.770e-01  2.973e-02  19.405  &lt; 2e-16 ***\n## windspeed           -4.692e+01  1.057e+01  -4.439 1.05e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1454 on 725 degrees of freedom\n## Multiple R-squared:  0.4409, Adjusted R-squared:  0.437 \n## F-statistic: 114.3 on 5 and 725 DF,  p-value: &lt; 2.2e-16\n\n\n\nPart c\n\nUse confint() to construct a 95% confidence interval for the coefficient of interest.\nInterpret this confidence interval in context.\nIs zero in the interval? Do we have evidence for a real holiday effect on ridership?\n\n\nResponse: We’ll focus on the CI from mod_bikes_smaller since the CI from mod_bikes_larger is pretty similar.\n\nInterpretation in context:\n\nPreferred interpretation: It is plausible that the true population difference in average holiday ridership vs. average non-holiday ridership is from 1371.8 to 90.5 fewer rides on holidays (among days of the same weather category and temperature).\nNot as preferred interpretation: We are 95% confident that the population difference in holiday vs non-holiday ridership is between -1371.8 to -90.4532521.\n\nZero is not in the CI which means that the difference between holidays and non-holidays (among days of the same weather category and temperature) is not plausibly zero. We do have evidence for a true holiday effect.\n\n\n\nconfint(mod_bikes_smaller, level = 0.95)\n##                             2.5 %        97.5 %\n## (Intercept)          1546.3798240  2198.1156306\n## holidayyes          -1371.8105006   -90.4532521\n## weather_catcateg2    -800.1540608  -341.3738083\n## weather_catcateg3   -3218.3124545 -1923.8150951\n## temp_actual_squared     0.5396379     0.6563642\nconfint(mod_bikes_larger, level = 0.95)\n##                            2.5 %        97.5 %\n## (Intercept)          2128.817226  3024.6176444\n## holidayyes          -1357.222742   -92.0407887\n## weather_catcateg2    -819.136285  -365.7464372\n## weather_catcateg3   -3064.923766 -1780.0402827\n## temp_actual_squared     0.518586     0.6353312\n## windspeed             -67.677428   -26.1684414"
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#exercise-3-1",
    "href": "activities/L21-confidence-intervals.html#exercise-3-1",
    "title": "Confidence intervals",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe Western Collaborative Group Study (WCGS) was designed in order to investigate a possible link between Type A behavior and coronary heart disease (CHD), and to develop a framework to select patients for intervention in order to decrease risk of CHD. The study contained 3154 cis men between the ages of 39 and 59 in California who had no history of CHD. They were enrolled in the study in 1960 and 1961, underwent a medical examination and covered their medical history, and they were re-examined annually for interim cardiovascular history.\nA full codebook is available here. We will focus on the following variables:\n\nchd: Presence (1) or absence (0) of CHD over followup (outcome)\ntabp: Presence (1) or absence (0) of Type A behavior (main variable of interest)\nage: Age at time of enrollment in the study (years)\nsbp: Systolic blood pressure\ndbp: Diastolic blood pressure\nchol: Cholesterol (mg/dL)\nncigs: Number of cigarettes smoked per day\narcus: Presence (1) or absence (0) of arcus senilis (a colored ring around the cornea made up of lipids like cholesterol and believed to be a risk factor for CHD)\nbmi: BMI = weight * 703 / height^2\n\nResearch question: Is there a causal effect of Type A/B personality on developing coronary heart disease?\n\nwcgs &lt;- read_csv(\"https://mac-stat.github.io/data/wcgs.csv\")\n\n\nPart a\nWe believe that the following variables are confounders of the relationship between Type A/B personality tabp and coronary heart disease (CHD): age + sbp + dbp + chol + ncigs + arcus + bmi.\nFit a regression model that would address our research question. (Should it be a linear or a logistic regression model?) Interpret only the coefficient of interest.\n\nResponse: We need to fit a logistic regression model because the chd outcome is binary. We include tabp as the main predictor of interest and all of the other confounding variables. We need to exponentiate the coefficient so that we’re interpreting on the odds scale rather than the log odds scale.\nInterpretation of exp(tabp): Among men of the same age, systolic and diastolic blood pressure, cholesterol levels, smoking habits, history of arcus sinilis, and BMI, those with Type A personality have 1.95 times the odds of CHD than those without Type A personality.\n\n\ntypea_mod &lt;- glm(chd ~ tabp + age + sbp + dbp + chol + ncigs + arcus + bmi, data = wcgs, family = \"binomial\")\nsummary(typea_mod)\n## \n## Call:\n## glm(formula = chd ~ tabp + age + sbp + dbp + chol + ncigs + arcus + \n##     bmi, family = \"binomial\", data = wcgs)\n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept) -1.225e+01  9.898e-01 -12.378  &lt; 2e-16 ***\n## tabp         6.670e-01  1.458e-01   4.576 4.74e-06 ***\n## age          5.897e-02  1.230e-02   4.794 1.64e-06 ***\n## sbp          1.824e-02  6.408e-03   2.846  0.00443 ** \n## dbp         -5.797e-04  1.086e-02  -0.053  0.95743    \n## chol         1.045e-02  1.519e-03   6.879 6.04e-12 ***\n## ncigs        2.131e-02  4.287e-03   4.971 6.67e-07 ***\n## arcus        2.219e-01  1.436e-01   1.545  0.12238    \n## bmi          5.841e-02  2.714e-02   2.152  0.03141 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 1769.2  on 3139  degrees of freedom\n## Residual deviance: 1572.6  on 3131  degrees of freedom\n##   (14 observations deleted due to missingness)\n## AIC: 1590.6\n## \n## Number of Fisher Scoring iterations: 6\ntidy(typea_mod) %&gt;% \n    mutate(exp_estimate = exp(estimate)) %&gt;% \n    select(term, estimate, exp_estimate)\n## # A tibble: 9 × 3\n##   term          estimate exp_estimate\n##   &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n## 1 (Intercept) -12.3        0.00000477\n## 2 tabp          0.667      1.95      \n## 3 age           0.0590     1.06      \n## 4 sbp           0.0182     1.02      \n## 5 dbp          -0.000580   0.999     \n## 6 chol          0.0105     1.01      \n## 7 ncigs         0.0213     1.02      \n## 8 arcus         0.222      1.25      \n## 9 bmi           0.0584     1.06\n\n\n\nPart b\n\nConstruct a 95% confidence interval for the odds ratio of interest using the following code.\nInterpret the confidence interval in context.\nIs 1 contained in the interval? Why is 1 a relevant value to look for here?\n\n\nResponse:\n\nInterpretation in context:\n\nPreferred interpretation: Among men of the same age, systolic and diastolic blood pressure, cholesterol levels, smoking habits, history of arcus sinilis, and BMI, it is plausible that those with Type A personality have 1.47 to 2.60 times the odds of CHD than those without Type A personality.\n\n1 is not in the CI. 1 is a relevant value to consider for ratios because if the odds ratio is 1, then the (adjusted) odds of CHD is the same in those with Type A and Type B personality. There seems to be a positive relationship between Type A personality and CHD in this study.\n\n\n\nconfint(typea_mod, level = 0.95) %&gt;% exp()\n##                    2.5 %       97.5 %\n## (Intercept) 6.706495e-07 3.257156e-05\n## tabp        1.469222e+00 2.603660e+00\n## age         1.035479e+00 1.086677e+00\n## sbp         1.005561e+00 1.031169e+00\n## dbp         9.783446e-01 1.020911e+00\n## chol        1.007521e+00 1.013538e+00\n## ncigs       1.012938e+00 1.030126e+00\n## arcus       9.399791e-01 1.651412e+00\n## bmi         1.004943e+00 1.117811e+00\n\n\n\nPart c\n(On your own time)\nThe data context in this exercise has a fraught history with the smoking industry. Read this article for some context about how the Type A personality came to be defined and studied. (One big takeaway: The smoking industry had a large incentive to find something to blame health problems on other than smoking!)"
  },
  {
    "objectID": "activities/L21-confidence-intervals.html#exercise-4-1",
    "href": "activities/L21-confidence-intervals.html#exercise-4-1",
    "title": "Confidence intervals",
    "section": "Exercise 4",
    "text": "Exercise 4\nFor each of the following MISINTERPRETATIONS of a 95% confidence interval (a,b), explain why the statement is a misinterpretation.\n\nMisinterpretation 1: “There is a 95% probability that the population parameter is within (a,b).”\n\nResponse: The population parameter is not random. It is either in the interval or not, so the probability is 1 or 0. The 95% means that 95% of random samples (that are representative of the population of interest) are expected to contain the true population parameter—“95% confidence” is describing confidence in the interval construction process.\n\nMisinterpretation 2: “There is a 5% probability that the population parameter is not within (a,b).”\n\nResponse: This is incorrect for the same reason as the first misinterpretation.\n\nMisinterpretation 3: “There is a 95% chance that the sample estimate in (a,b).”\n\nResponse: The sample estimate is always in the interval by construction."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#learning-goals",
    "href": "activities/L02-foundations-univariate.html#learning-goals",
    "title": "Univariate visualization and summaries",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nDescribe what a case (or unit of analysis) represents in a dataset.\nDescribe what a variable represents in a dataset.\nIdentify whether a variable is categorical or quantitative and what summarizations and visualizations are appropriate for that variable\nWrite R code to read in data and to summarize and visualize a single variable at a time.\nInterpret key features of barplots, boxplots, histograms, and density plots\nDescribe information about the distribution of a quantitative variable using the concepts of shape, center, spread, and outliers\nRelate summary statistics of data to the concepts of shape, center, spread, and outliers"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#readings-and-videos",
    "href": "activities/L02-foundations-univariate.html#readings-and-videos",
    "title": "Univariate visualization and summaries",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 2.1-2.4, 2.6 in the STAT 155 Notes\nVideos:\n\nUnivariate summaries (slides)\n\nPart 1\nPart 2\n\nR Code for Categorical Visualization and Summarization\nR Code for Quantitative Visualization and Summarization\nQuarto docs\n\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-1-get-curious",
    "href": "activities/L02-foundations-univariate.html#exercise-1-get-curious",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 1: Get curious",
    "text": "Exercise 1: Get curious\n\nHypothesize with each other: what themes do you think might come up often in Dear Abby letters?\nAfter brainstorming, take a quick glance at the original article from The Pudding to see what themes they explored.\nGo to the very end of the Pudding article to the section titled “Data and Method”. In thinking about the who, what, when, where, why, and how of data context, what concerns/limitations surface with regards to using this data to learn about Americans’ concerns over the decades?"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "href": "activities/L02-foundations-univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 2: Importing and getting to know the data",
    "text": "Exercise 2: Importing and getting to know the data\nFirst, in the Console pane of RStudio, run the following command to install some necessary packages (you will need to do this any time you are installing a new package):\ninstall.packages(\"tidyverse\")\nNow, in the Quarto pane, run the following code chunk to load the package and load a dataset (you can either click the green arrow in the top right of the code chunk, put your cursor in the code chunk and hit Ctrl+Alt+C [on Windows/Linux] or Command+Option+C [on Mac]).\n\n# Load package\nlibrary(tidyverse)\n\n# Read in the Dear Abby data\nabby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\n\nIf it runs successfully, you should see the following output appear in the Console pane:\n&gt; # Load package\n&gt; library(tidyverse)\n&gt; \n&gt; # Read in the course evaluation data\n&gt; abby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\nRows: 20034 Columns: 11\n── Column specification ────────────────────────────\nDelimiter: \",\"\nchr (4): day, url, title, question_only\ndbl (7): year, month, letterId, afinn_overall, a...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nThroughout this activity, we’ll work only with the most recent year of data, from 2017. Run the following chunk:\n\n# Wrangle the Dear Abby data\n# Ignore this code for now!\nabby &lt;- abby %&gt;% \n  filter(year == 2017) %&gt;% \n  mutate(month = month(month, label = TRUE)) %&gt;%\n  mutate(\n    parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\"),\n    marriage = str_detect(question_only, \"marriage|marry|married\"),\n    money = str_detect(question_only, \"money|finance\")\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    themes = c(\n      if (parents) \"parents\",\n      if (marriage) \"marriage\",\n      if (money) \"money\"\n    ) %&gt;% paste(collapse = \", \"),\n    themes = ifelse(themes == \"\", \"other\", themes)\n  ) %&gt;%\n  ungroup() %&gt;% \n  select(year, month, day, question_only, bing_pos, afinn_overall, afinn_pos, afinn_neg, themes)\n\n\nClick on the Environment tab (generally in the upper right hand pane in RStudio). Then click the abby line. The abby data will pop up as a separate pane (like viewing a spreadsheet) – check it out.\nIn this tidy dataset, what is the unit of observation? That is, what is represented in each row of the dataset?\nWhat term do we use for the columns of the dataset?\nTry out each function below. Identify what each function tells you about the abby data and note this in the ???:\n\n\n# ??? [what do both numbers mean?]\ndim(abby)\n\n\n# ???\nnrow(abby)\n\n\n# ???\nncol(abby)\n\n\n# ???\nhead(abby)\n\n\n# ???\nnames(abby)\n\n\n[OPTIONAL] If you’re not sure how exactly to use a function, you can pull up a built-in help page with information about the arguments a function takes (i.e., what goes inside the parentheses), and the output it produces. To do this, click inside the Console pane, and enter ?function_name. For example, to pull up a help page for the dim() function, we can type ?dim and hit Enter. Try pulling up the help page for the read_csv() function we used to load the dataset."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "href": "activities/L02-foundations-univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 3: Preparing to summarize and visualize the data",
    "text": "Exercise 3: Preparing to summarize and visualize the data\nIn the next exercises, we will be exploring themes in the Dear Abby questions and the overall “mood” or sentiment of the questions. Before continuing, read the codebook for this dataset for some context about sentiment analysis, which gives us a measure of the mood/sentiment of a text.\n\nWhat sentiment variables do we have in the dataset? Are they quantitative or categorical?\nCheck out the theme variable. Is this quantitative or categorical?\nWhat visualizations are appropriate for looking at the distribution of a single quantitative variable? What about a single categorical variable?"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-4-exploring-themes-in-the-letters",
    "href": "activities/L02-foundations-univariate.html#exercise-4-exploring-themes-in-the-letters",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 4: Exploring themes in the letters",
    "text": "Exercise 4: Exploring themes in the letters\n\nThe code below makes a barplot of the themes variable using the ggplot2 visualization package. Before making the plot, make note of what you expect the plot might look like. (This might be hard–just do your best!) Then compare to what you observe when you run the code chunk to make the plot. (Clearly defining your expectations first is good scientific practice to avoid confirmation bias.)\n\n\n# Load package\nlibrary(ggplot2)\n\n# barplot\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\nWe can follow up on the barplot with a simple numerical summary. Whereas the ggplot2 package is great for visualizations, dplyr is great for numerical summaries. The code below constructs a table of the number of questions with each theme. Make sure that these numerical summaries match up with what you saw in the barplot.\n\n\n# Construct a table of counts\nabby %&gt;% \n    count(themes)\n\n\nBefore proceeding, let’s break down the plotting code above. Run each chunk to see how the two lines of code above build up the plot in “layers”. Add comments (on the lines starting with #) to document what you notice.\n\n\n# ???\nggplot(abby, aes(x = themes))\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar()\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-5-exploring-sentiment",
    "href": "activities/L02-foundations-univariate.html#exercise-5-exploring-sentiment",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 5: Exploring sentiment",
    "text": "Exercise 5: Exploring sentiment\nWe’ll look at the distribution of the bing_pos sentiment variable and associated summary statistics.\n\nThe code below creates a boxplot of this variable. In the comment, make note of how this code is similar to the code for the barplot above. As in the previous exercise, before running the code chunk to create the plot, make note of what you expect the boxplot to look like.\n\n\n# ???\nggplot(abby, aes(x = bing_pos)) +\n    geom_boxplot()\n\n\nChallenge: Using the code for the barplot and boxplot as a guide, try to make a histogram and a density plot of the overall average ratings.\n\nWhat information is given by the tallest bar of the histogram?\nHow would you describe the shape of the distribution?\n\n\n\n# Histogram\n\n# Density plot\n\n\nWe can compute summary statistics (numerical summaries) for a quantitative variable using the summary() function or with the summarize() function from the dplyr package. (1st Qu. and 3rd Qu. stand for first and third quartile.) After inspecting these summaries, look back to your boxplot, histogram, and density plot. Which plots show which summaries most clearly?\n\n\n# Summary statistics\n# Using summary() - convenient for computing many summaries in one command\n# Does not show the standard deviation\nabby %&gt;% \n    select(bing_pos) %&gt;% \n    summary()\n\n# Using summarize() from dplyr\n# Note that we use %&gt;% to pipe the data into the summarize() function\n# We need to use na.rm = TRUE because there are missing values (NAs)\nabby %&gt;% \n    summarize(mean(bing_pos, na.rm = TRUE), median(bing_pos, na.rm = TRUE), sd(bing_pos, na.rm = TRUE))\n\n\nWrite a good paragraph describing the information in the histogram (or density plot) by discussing shape, center, spread, and outliers. Incorporate the numerical summaries from part c."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#pause-math-box",
    "href": "activities/L02-foundations-univariate.html#pause-math-box",
    "title": "Univariate visualization and summaries",
    "section": "Pause: Math box",
    "text": "Pause: Math box\nBelow is an example of a “math box” which summarizes the formulas for some of the numerical summaries above. You are not required to memorize, nor will you be assessed on, any formulas presented in this or any future math box. They serve 3 purposes:\n\nTo emphasize that there’s “math” / a formal structure behind what we’re doing.\nTo provide students that plan to continue studying Statistics a glimpse into the formal statistical theory they’ll explore in later courses.\nTo make happy the students that are simply interested in math!\n\n\n\n\n::: {.callout-note title = “MATH BOX: Univariate numerical summaries”}\nLet \\((y_1, y_2, ..., y_n)\\) be a sample of \\(n\\) data points.\nmean: \\[\\overline{y} = \\frac{y_1 + y_2 + \\cdots + y_n}{n} = \\frac{\\sum_{i=1}^n y_i}{n}\\]\nvariance: \\[\\text{var}(y) = \\frac{(y_1 - \\overline{y})^2 + (y_2 - \\overline{y})^2 + \\cdots + (y_n - \\overline{y})^2}{n - 1} = \\frac{\\sum_{i=1}^n (y_i - \\overline{y})^2}{n - 1}\\]\nstandard deviation: \\[\\text{sd}(y) = \\sqrt{\\text{var}(y)}\\] :::"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "href": "activities/L02-foundations-univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 6: Box plots vs. histograms vs. density plots",
    "text": "Exercise 6: Box plots vs. histograms vs. density plots\nWe took 3 different approaches to plotting the quantitative average course variable above. They all have pros and cons.\n\nWhat is one pro about the boxplot in comparison to the histogram and density plot?\nWhat is one con about the boxplot in comparison to the histogram and density plots?\nIn this example, which plot do you prefer and why?"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-7-returning-to-our-context-looking-ahead",
    "href": "activities/L02-foundations-univariate.html#exercise-7-returning-to-our-context-looking-ahead",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 7: Returning to our context, looking ahead",
    "text": "Exercise 7: Returning to our context, looking ahead\nIn this activity, we explored data on Dear Abby question, with a focus on exploring a single variable at a time.\n\nIn big picture terms, what have we learned about Dear Abby questions?\nWhat further curiosities do you have about the data?"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-8-different-ways-to-think-about-data-visualization",
    "href": "activities/L02-foundations-univariate.html#exercise-8-different-ways-to-think-about-data-visualization",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 8: Different ways to think about data visualization",
    "text": "Exercise 8: Different ways to think about data visualization\nIn working with and visualizing data, it’s important to keep in mind what a data point represents. It can reflect the experience of a real person. It might reflect the sentiment in a piece of art. It might reflect history. We’ve taken one very narrow and technical approach to data visualization. Check out the following examples, and write some notes about anything you find interesting.\n\nDear Data\nW.E.B. DuBois\nDecolonizing Data Viz"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-9-rendering-your-work",
    "href": "activities/L02-foundations-univariate.html#exercise-9-rendering-your-work",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 9: Rendering your work",
    "text": "Exercise 9: Rendering your work\nSave this file, and then click the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\n\nScroll through and inspect the document to see how your work was translated into this HTML format. Neat!\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#reflection",
    "href": "activities/L02-foundations-univariate.html#reflection",
    "title": "Univariate visualization and summaries",
    "section": "Reflection",
    "text": "Reflection\nGo to the top of this file and review the learning objectives for this lesson. Which objectives do you have a good handle on, are at least familiar with, or are struggling with? What feels challenging right now? What are some wins from the day?\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#advice-make-an-r-code-cheat-sheet",
    "href": "activities/L02-foundations-univariate.html#advice-make-an-r-code-cheat-sheet",
    "title": "Univariate visualization and summaries",
    "section": "Advice: make an R code “cheat sheet”!",
    "text": "Advice: make an R code “cheat sheet”!\nYou will continue to pick up new R code and ideas. You’re highly encouraged to start tracking this in a cheat sheet (eg: in a Google doc). The cheat sheet will be a handy reference for you, and the act of making it will help deepen your understanding and retention."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-10-read-in-and-get-to-know-the-weather-data",
    "href": "activities/L02-foundations-univariate.html#exercise-10-read-in-and-get-to-know-the-weather-data",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 10: Read in and get to know the weather data",
    "text": "Exercise 10: Read in and get to know the weather data\nDaily weather data are available for 3 locations in Perth, Australia.\n\nView the codebook here.\nComplete the code below to read in the data.\n\n\n# Replace the ??? with your own name for the weather data\n# Replace the ___ with the correct function\n??? &lt;- ___(\"https://mac-stat.github.io/data/weather_3_locations.csv\")"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-11-exploring-the-data-structure",
    "href": "activities/L02-foundations-univariate.html#exercise-11-exploring-the-data-structure",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 11: Exploring the data structure",
    "text": "Exercise 11: Exploring the data structure\nCheck out the basic features of the weather data.\n\n# Examine the first six cases\n\n# Find the dimensions of the data\n\nWhat does a case represent in this data?"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-12-exploring-rainfall",
    "href": "activities/L02-foundations-univariate.html#exercise-12-exploring-rainfall",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 12: Exploring rainfall",
    "text": "Exercise 12: Exploring rainfall\nThe raintoday variable contains information about rainfall.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about rainfall in Perth?\n\n\n# Visualization\n\n# Numerical summaries"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-13-exploring-temperature",
    "href": "activities/L02-foundations-univariate.html#exercise-13-exploring-temperature",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 13: Exploring temperature",
    "text": "Exercise 13: Exploring temperature\nThe maxtemp variable contains information on the daily high temperature.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about high temperatures in Perth?\n\n\n# Visualization\n\n# Numerical summaries"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-14-customizing-challenge",
    "href": "activities/L02-foundations-univariate.html#exercise-14-customizing-challenge",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 14: Customizing! (CHALLENGE)",
    "text": "Exercise 14: Customizing! (CHALLENGE)\nThough you will naturally absorb some RStudio code throughout the semester, being an effective statistical thinker and “programmer” does not require that we memorize all code. That would be impossible! In contrast, using the foundation you built today, do some digging online to learn how to customize your visualizations.\n\nFor the histogram below, add a title and more meaningful axis labels. Specifically, title the plot “Distribution of max temperatures in Perth”, change the x-axis label to “Maximum temperature” and y-axis label to “Number of days”. HINT: Do a Google search for something like “add axis labels ggplot”.\n\n\n# Add a title and axis labels\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram()\n\n\nAdjust the code below in order to color the bars green. NOTE: Color can be an effective tool, but here it is simply gratuitous.\n\n\n# Make the bars green\nggplot(weather, aes(x = raintoday)) + \n    geom_bar()\n\n\nCheck out the ggplot2 cheat sheet. Try making some of the other kinds of univariate plots outlined there.\nWhat else would you like to change about your plot? Try it!"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-15-optional-challenge",
    "href": "activities/L02-foundations-univariate.html#exercise-15-optional-challenge",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 15: Optional challenge",
    "text": "Exercise 15: Optional challenge\nAt the top of this activity, we searched for words related to some topics of interest (parents, marriage, money) and combined them into a single theme variable. It looked something like this:\n\nabby_new &lt;- abby %&gt;% \n  mutate(\n    parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\"),\n    marriage = str_detect(question_only, \"marriage|marry|married\"),\n    money = str_detect(question_only, \"money|finance\")\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    themes = c(\n      if (parents) \"parents\",\n      if (marriage) \"marriage\",\n      if (money) \"money\"\n    ) %&gt;% paste(collapse = \", \"),\n    themes = ifelse(themes == \"\", \"other\", themes)\n  ) %&gt;%\n  ungroup()\n\nCheck it out:\n\nhead(abby_new)\n\n\nUnderstand the code!\n\nInside mutate() the line parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\") created a new variable called parents. This variable takes on TRUE or FALSE. Explain what TRUE and FALSE mean here.\nThe themes variable combines the information from the parents, marriage, and money variables. Check out the themes for the first 3 rows / data points. Convince yourself that you understand how it corresponds to the parents, marriage, and money variables.\n\nBeyond parents, marriage, and money, what are some other topics that might pop up in the Dear Abby letters (and that you’re interested in exploring)? Modify the code below to explore those topics! Update the themes variable accordingly.\n\n\nabby_new &lt;- abby %&gt;% \n  mutate(\n    parents = str_detect(question_only, \"mother|mama|mom|father|papa|dad\"),\n    marriage = str_detect(question_only, \"marriage|marry|married\"),\n    money = str_detect(question_only, \"money|finance\")\n  ) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    themes = c(\n      if (parents) \"parents\",\n      if (marriage) \"marriage\",\n      if (money) \"money\"\n    ) %&gt;% paste(collapse = \", \"),\n    themes = ifelse(themes == \"\", \"other\", themes)\n  ) %&gt;%\n  ungroup()\n\n# Check out the raw data\nhead(abby_new)\n\n# Check out the number of letters belonging to each theme\nabby_new %&gt;% \n  count(themes)"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-1-get-curious-1",
    "href": "activities/L02-foundations-univariate.html#exercise-1-get-curious-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 1: Get curious",
    "text": "Exercise 1: Get curious\n\nResults of brainstorming themes will vary\nFrom the “Data and Method” section at the end of the Pudding article, we see this paragraph:\n\n\nThe writers of these questions likely skew roughly 2/3 female (according to Pauline Phillips, who mentions the demographics of responses to a survey she disseminated in 1987), and consequently, their interests are overrepresented; we’ve been unable to find other demographic data surrounding their origins. There is, doubtless, a level of editorializing here: only a fraction of the questions that people have written in have seen publication, because agony aunts (the writers of advice columns) must selectively filter what gets published. Nevertheless, the concerns of the day seem to be represented, such as the HIV/AIDS crisis in the 1980s. Additionally, we believe that the large sample of questions in our corpus (20,000+) that have appeared over recent decades gives a sufficient directional sense of broad trends.\n\n\nWriters of the questions are predominately female. The 2/3 proportion was estimated in 1987, so it would be useful to understand shifts in demographics over time.\nWhat questions were chosen to be answered on the column? Likely a small fraction of what got submitted. What themes tended to get cut out?"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-2-importing-and-getting-to-know-the-data-1",
    "href": "activities/L02-foundations-univariate.html#exercise-2-importing-and-getting-to-know-the-data-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 2: Importing and getting to know the data",
    "text": "Exercise 2: Importing and getting to know the data\n\nNote how clicking the abby data causes both a popup pane and the command View(abby) to appear in the Console. In fact, the View() function is the underlying command that opens a dataset pane. (View() should always be entered in the Console and NOT your Quarto document.)\nEach row / case corresponds to a single question.\nColumns = variables\nTry out each function below. Identify what each function tells you about the abby data and note this in the ???:\n\n\n# First number = number of rows / cases\n# Second number = number of columns / variables\ndim(abby)\n## [1] 514   6\n\n# Number of rows (cases)\nnrow(abby)\n## [1] 514\n\n# Number of columns (variables)\nncol(abby)\n## [1] 6\n\n# View first few rows of the dataset (6 rows, by default)\nhead(abby)\n## # A tibble: 6 × 6\n##    year month day   question_only                                bing_pos themes\n##   &lt;dbl&gt; &lt;ord&gt; &lt;chr&gt; &lt;chr&gt;                                           &lt;dbl&gt; &lt;chr&gt; \n## 1  2017 Aug   30    \"i moved to the philippines five years ago.…    0.75  paren…\n## 2  2017 Aug   30    \"under what circumstances do you ask your a…   NA     money \n## 3  2017 Aug   28    \"i'm not a dog person. i'm not even an anim…    0.333 other \n## 4  2017 Aug   28    \"my 62-year-old father has recently started…    0.143 paren…\n## 5  2017 Aug   27    \"i have a friend, \\\"charlene,\\\" whom i met …    0.222 other \n## 6  2017 Aug   27    \"i have been selected to attend a symposium…    0.333 other\n\n# Get all column (variable) names\nnames(abby)\n## [1] \"year\"          \"month\"         \"day\"           \"question_only\"\n## [5] \"bing_pos\"      \"themes\"\n\n\nWe can display the first 10 rows with head(abby, n = 10)."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data-1",
    "href": "activities/L02-foundations-univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 3: Preparing to summarize and visualize the data",
    "text": "Exercise 3: Preparing to summarize and visualize the data\n\nThe sentiment variables are afinn_overall, afinn_pos, afinn_neg, and bing_pos, and they are quantitative. The afinn variables don’t have units but we can still get a sense of the scale by remembering that each word gets a score between -5 and 5. The bing_pos variable doesn’t have units because it’s a fraction, but we know that it ranges from 0 to 1.\ncategorical\nAppropriate visualizations:\n\nsingle quantitative variable: boxplot, histogram, density plot\nsingle categorical variable: barplot"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-4-exploring-themes-in-the-letters-1",
    "href": "activities/L02-foundations-univariate.html#exercise-4-exploring-themes-in-the-letters-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 4: Exploring themes in the letters",
    "text": "Exercise 4: Exploring themes in the letters\n\nExpectations about the plot will vary\n\n\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\nCounts in the table below match the barplot\n\n\n# Construct a table of counts\nabby %&gt;% \n    count(themes)\n## # A tibble: 8 × 2\n##   themes                       n\n##   &lt;chr&gt;                    &lt;int&gt;\n## 1 marriage                    75\n## 2 marriage, money              5\n## 3 money                       21\n## 4 other                      234\n## 5 parents                    127\n## 6 parents, marriage           33\n## 7 parents, marriage, money     4\n## 8 parents, money              15\n\n\nWhat do the plot layers do?\n\n\n# Just sets up the \"canvas\" of the plot with axis labels\nggplot(abby, aes(x = themes))\n\n\n\n\n\n\n\n\n\n# Adds the bars\nggplot(abby, aes(x = themes)) +\n    geom_bar()\n\n\n\n\n\n\n\n\n\n# Rotates the x axis labels\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\n# Changes the visual theme of the plot with a white background and removes gridlines\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-5-exploring-sentiment-1",
    "href": "activities/L02-foundations-univariate.html#exercise-5-exploring-sentiment-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 5: Exploring sentiment",
    "text": "Exercise 5: Exploring sentiment\n\n\nWe might expect the mean of this variable is less than zero given that more negative words might be appear in questions on an advice column.\nThe code has a similar structure to the barplot in that there is an initial ggplot() layer which sets the canvas, then a + to add a layer, then the final layer geom_boxplot() (like geom_bar()) which tells R what type of plot to make.\n\n\n\nggplot(abby, aes(x = afinn_overall)) +\n    geom_boxplot()\n## Error in `geom_boxplot()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'afinn_overall' not found\n\n\nWe replace geom_boxplot() with geom_histogram() and geom_density().\n\nThe tallest bar of the histogram indicates that over 7500 questions had an overall afinn sentiment score between around -8 to 0.(The -8 to 0 comes from eyeballing where the tallest bar is placed on the x-axis, and the height of this bar indicates how many cases fall into that bin.)\nThe shape of the distribution: roughly symmetric\n\n\n\n# Histogram\nggplot(abby, aes(x = afinn_overall)) +\n    geom_histogram()\n## Error in `geom_histogram()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'afinn_overall' not found\n\n# Density plot\nggplot(abby, aes(x = afinn_overall)) +\n    geom_density()\n## Error in `geom_density()`:\n## ! Problem while computing aesthetics.\n## ℹ Error occurred in the 1st layer.\n## Caused by error:\n## ! object 'afinn_overall' not found\n\n\n\nBoxplot shows min, max, median, 1st and 3rd quartile easily. (It shows median, 1st and 3rd quartile directly as lines)\nHistogram and density plot show min and max but the mean and median aren’t shown directly–we have to roughly guess based on the peak of the distribution\n\n\n\n# Summary statistics\nsummary(abby$afinn_overall)\n## Length  Class   Mode \n##      0   NULL   NULL\n\nabby %&gt;% \n    summarize(mean(afinn_overall, na.rm = TRUE), median(afinn_overall, na.rm = TRUE), sd(afinn_overall, na.rm = TRUE))\n## Error in `summarize()`:\n## ℹ In argument: `mean(afinn_overall, na.rm = TRUE)`.\n## Caused by error:\n## ! object 'afinn_overall' not found\n\n\nThe distribution of sentiment scores is roughly symmetric with a mean of -1.4 and a similar median of -1. The median and mean are quite similar because the distribution is fairly symmetric. The standard deviation of the sentiment scores is about 11.08 which tells us how much variation there is from the center of the distribution. 11.08 is somewhat high given the IQR of -6 to 3 (which is a span of 9 units)."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots-1",
    "href": "activities/L02-foundations-univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 6: Box plots vs. histograms vs. density plots",
    "text": "Exercise 6: Box plots vs. histograms vs. density plots\n\nBoxplots very clearly show key summary statistics like median, 1st and 3rd quartile\nBoxplots can oversimplify by not showing the shape of the distribution."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-7-returning-to-our-context-looking-ahead-1",
    "href": "activities/L02-foundations-univariate.html#exercise-7-returning-to-our-context-looking-ahead-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 7: Returning to our context, looking ahead",
    "text": "Exercise 7: Returning to our context, looking ahead\n\nAnswers will vary"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-10-read-in-and-get-to-know-the-weather-data-1",
    "href": "activities/L02-foundations-univariate.html#exercise-10-read-in-and-get-to-know-the-weather-data-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 10: Read in and get to know the weather data",
    "text": "Exercise 10: Read in and get to know the weather data\n\nweather &lt;- read_csv(\"https://raw.githubusercontent.com/Mac-STAT/data/main/weather_3_locations.csv\")"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-11-exploring-the-data-structure-1",
    "href": "activities/L02-foundations-univariate.html#exercise-11-exploring-the-data-structure-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 11: Exploring the data structure",
    "text": "Exercise 11: Exploring the data structure\nCheck out the basic features of the weather data.\n\n# Examine the first six cases\nhead(weather)\n## # A tibble: 6 × 24\n##   date       location  mintemp maxtemp rainfall evaporation sunshine windgustdir\n##   &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      \n## 1 2020-01-01 Wollongo…    17.1    23.1        0          NA       NA SSW        \n## 2 2020-01-02 Wollongo…    17.7    24.2        0          NA       NA SSW        \n## 3 2020-01-03 Wollongo…    19.7    26.8        0          NA       NA NE         \n## 4 2020-01-04 Wollongo…    20.4    35.5        0          NA       NA SSW        \n## 5 2020-01-05 Wollongo…    19.8    21.4        0          NA       NA SSW        \n## 6 2020-01-06 Wollongo…    18.3    22.9        0          NA       NA NE         \n## # ℹ 16 more variables: windgustspeed &lt;dbl&gt;, winddir9am &lt;chr&gt;, winddir3pm &lt;chr&gt;,\n## #   windspeed9am &lt;dbl&gt;, windspeed3pm &lt;dbl&gt;, humidity9am &lt;dbl&gt;,\n## #   humidity3pm &lt;dbl&gt;, pressure9am &lt;dbl&gt;, pressure3pm &lt;dbl&gt;, cloud9am &lt;dbl&gt;,\n## #   cloud3pm &lt;dbl&gt;, temp9am &lt;dbl&gt;, temp3pm &lt;dbl&gt;, raintoday &lt;chr&gt;,\n## #   risk_mm &lt;dbl&gt;, raintomorrow &lt;chr&gt;\n\n# Find the dimensions of the data\ndim(weather)\n## [1] 2367   24\n\nA case represents a day of the year in a particular area (Hobart, Uluru, Wollongong as seen by the location variable)."
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-12-exploring-rainfall-1",
    "href": "activities/L02-foundations-univariate.html#exercise-12-exploring-rainfall-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 12: Exploring rainfall",
    "text": "Exercise 12: Exploring rainfall\nThe raintoday variable contains information about rainfall.\n\nraintoday is categorical (No, Yes)\nIt is more common to have no rain.\n\n\n# Visualization\nggplot(weather, aes(x = raintoday)) +\n    geom_bar()\n\n\n\n\n\n\n\n\n# Numerical summaries\nweather %&gt;% \n    count(raintoday)\n## # A tibble: 3 × 2\n##   raintoday     n\n##   &lt;chr&gt;     &lt;int&gt;\n## 1 No         1864\n## 2 Yes         446\n## 3 &lt;NA&gt;         57"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-13-exploring-temperature-1",
    "href": "activities/L02-foundations-univariate.html#exercise-13-exploring-temperature-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 13: Exploring temperature",
    "text": "Exercise 13: Exploring temperature\nThe maxtemp variable contains information on the daily high temperature.\n\nmaxtemp is quantitative\nThe typical max temperature is around 23 degrees Celsius (with an average of 23.62 and a median of 22 degrees). The max temperatures ranged from 8.6 to 45.4 degrees. Finally, on the typical day, the max temp falls about 7.8 degrees from the mean. There are multiple modes in the distribution of max temperature—this likely reflects the different cities in the dataset.\n\n\n# Visualization\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram()\n\n\n\n\n\n\n\n\n# Numerical summaries\nsummary(weather$maxtemp)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    8.60   18.10   22.00   23.62   27.40   45.40      34\n\n# There are missing values (NAs) in this variable, so we add\n# the na.rm = TRUE argument\nweather %&gt;% \n    summarize(sd(maxtemp, na.rm = TRUE))\n## # A tibble: 1 × 1\n##   `sd(maxtemp, na.rm = TRUE)`\n##                         &lt;dbl&gt;\n## 1                        7.80"
  },
  {
    "objectID": "activities/L02-foundations-univariate.html#exercise-14-customizing-challenge-1",
    "href": "activities/L02-foundations-univariate.html#exercise-14-customizing-challenge-1",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 14: Customizing! (CHALLENGE)",
    "text": "Exercise 14: Customizing! (CHALLENGE)\n\n\n\n\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram() + \n    labs(x = \"Maximum temperature\", y = \"Number of days\", title = \"Distribution of max temperatures in Perth\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Make the bars green\nggplot(weather, aes(x = raintoday)) + \n    geom_bar(fill = \"green\")"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#learning-goals",
    "href": "activities/L03-slr-introduction.html#learning-goals",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nVisualize and describe the relationship between two quantitative variables using a scatterplot\nWrite R code to create a scatterplot and compute the linear correlation between two quantitative variables\nDescribe/identify weak / strong, and positive / negative correlation from a point cloud\nBuild intuition for fitting lines to quantify the relationship between two quantitative variables"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#readings-and-videos",
    "href": "activities/L03-slr-introduction.html#readings-and-videos",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through after class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-1-get-to-know-the-data",
    "href": "activities/L03-slr-introduction.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nCreate a new code chunk by clicking the green “C” button with a green + sign in the top right of the menu bar. In this code chunk, use an appropriate function to look at the first few rows of the data.\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\nWhat does a case represent?\nNavigate to the FAQ page and read the response to the “How does this site work? Do you just download results from the federations?” question. What do you learn about data quality and completeness from this response?"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-2-mutating-our-data",
    "href": "activities/L03-slr-introduction.html#exercise-2-mutating-our-data",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (lifts data is \"fed into\" the mutate() function).\n# When creating a new variable, we often reassign the data frame to itself,\n# which updates the existing columns in lifts with the additional \"new\" column(s)\n# in lifts!\nlifts &lt;- lifts %&gt;% \n    mutate(NEW_VARIABLE_NAME = Age/BestSquatKg)\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "href": "activities/L03-slr-introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet’s get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "href": "activities/L03-slr-introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe’d like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a “point cloud”) allows us to do this! The code below creates a scatterplot of body weight vs. SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\n\nThis is your first bivariate data visualization (visualization for two variables)! What differences do you notice in the code structure when creating a bivariate visualization, compared to univariate visualizations we’ve worked with before?\nWhat similarities do you notice in the code structure?\nDoes there appear to be some sort of pattern in the structure of the point cloud? Describe it, in no more than three sentences! Comment on the direction of the relationship between the two variables (positive? negative?) and the spread of the points (are they dispersed? close together?)."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "href": "activities/L03-slr-introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n\nLook back at your answer to Exercise 4 (c). Does the smoothing line assist you in seeing a pattern, or change your answer at all? Why or why not?\nBased on the scatterplot with the smoothing line added above, does there appear to be a linear relationship between body weight and SWR (i.e. would a straight line do a decent job at summarizing the relationship between these two variables)? Why or why not?"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-6-correlation",
    "href": "activities/L03-slr-introduction.html#exercise-6-correlation",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\nWe can quantify the linear relationship between two quantitative variables using a numerical summary known as correlation (sometimes known as a “correlation coefficient” or “Pearson’s correlation”). Correlation can range from -1 to 1, where a correlation of 0 indicates that there is no linear relationship between the two quantitative variables.\nBelow is an example of a “Math Box”. You’ll see these occasionally throughout the activities. You are not required to memorize, nor will you be assessed on, anything in the math boxes. If you plan on continuing with Statistics courses at Macalester (or are interested in the math behind everything!), these math boxes are for you!\n\n\n\n\n\n\nCorrelation\n\n\n\n\n\nThe Pearson correlation coefficient, \\(r_{x, y}\\), of \\(x\\) and \\(y\\) is the (almost) average of products of the z-scores of variables \\(x\\) and \\(y\\):\n\\[\nr_{x, y} = \\frac{\\sum z_x z_y}{n - 1}\n\\]\n\n\n\nIn general, we will want to be able to describe (qualitatively) two aspects of correlation:\n\nStrength\n\n\nIs the correlation between x and y strong, or weak, i.e. how closely do the points fit around a line? This has to do with how dispersed our point clouds are.\n\n\nDirection\n\n\nIs the correlation between x and y positive or negative, i.e. does y go “up” when x goes “up” (positive), or does y go “down” when x goes “up” (negative)?\n\nStronger correlations will be further from 0 (closer to -1 or 1), and positive and negative correlations will have the appropriate respective sign (above or below zero).\n\nRather than a smooth trend line, we can force the line we add to our scatterplots to be linear using geom_smooth(method = 'lm'), as below:\n\n\n# scatterplot with linear trend line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\")\n\n\nBased on the above scatterplot, how would you describe the correlation between body weight and SWR, in terms of strength and direction?\nMake a guess as to what numerical value the correlation between body weight and SWR will have, based on your response to part (b)."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-7-computing-correlation-in-r",
    "href": "activities/L03-slr-introduction.html#exercise-7-computing-correlation-in-r",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\nWe can compute the correlation between body weight and SWR using summarize and cor functions:\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n\nIs the computed correlation close to what you guessed in Exercise 6 part (c)?"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-8-limitations-of-correlation",
    "href": "activities/L03-slr-introduction.html#exercise-8-limitations-of-correlation",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\nWe previously noted that correlation was a numerical summary of the linear relationship between two variables. We’ll now go through some examples of relationships between quantitative variables to demonstrate why it is incredibly important to visualize our data in addition to just computing numerical summaries!\nFor this exercise, we’ll be working with the anscombe dataset, which is built in to R. To load this dataset into our environment, we run the following code:\n\n# load anscombe data\ndata(\"anscombe\")\n\nThe anscombe dataset contains four different pairs of quantitative variables:\n\nx1, y1\nx2, y2\nx3, y3\nx4, y4\n\nAdapt the code we used in Exercise 7 to compute the correlation between each of these four pairs of variables, below:\n\n# correlation between x1, y1\n\n# correlation between x2, y2\n\n# correlation between x3, y3\n\n# correlation between x4, y4\n\n\nWhat do you notice about each of these correlations (if the answer to this isn’t obvious, double-check your code)?\nDescribe these correlations in terms of strength and direction, using only the numerical summary to assist you in your description.\nDraw an example on the white board or at your tables of what you think the point clouds for these pairs of variables might look like. There are only 11 observations, so you can draw all 11 points if you’d like!\nAdapt the code for scatterplots given previously in this activity to make four distinct scatterplots for each pair of quantitative variables in the anscombe dataset. You do not need to add a smooth trend line or a linear trend line to these plots.\n\n\n# scatterplot: x1, y1\n\n# scatterplot: x2, y2\n\n# scatterplot: x3, y3\n\n# scatterplot: x4, y4\n\n\nBased on the correlations you calculated and scatterplots you made, what is the message of this last exercise as it relates to the limits of correlation?"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#reflection",
    "href": "activities/L03-slr-introduction.html#reflection",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Reflection",
    "text": "Reflection\nMuch of statistics is about making (hopefully) reasonable assumptions in attempt to summarize observed relationships in data. Today we started considering assumptions of linear relationships between quantitative variables.\nReview the learning objectives at the top of this file and today’s activity. How do you imagine assumptions of linearity might be useful in terms of quantifying relationships between quantitative variables? How do you imagine these assumptions could sometimes fall short, or even be unethical in certain cases?\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-9-lines-of-best-fit",
    "href": "activities/L03-slr-introduction.html#exercise-9-lines-of-best-fit",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 9: Lines of best fit",
    "text": "Exercise 9: Lines of best fit\nIn this activity, we’ve learned how to fit straight lines to data, to help us visualize the relationship between two quantitative variables. So far, ggplot has chosen the line for us. How does it know which line is “best”, and what does “best” even mean?\nFor this exercise, we’ll consider the relationship between x1 and y1 in the anscombe dataset. Run the following code, which creates a scatterplot with a fitted line to our data using the function geom_abline:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1)\n\nDescribe the line that you see. Do you think the line is “good”? What are you using to define “good”?\nSome things to think about:\n\nHow many points are above the line?\nHow many points are below the line?\nAre the distances of the points above and below the line roughly similar, or is there meaningful difference?\n\nNow we’ll add another line to our plot. Which line do you think is better suited for this data? Why? Be specific!\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1) +\n  geom_abline(slope = 0.5, intercept = 4, col = \"orange\", size = 1)\n\nIt’s usually quite simple to note when a line is bad, but more difficult to quantify when a line is a good fit for our data. Consider the following line:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = -0.5, intercept = 10, col = \"red\", size = 1) \n\nIn the next activity, we’ll formalize the principle of least squares, which will give us one particular definition of a line of best fit that is commonly used in statistics! We’ll take advantage of the vertical distances between each point and the fitted line (residuals), which will help us define (mathematically) a line that best fits our data:\n\nlibrary(broom)\nanscombe %&gt;%\n  lm(y1 ~ x1, data = .) %&gt;%\n  augment() %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_segment(aes(xend = x1, yend = .fitted), col = \"red\") +\n  geom_point()"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-10-correlation-and-extreme-values",
    "href": "activities/L03-slr-introduction.html#exercise-10-correlation-and-extreme-values",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 10: Correlation and extreme values",
    "text": "Exercise 10: Correlation and extreme values\nIn this exercise, we’ll explore how correlation changes with the addition of extreme values, or observations. We’ll begin by generating a toy dataset called dat with two quantitative variables, x and y. Run the code below to create the dataset.\nwhile not required, recall that you can look up function documentation in R using the ? in front of a function name to figure out what that function is doing!\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\nMake a scatterplot of x vs. y.\n\n\n# scatterplot\n\n\nBased on your scatterplot, describe the correlation between x and y in terms of strength and direction.\nGuess the correlation (the numerical value) between x and y.\nCompute the correlation between x and y. Was your guess from part (c) close?\n\n\n# correlation\n\n\nSuppose we observe an additional observation with x = 15 and y = -45. We can create a new data frame, dat_new1, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nSuppose instead of our additional observation having values x = 15 and y = -45, we instead observe x = 15 and y = -15. We can create a new data frame, dat_new2, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nWhat do you think the takeaway message is of this exercise?\n\n\nChallenge Add linear trend lines to your scatterplots from parts (f) and (h). Does this give you any additional insight into why the correlations may have changed in different ways with the addition of a new observation?"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-1-get-to-know-the-data-1",
    "href": "activities/L03-slr-introduction.html#exercise-1-get-to-know-the-data-1",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nUse an appropriate function to look at the first few rows of the data.\n\n\nhead(lifts)\n## # A tibble: 6 × 21\n##   Name        Sex   Event Equipment   Age BodyweightKg Best3SquatKg Best3BenchKg\n##   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n## 1 Natalya Po… F     D     Raw        37           58.4          NA          NA  \n## 2 Fatima Rod… F     SBD   Single-p…  NA           74.8          NA          NA  \n## 3 Josh Kelley M     SBD   Single-p…  NA           72.4         147.         97.5\n## 4 Timothy Ca… M     D     Raw        16           72.9          NA          NA  \n## 5 M Moynihan  M     B     Raw        NA           67.5          NA         100  \n## 6 Lucas Wegr… M     B     Raw        23.5        103.           NA         188. \n## # ℹ 13 more variables: Best3DeadliftKg &lt;dbl&gt;, TotalKg &lt;dbl&gt;, Place &lt;chr&gt;,\n## #   Dots &lt;dbl&gt;, Wilks &lt;dbl&gt;, Glossbrenner &lt;dbl&gt;, Goodlift &lt;dbl&gt;, Tested &lt;chr&gt;,\n## #   Country &lt;chr&gt;, State &lt;chr&gt;, Date &lt;date&gt;, MeetCountry &lt;chr&gt;, MeetState &lt;chr&gt;\n\n\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\n\n\ndim(lifts)\n## [1] 100000     21\n\n\nA case represents an individual lifter at a single weightlifting competition.\nIt looks like some meets may be missing if they weren’t detected by the web scraper used by the maintainers of the Open Powerlifting database. They don’t describe in detail the process used for transferring PDFs of results to their database, so it’s unclear what errors in transcription might have resulted. Still, it’s worth taking a moment to appreciate the labor they put into making these results available for passionate powerlifters to explore."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-2-mutating-our-data-1",
    "href": "activities/L03-slr-introduction.html#exercise-2-mutating-our-data-1",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\nlifts &lt;- lifts %&gt;% \n    mutate(SWR = TotalKg / BodyweightKg)\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable-1",
    "href": "activities/L03-slr-introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable-1",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet’s get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\n\n\nlifts %&gt;%\n  ggplot(aes(SWR)) +\n  geom_histogram(bins = 10, col = \"black\")\n\n\n\n\n\n\n\n\nlifts %&gt;% summarize(mean(SWR, na.rm = TRUE), min(SWR, na.rm = TRUE), max(SWR, na.rm = TRUE), sd(SWR, na.rm = TRUE))\n## # A tibble: 1 × 4\n##   `mean(SWR, na.rm = TRUE)` `min(SWR, na.rm = TRUE)` `max(SWR, na.rm = TRUE)`\n##                       &lt;dbl&gt;                    &lt;dbl&gt;                    &lt;dbl&gt;\n## 1                      4.42                    0.183                     12.5\n## # ℹ 1 more variable: `sd(SWR, na.rm = TRUE)` &lt;dbl&gt;\n\n\nWrite a good paragraph interpreting the plot and numerical summaries.\n\nStrength-to-weight (SWR) ratio ranges from 0.18 to 12.46, with a mean SWR of 4.4. SWR varies about 2.08 units above and below the mean. We observe that most SWRs appear to be centered between 4 and 7, with a slight right-skew to the data. The distribution of SWRs appears to be unimodal."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-4-data-visualization---two-quantitative-variables-1",
    "href": "activities/L03-slr-introduction.html#exercise-4-data-visualization---two-quantitative-variables-1",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe’d like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a “point cloud”) allows us to do this! The code below creates a scatterplot of body weight vs. SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\na & b. In our plot aesthetics, we now have two variables listed (an “x” and a “y”) as opposed to just a single variable. The “geom” for a scatterplot is geom_point. Otherwise, the code structure remains very similar!\n\nIn general, it seems as though higher body weights are associated with lower SWRs. Once body weight (in kg) is greater than 50, the relationship between body weight and SWR appears to be weakly negative, and roughly linear. The points are very dispersed, indicating that there is a good amount of variation in this relationship (hence the term “weak”)."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-5-scatterplots---patterns-in-point-clouds-1",
    "href": "activities/L03-slr-introduction.html#exercise-5-scatterplots---patterns-in-point-clouds-1",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\nThis doesn’t change my answer much (but it may have changed yours, and that’s okay!). It does appear as though there is a weakly negative relationship between body weight and SWR, particularly once body weight is above a certain value.\nI would say that yes, a linear relationship here seems reasonable! Even though there is some curvature in the smoothed trend line early on, that is based on very few data points. Those data points with low body weights aren’t enough to convince me that the relationship couldn’t be roughly linear between body weight and SWR."
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-6-correlation-1",
    "href": "activities/L03-slr-introduction.html#exercise-6-correlation-1",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\n\nI would describe the correlation between body weight and SWR as weak and negative.\nI’ll guess -0.1, since the line is negative, and the points are very dispersed around the line!"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-7-computing-correlation-in-r-1",
    "href": "activities/L03-slr-introduction.html#exercise-7-computing-correlation-in-r-1",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n## # A tibble: 1 × 1\n##   `cor(SWR, BodyweightKg, use = \"complete.obs\")`\n##                                            &lt;dbl&gt;\n## 1                                        -0.0392\n\nSo close to our guess!"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-8-limitations-of-correlation-1",
    "href": "activities/L03-slr-introduction.html#exercise-8-limitations-of-correlation-1",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\n\n# correlation between x1, y1\nanscombe %&gt;% summarize(cor(x1, y1))\n##   cor(x1, y1)\n## 1   0.8164205\n\n# correlation between x2, y2\nanscombe %&gt;% summarize(cor(x2, y2))\n##   cor(x2, y2)\n## 1   0.8162365\n\n# correlation between x3, y3\nanscombe %&gt;% summarize(cor(x3, y3))\n##   cor(x3, y3)\n## 1   0.8162867\n\n# correlation between x4, y4\nanscombe %&gt;% summarize(cor(x4, y4))\n##   cor(x4, y4)\n## 1   0.8165214\n\n\nEach of these correlations are nearly the same!\nEach of these correlations is relatively strong, and positive, since 0.8 is positive and closer to 1 than 0.\n\n\n\n# scatterplot: x1, y1\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# scatterplot: x2, y2\nanscombe %&gt;%\n  ggplot(aes(x = x2, y = y2)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# scatterplot: x3, y3\nanscombe %&gt;%\n  ggplot(aes(x = x3, y = y3)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# scatterplot: x4, y4\nanscombe %&gt;%\n  ggplot(aes(x = x4, y = y4)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe message of this exercise is that data visualization is important in addition to numerical summaries! Many different sets of points can have nearly the same correlation, but display very different patterns in point clouds upon closer inspection. Reporting correlation alone is not enough to summarize the relationship between two quantitative variables, and should be accompanied by a scatter plot!"
  },
  {
    "objectID": "activities/L03-slr-introduction.html#exercise-10-correlation-and-extreme-values-1",
    "href": "activities/L03-slr-introduction.html#exercise-10-correlation-and-extreme-values-1",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 10: Correlation and extreme values",
    "text": "Exercise 10: Correlation and extreme values\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\n\n\n\n# scatterplot\ndat %&gt;% \n  ggplot(aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe correlation between x and y is moderately strong and negative.\nI’ll guess -0.6, since the relationship is negative and is sort of in-between weak and strong.\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x, y))\n##    cor(x, y)\n## 1 -0.8295483\n\n\n\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\n\n\n\n# scatterplot\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x1, y1))\n##   cor(x1, y1)\n## 1  -0.8573567\n\nOur correlation stayed roughly the same with the addition of this new point!\n\n\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\n\n\n\n# scatterplot\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point()\n\n\n\n\n\n\n\n\n# correlation\ndat_new2 %&gt;% summarize(cor(x2, y2))\n##   cor(x2, y2)\n## 1  -0.2924792\n\nThe correlation changes quite a bit with the addition of this new point! Something to note is that this new point does not follow the rough linear trend that the original points had, that the first point we considered adding also had. This line seems way off base, comparatively!\n\nThe takeaway message here is that even though both of these additional points might be considered “outliers” because they have extreme x values, one changes the relationship between x and y much more than the other. In this case, the second point we considered would be influential because it changes the observed relationship between all x’s and y’s much more than the first point we considered. Not all “outliers” are considered equal!\n\n\n\n\n\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#learning-goals",
    "href": "activities/L04-slr-formalization.html#learning-goals",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula for a simple linear regression model with a quantitative predictor\nWrite R code to fit a linear regression model\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute expected / predicted / fitted values and residuals from a linear regression model formula\nInterpret predicted values and residuals in the context of the data\nExplain the connection between residuals and the least squares criterion"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#readings-and-videos",
    "href": "activities/L04-slr-formalization.html#readings-and-videos",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSimple linear regression Part 1: motivation & scatterplots\nSimple linear regression Part 2: correlation\nSimple linear regression Part 3: simple linear regression models\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-1-get-to-know-the-data",
    "href": "activities/L04-slr-formalization.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nCreate a new code chunk to look at the first few rows of the data and learn how much data (in terms of cases and variables) we have.\n\nWhat does a case represent?\nHow many and what kinds of variables do we have?\nThinking about the who, what, when, where, why, and how of this data, which of the 5W’s + H seem most relevant to our investigations? Explain your thoughts."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "href": "activities/L04-slr-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nLet’s get acquainted with the riders_registered variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "href": "activities/L04-slr-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe’d like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nWhat type of plot would be appropriate to visualize this relationship? Sketch and describe what you expect this plot to look like.\nCreate an appropriate plot using ggplot(). How does the plot compare to what you predicted?\nAdd the following two lines after your plot to add a linear (blue) and curved (red) smoothing line. What do you notice? Is a simple linear regression model appropriate for this data?\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nYOUR_PLOT +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-4-filtering-our-data",
    "href": "activities/L04-slr-formalization.html#exercise-4-filtering-our-data",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\nThe relationship between registered riders and temperature looks linear below 80 degrees. We can use the filter() function from the dplyr package to subset our cases. (We’ll learn techniques soon for handling this nonlinear relationship.)\nIf we wanted to only keep cases where registered ridership was greater than 2000, we would use the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nNEW_DATASET_NAME &lt;- bikes %&gt;% \n    filter(riders_registered &gt; 2000)\n\nAdapt the example above to create a new dataset called bikes_sub that only keeps cases where the felt temperature is less than 80 degrees."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "href": "activities/L04-slr-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet’s fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n\n\nUsing the model summary output, complete the following model formula:\nE[riders_registered | temp_feel] = ___ + ___ * temp_feel\nInterpret the intercept in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Is the intercept meaningful in this situation?\nInterpret the slope in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-6-predictions-and-residuals",
    "href": "activities/L04-slr-formalization.html#exercise-6-predictions-and-residuals",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don’t worry about the syntax – we haven’t learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n\n\nPeak back at the scatterplot. Identify which point corresponds to August 17, 2012. Is it close to the trend? Were there more riders than expected or fewer than expected?\nUse your model formula from the previous exercise to predict the ridership on August 17, 2012 from the temperature on that day. (That is, where do days with this temperature fall on the model trend line? How many registered riders would we expect on a 53.816 degree day?)\nCheck your part b calculation using the predict() function. Take careful note of the syntax – there’s a lot going on!\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n\n\nCalculate the residual or prediction error. How far does the observed ridership fall from the model prediction?\nresidual = observed y - predicted y = ???\nAre positive residuals above or below the trend line? When we have positive residuals, does the model over- or under-estimate ridership? Repeat these questions for negative residuals.\nFor an 85 degree day, how many registered riders would we expect? Do you think it’s a good idea to make this prediction? (Revisit the visualization and filtering we did in Exercises 3 and 4.)"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-7-changing-temperature-units-challenge",
    "href": "activities/L04-slr-formalization.html#exercise-7-changing-temperature-units-challenge",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 7: Changing temperature units (CHALLENGE)",
    "text": "Exercise 7: Changing temperature units (CHALLENGE)\nSuppose we had measured temperature in degrees Celsius rather than degrees Fahrenheit. How do you think our intercept and slope estimates, and their coefficient interpretations, would change?"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#reflection",
    "href": "activities/L04-slr-formalization.html#reflection",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Reflection",
    "text": "Reflection\nStatistics is a particular kind of language and collection of tools for channeling curiosity to improve our world.\nReview the learning objectives at the top of this file and the flow of today’s activity. How do the concepts we practiced today facilitate curiosity?\n\nResponse: Put your response here."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#render-your-work",
    "href": "activities/L04-slr-formalization.html#render-your-work",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-8-ridership-and-windspeed",
    "href": "activities/L04-slr-formalization.html#exercise-8-ridership-and-windspeed",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet’s pull together everything that you’ve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\n\n\n# Get a short summary of this model\n\n\nSummarize your observations from the visualizations.\nWrite out a formula for the model trend.\nInterpret both the intercept and the windspeed coefficient. (Note: What does a negative slope indicate?)\nUse this model to predict the ridership on August 17, 2012 and calculate the corresponding residual. (Note: You’ll first need to find the windspeed on this date!)"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-9-data-drills-filter-select-summarize",
    "href": "activities/L04-slr-formalization.html#exercise-9-data-drills-filter-select-summarize",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 9: Data drills (filter, select, summarize)",
    "text": "Exercise 9: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We’ll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nThus far, in the dplyr grammar you’ve seen 3 verbs or action words: summarize(), select(), filter(). Try out the following code and then summarize the point of the summarize() function:\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n\n\n\nVerb 2: select\nTry out the following code and then summarize the point of the select() function:\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n\n\n\nVerb 3: filter\nTry out the following code and then summarize the point of the filter() function:\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-10-your-turn",
    "href": "activities/L04-slr-formalization.html#exercise-10-your-turn",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 10: Your turn",
    "text": "Exercise 10: Your turn\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\n\n# Keep only information about the humidity and day of week using a different approach\n\n# Keep only information for Sundays\n\n# Keep only information for Sundays with temperatures below 50\n\n# Calculate the maximum and minimum temperatures"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-1-get-to-know-the-data-1",
    "href": "activities/L04-slr-formalization.html#exercise-1-get-to-know-the-data-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\ndim(bikes)\n## [1] 731  15\n\nhead(bikes)\n## # A tibble: 6 × 15\n##   date       season  year month day_of_week weekend holiday temp_actual\n##   &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;lgl&gt;   &lt;chr&gt;         &lt;dbl&gt;\n## 1 2011-01-01 winter  2011 Jan   Sat         TRUE    no             57.4\n## 2 2011-01-02 winter  2011 Jan   Sun         TRUE    no             58.8\n## 3 2011-01-03 winter  2011 Jan   Mon         FALSE   no             46.5\n## 4 2011-01-04 winter  2011 Jan   Tue         FALSE   no             46.8\n## 5 2011-01-05 winter  2011 Jan   Wed         FALSE   no             48.7\n## 6 2011-01-06 winter  2011 Jan   Thu         FALSE   no             47.1\n## # ℹ 7 more variables: temp_feel &lt;dbl&gt;, humidity &lt;dbl&gt;, windspeed &lt;dbl&gt;,\n## #   weather_cat &lt;chr&gt;, riders_casual &lt;dbl&gt;, riders_registered &lt;dbl&gt;,\n## #   riders_total &lt;dbl&gt;\n\n\nA case represents a day of the year.\nWe have 15 variables broadly concerning weather, day of week information, whether the day is a holiday.\nLots of answers are reasonable here! When and where seem to be particularly relevant because this is for a rideshare based in Washington DC with data from 2011-2012. Ridership likely changes a lot from city to city and over time."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable-1",
    "href": "activities/L04-slr-formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nThe distribution of the riders_registered variable looks fairly symmetric. On average there are about 3600 registered riders per day (mean = 3656, median = 3662). On any given day, the number of registered riders is about 1560 from the mean. There seem to be a small number of low outliers (minimum ridership was 20).\n\nggplot(bikes, aes(x = riders_registered)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\nggplot(bikes, aes(y = riders_registered)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\nsummary(bikes$riders_registered)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##      20    2497    3662    3656    4776    6946\n\nbikes %&gt;% \n    summarize(sd(riders_registered))\n## # A tibble: 1 × 1\n##   `sd(riders_registered)`\n##                     &lt;dbl&gt;\n## 1                   1560."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature-1",
    "href": "activities/L04-slr-formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe’d like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nScatterplot (outcome and predictor are both quantitative)\n\n\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nIf we only displayed the red line of best fit on the plot, we might miss the slight downward trend at the highest temperatures that we can see more clearly with the blue curve of best fit. A linear model is not appropriate if fit to the whole range of the data, but there does seem to be a linear relationship between ridership and temperature below 80 degrees Fahrenheit.\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-4-filtering-our-data-1",
    "href": "activities/L04-slr-formalization.html#exercise-4-filtering-our-data-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nbikes_sub &lt;- bikes %&gt;% \n    filter(temp_feel &lt; 80)"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation-1",
    "href": "activities/L04-slr-formalization.html#exercise-5-model-fitting-and-coefficient-interpretation-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet’s fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n## \n## Call:\n## lm(formula = riders_registered ~ temp_feel, data = bikes_sub)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3681.8  -928.3   -98.6   904.9  3496.7 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -2486.412    421.379  -5.901 7.37e-09 ***\n## temp_feel      86.493      6.464  13.380  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1267 on 428 degrees of freedom\n## Multiple R-squared:  0.2949, Adjusted R-squared:  0.2933 \n## F-statistic:   179 on 1 and 428 DF,  p-value: &lt; 2.2e-16\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n##                Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) -2486.41180 421.379174 -5.900652 7.368345e-09\n## temp_feel      86.49251   6.464247 13.380135 2.349753e-34\n\n\nE[riders_registered | temp_feel] = -2486.41180 + 86.49251 * temp_feel\nIntercept interpretation: On days that feel like 0 degrees Fahrenheit, we can expect an average of -2486.41180 riders—a negative number of riders doesn’t make sense! This results because of extrapolation—0 degrees is so far below the minimum temperature in the data. We only have information on the relationship between ridership and temperature in the ~40-100 degree range and have no idea what that relationship looks like outside that range.\nSlope interpretation: Every 1 degree increase in feeling temperature is associated with an average of about 86 more riders."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-6-predictions-and-residuals-1",
    "href": "activities/L04-slr-formalization.html#exercise-6-predictions-and-residuals-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don’t worry about the syntax – we haven’t learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n## # A tibble: 1 × 2\n##   riders_registered temp_feel\n##               &lt;dbl&gt;     &lt;dbl&gt;\n## 1              5665      53.8\n\n\nMore riders than expected – the point is far above the trend line\n-2486.41180 + 86.49251 * 53.816 = 2168.269\nWe get the same result with predict():\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n##        1 \n## 2168.269\n\n\nresidual = 5665 - 2168.269 = 3496.731. On August 17, 2012, there were 3496.731 more riders than would be expected from our model.\n\nPositive residuals are above the trend line—we under-estimate ridership.\nNegative residuals are below the trend line—we over-estimate ridership.\n\nOn an 85 degree day, we would predict 4865.452 riders. Even though we can compute this prediction, it’s not a good idea because of extrapolation–the data that we used to fit our model was filtered to days less than 80 degrees.\n\n\n-2486.41180 + 86.49251 * 85\n## [1] 4865.452\npredict(bike_mod, newdata = data.frame(temp_feel = 85))\n##        1 \n## 4865.451"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-7-changing-temperature-units-challenge-1",
    "href": "activities/L04-slr-formalization.html#exercise-7-changing-temperature-units-challenge-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 7: Changing temperature units (CHALLENGE)",
    "text": "Exercise 7: Changing temperature units (CHALLENGE)\nIf we had measured temperature in degrees Celsius rather than degrees Fahrenheit, both the intercept and slope should change. The intercept would now represent 0 degrees Celsius (32 degrees Fahrenheit) and a one unit change in temperature is now 1 degree Celsius (1.8 degrees Fahrenheit)."
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-8-ridership-and-windspeed-1",
    "href": "activities/L04-slr-formalization.html#exercise-8-ridership-and-windspeed-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet’s pull together everything that you’ve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\nggplot(bikes, aes(x = windspeed, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\n\n\n\n\n\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\nbike_mod2 &lt;- lm(riders_registered ~ windspeed, data = bikes)\n\n# Get a short summary of this model\ncoef(summary(bike_mod2))\n##               Estimate Std. Error   t value      Pr(&gt;|t|)\n## (Intercept) 4490.09761  149.65992 30.002005 2.023179e-129\n## windspeed    -65.34145   10.86299 -6.015053  2.844453e-09\n\n\nThere’s a weak, negative relationship – ridership tends to be smaller on windier days.\nE[riders_registered | windspeed] = 4490.09761 - 65.34145 windspeed\n\nIntercept: On days with no wind, we’d expect around 4490 riders. (0 is a little below the minimum of the observed data, but not by much! So extrapolation in interpreting the intercept isn’t a huge concern.)\nSlope: Every 1mph increase in windspeed is associated with a ridership decrease of 65 riders on average.\n\nSee the code below to predict ridership on August 17, 2012 and calculate the corresponding residual. Note that this residual is smaller than the residual from the temperature model (that residual was 3496.731). This indicates that August 17 was more of an outlier in ridership given the temperature than the windspeed.\n\n\nbikes %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, windspeed)\n## # A tibble: 1 × 2\n##   riders_registered windspeed\n##               &lt;dbl&gt;     &lt;dbl&gt;\n## 1              5665      15.5\n\n# prediction\n4490.09761 - 65.34145 * 15.50072\n## [1] 3477.258\n\n# residual \n5665 - 3477.258\n## [1] 2187.742"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-9-data-drills-filter-select-summarize-1",
    "href": "activities/L04-slr-formalization.html#exercise-9-data-drills-filter-select-summarize-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 9: Data drills (filter, select, summarize)",
    "text": "Exercise 9: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We’ll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nsummarize() calculates numerical summaries of variables (columns).\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n## # A tibble: 1 × 2\n##   `mean(temp_feel)` `mean(humidity)`\n##               &lt;dbl&gt;            &lt;dbl&gt;\n## 1              52.0            0.544\n\n\n\nVerb 2: select\nselect() selects variables (columns).\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n## # A tibble: 10 × 2\n##    date       temp_feel\n##    &lt;date&gt;         &lt;dbl&gt;\n##  1 2011-01-01      64.7\n##  2 2011-01-02      63.8\n##  3 2011-01-03      49.0\n##  4 2011-01-04      51.1\n##  5 2011-01-05      52.6\n##  6 2011-01-06      53.0\n##  7 2011-01-07      50.8\n##  8 2011-01-08      46.6\n##  9 2011-01-09      42.5\n## 10 2011-01-10      45.6\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n## # A tibble: 10 × 3\n##    humidity riders_registered day_of_week\n##       &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806               654 Sat        \n##  2    0.696               670 Sun        \n##  3    0.437              1229 Mon        \n##  4    0.590              1454 Tue        \n##  5    0.437              1518 Wed        \n##  6    0.518              1518 Thu        \n##  7    0.499              1362 Fri        \n##  8    0.536               891 Sat        \n##  9    0.434               768 Sun        \n## 10    0.483              1280 Mon\n\n\n\nVerb 3: filter\nfilter() keeps only days (rows) that meet the given condition(s).\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n## # A tibble: 7 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-03      49.0    0.437              1229 Mon        \n## 2 2011-01-04      51.1    0.590              1454 Tue        \n## 3 2011-01-05      52.6    0.437              1518 Wed        \n## 4 2011-01-06      53.0    0.518              1518 Thu        \n## 5 2011-01-07      50.8    0.499              1362 Fri        \n## 6 2011-01-08      46.6    0.536               891 Sat        \n## 7 2011-01-10      45.6    0.483              1280 Mon\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n## # A tibble: 2 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-01      64.7    0.806               654 Sat        \n## 2 2011-01-08      46.6    0.536               891 Sat\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")\n## # A tibble: 1 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-08      46.6    0.536               891 Sat"
  },
  {
    "objectID": "activities/L04-slr-formalization.html#exercise-10-your-turn-1",
    "href": "activities/L04-slr-formalization.html#exercise-10-your-turn-1",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 10: Your turn",
    "text": "Exercise 10: Your turn\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\nnew_bikes %&gt;% \n    select(humidity, day_of_week)\n## # A tibble: 10 × 2\n##    humidity day_of_week\n##       &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806 Sat        \n##  2    0.696 Sun        \n##  3    0.437 Mon        \n##  4    0.590 Tue        \n##  5    0.437 Wed        \n##  6    0.518 Thu        \n##  7    0.499 Fri        \n##  8    0.536 Sat        \n##  9    0.434 Sun        \n## 10    0.483 Mon\n\n# Keep only information about the humidity and day of week using a different approach\nnew_bikes %&gt;% \n    select(-date, -temp_feel, -riders_registered)\n## # A tibble: 10 × 2\n##    humidity day_of_week\n##       &lt;dbl&gt; &lt;chr&gt;      \n##  1    0.806 Sat        \n##  2    0.696 Sun        \n##  3    0.437 Mon        \n##  4    0.590 Tue        \n##  5    0.437 Wed        \n##  6    0.518 Thu        \n##  7    0.499 Fri        \n##  8    0.536 Sat        \n##  9    0.434 Sun        \n## 10    0.483 Mon\n\n# Keep only information for Sundays\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sun\")\n## # A tibble: 2 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-02      63.8    0.696               670 Sun        \n## 2 2011-01-09      42.5    0.434               768 Sun\n\n# Keep only information for Sundays with temperatures below 50\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sun\", temp_feel &lt; 50)\n## # A tibble: 1 × 5\n##   date       temp_feel humidity riders_registered day_of_week\n##   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n## 1 2011-01-09      42.5    0.434               768 Sun\n\n# Calculate the maximum and minimum temperatures\nnew_bikes %&gt;% \n    summarize(min(temp_feel), max(temp_feel))\n## # A tibble: 1 × 2\n##   `min(temp_feel)` `max(temp_feel)`\n##              &lt;dbl&gt;            &lt;dbl&gt;\n## 1             42.5             64.7"
  }
]