---
title: "08/09. Introduction to multiple linear regression"
subtitle: "Notes and in-class exercises"
format: 
  html:
    embed-resources: true
    toc: true
eval: false # change this to "true" if you want to render a complete .qmd    
---

-   Download the `.qmd` file for this activity [here](../activity_templates/08_mlr_intro.qmd).

# Notes

## Learning goals

By the end of this lesson, you should be familiar with:

- some limitations of **simple linear regression**
- the general goals behind **multiple linear regression**
- strategies for *visualizing* and *interpreting* multiple linear regression models of $y$ vs 2 predictors, 1 quantitative and 1 categorical
- how additional quantitative or categorical predictors impact the physical representation of a model

## Readings and videos

Please watch the following video **before** class.

- [Interpreting multivariate models](https://www.youtube.com/watch?v=DnXwu1OWgMM) ([slides](https://drive.google.com/file/d/1fiJL1IbReg6RJmjxRideYzYTyQtWR3Or/view?usp=sharing))


# Exercises

Let's explore some data on penguins.
First, enter `install.packages("palmerpenguins")` in the *console* (not this Quarto file).
Then load the `penguins` data using the code chunk below.
You can find a **codebook** for these data by typing `?penguins` in your *console* (not this Quarto file).


```{r warning=FALSE, message=FALSE}
# Load packages
library(readr)
library(ggplot2)
library(dplyr)

# Load data
library(palmerpenguins)
data(penguins)
penguins <- penguins %>% 
  filter(species != "Adelie", bill_length_mm < 57, !is.na(sex))

# Check it out
head(penguins)
```


Our goal is to build a model that we can use to get good predictions of penguins' flipper ("arm") lengths.

## Review Exercise 1: Visualizing bivariate relationships

Consider two potential predictors of flipper length: a penguin's bill length, and the species of penguin.

Let's first visualize how each of these predictors is related to flipper length:

```{r}
penguins %>% 
  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + 
  geom_ ____t() + 
  geom_smooth(method = "lm", se = FALSE)+
  theme_classic()
```

```{r}
penguins %>% 
  ggplot(aes(y = flipper_length_mm, x = species)) + 
  geom_ ____() + 
  theme_classic()
```

## Review Exercise 2: model the bivariate relationships

Let's fit 2 simple linear regression models of `flipper_length_mm` by penguin `bill_length_mm` and `species`: 

```{r}
summary(lm(flipper_length_mm ~ bill_length_mm, penguins))
```

**Review:** How do we interpret the `bill_length_mm` coefficient from this model?

> Your answer

```{r}
summary(lm(flipper_length_mm ~ species, penguins))
```

**Review:** How do we interpret the intercept and `speciesGentoo` coefficient from this model?

> Your answer

What do these visualizations and models tell us? Do you think it would be useful to consider both bill length *and* species as predictors?

> Your answer


## Exercise 3: Visualizing the model

We've learned how to visualize the relationship of `flipper_length_mm` by `bill_length_mm` alone:

```{r}
penguins %>% 
  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + 
  geom_point()
```

a. THINK: How might we change the scatterplot points to *also* indicate information about penguin `species`? (There's more than 1 approach!)

b. Try out your idea by modifying the code below. If you get stuck, talk with the tables around you!

```{r}
penguins %>%
  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, ___ = ___)) +
  geom_point()
```

c. THINK: Reflect on this plot--how do you think a *multiple* regression model of `flipper_length_mm` using *both* of these predictors would be represented?

b. Check your intuition below by modifying the code below to include `species` in this plot, as you did in Exercise 1.

```{r}
penguins %>%
  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, ___ = ___)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```




## Exercise 4: Intuition

Your plot in Exercise 2 demonstrated that the **multiple linear regression model** of `flipper_length_mm` by `bill_length_mm` and `species` is represented by 2 lines, each defined by a slope and an intercept. 

Let's interpret the punchlines!

For each question, provide an answer along with evidence from the model lines that supports your answer.

a. What's the relationship between `flipper_length_mm` and `species`, no matter a penguin's `bill_length_mm`? 


b. What's the relationship between `flipper_length_mm` and `bill_length_mm`, no matter a penguin's `species`?


c. Does the rate of increase in `flipper_length_mm` with `bill_length_mm` differ between the two `species`?

d. Do the intercepts for `flipper_length_mm` (i.e., the expected flipper length when `bill_length_mm` = 0) appear to differ between the two `species`?

## Exercise 5: Fitting a multiple linear regression model

Fitting a multiple linear regression model in R is very straightforward, using the familiar `lm()` function:

```{r}
# Build the model
penguin_mod <- lm(flipper_length_mm ~ bill_length_mm + species, data = penguins)

# Summarize the model
summary(penguin_mod)
```


a. In the `lm()` function, how did we communicate that we wanted to model `flipper_length_mm` by both `bill_length_mm` and `species`?


b. Using the coefficient estimates from the model summary output, complete the following model formula:    
    
    E[flipper_length_mm | bill_length_mm, speciesGentoo] = ___ + ___ * bill_length_mm + ___ * speciesGentoo


### Interlude: MLR formula and coefficient interpretation

::: {.callout-note collapse="false"}

In general, a **multiple linear regression model** of $y$ with $p$ multiple predictors $(X_1, X_2, ..., X_p)$ is represented by the following formula:

$$E[Y \mid X_1, X_2, ..., X_p] = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p$$

Put another way, multiple linear regression means that we are estimating the value of our response variable $Y$ as a **linear combination** of $p > 1$ different predictors ($X_1, X_2, ..., X_p$). 

**Principles of interpretation**

We can interpret the coefficients from this model as follows:    

- $\beta_0$ ("beta 0") is the y-intercept. It describes the average value of $Y$ when $X_1, X_2,..., X_p$ are all 0, i.e. when all quantitative predictors are set to 0 and the categorical predictors are set to their reference levels.    

- $\beta_i$ ("beta i") is the coefficient of the predictor $X_i$.    

- If $X_i$ is quantitative, $\beta_i$ describes the average change in $Y$ associated with a 1-unit increase in $X_i$ while at a fixed set of the other $X$.  
    
- If $X_i$ represents a category of a categorical variable, $\beta_i$ describes the average difference in $Y$ between this category and the reference category, while at a fixed set of the other $X$. 
    
- The phrase "while at a fixed set of the other $X$" in the interpretations above is **crucial**. This is because our typical interpretation of $\beta_i$ as "expected change in Y per 1 unit change in $X_i$" (or average difference in $Y$ between a category and the reference category) can only be valid if we assume that "all else is equal." We cannot, for example, interpret the slope coefficient in the penguin model above if we are comparing penguins of different species!

Two other (more common) ways of stating this caveat in your interpretation of a given $\beta_i$ as "...holding predictors $X_j, X_k, ..., X_p$ constant" or "...adjusting for predictors $X_j, X_k, ..., X_p$."

:::

## Exercise 6: Sub-model formulas

Ok. We now have a single *formula* for the model.
And we observed earlier that this formula is represented by two lines: one describing the relationship between `flipper_length_mm` and `bill_length_mm` for `Chinstrap` penguins and the other for `Gentoo` penguins.
Let's bring these ideas together.
Utilize the model formula to obtain the equations of these two lines, i.e. to obtain the *sub-model formulas* for the 2 species. Hint: Plug speciesGentoo = 0 and speciesGentoo = 1.        
    
Chinstrap: flipper_length_mm = ___ + ___ bill_length_mm

Gentoo:    flipper_length_mm = ___ + ___ bill_length_mm


**Challenge question:** What are some pros and cons of fitting a multiple linear regression model versus subsetting the data by species and fitting two separate simple linear regression models?

> Your answer


## Exercise 7: coefficients -- physical interpretation

Reflecting on Exercise 5, let's interpret what the model coefficients tell us about the *physical* properties of the two 2 sub-model lines.

Choose the correct option given in parentheses:        

a. The intercept coefficient, 127.75, is the intercept of the line for (Chinstrap / Gentoo) penguins.

b. The `bill_length_mm` coefficient, 1.40, is the (intercept / slope) of both lines.

c. The `speciesGentoo` coefficient, 22.85, indicates that the (intercept / slope) of the line for Gentoo is 22.85mm higher than the (intercept / slope) of the line for Chinstrap. Similarly, since the lines are parallel, the line for Gentoo is 22.85mm higher than the line for Chinstrap at any `bill_length_mm`.
    
    



## Exercise 8: coefficients -- contextual interpretation

Next, interpret each coefficient in a *contextually* meaningful way.
What do they tell us about penguin flipper lengths?!

a. Interpret 127.75 (intercept of the Chinstrap line).

b. Interpret 1.40 (slope of both lines). For both Chinstrap and Gentoo penguins, we expect...

c. Interpret 22.85. At any `bill_length_mm`, we expect...
    
    




## Exercise 9: Prediction

Now that we better understand the model, let's use it to predict flipper lengths!
Recall the model summary and visualization:

```{r}
coef(summary(penguin_mod))

penguins %>% 
  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, color = species)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE)
```

a. Predict the flipper length of a Chinstrap penguin with a 50mm long bill. Make sure your calculation is consistent with the plot.       

```{r}
127.75 + 1.40*___ + 22.85*___
```    


b. Predict the flipper length of a Gentoo penguin with a 50mm long bill. Make sure your calculation is consistent with the plot.       

```{r}
127.75 + 1.40*___ + 22.85*___
```    

c. Use the `predict()` function to confirm your predictions in parts a and b.

```{r}
# Confirm the calculation in part a
predict(penguin_mod,
        newdata = data.frame(bill_length_mm = ___, species = "___"))

# Confirm the calculation in part b
predict(penguin_mod,
        newdata = data.frame(bill_length_mm = ___, species = "___"))
```






## Exercise 10: R-squared

Finally, recall that improving our predictions was one motivation for multiple linear regression (using 2 predictors instead of 1).

To this end, consider the R-squared values of the simple linear regression models that use just *one* predictor at a time:

```{r}
summary(lm(flipper_length_mm ~ bill_length_mm, data = penguins))$r.squared

summary(lm(flipper_length_mm ~ species, data = penguins))$r.squared
```


a. If you had to use only *1* of our 2 predictors, which would give the better predictions of `flipper_length_mm`?



b. What do you *guess* is the R-squared of our multiple regression model that uses *both* of these predictors? Why?



c. Check your intuition. How does the R-squared of our multiple regression model compare to that of the 2 separate simple linear regression models? 

```{r}
summary(penguin_mod)$r.squared
```

# More practice

The following exercises will explore how to visualize, fit, and interpret multiple linear regression models using other combinations of quantitative/categorical predictors.

Let's revisit the bikeshare data:

```{r warning = FALSE, message = FALSE}
# Load packages & import data
library(readr)
library(ggplot2)
library(dplyr)

bikes <- read_csv("https://mac-stat.github.io/data/bikeshare.csv") %>% 
  rename(rides = riders_registered)
```

Our goal is to understand how / why registered ridership from day to day.

To this end, we'll build various **multiple linear regression** models of `rides` by different combinations of the possible predictors.

```{r}
# Check out the data
head(bikes)
```

# MLR with 1 quantitative, 1 categorical predictor

## Exercise 1: Review visualization

Let's build a model of `rides` by `windspeed` (quantitative) and `weekend` status (categorical).

a. Write a model statement for this regression model.

b. Plot & describe, in words, the relationship between these 3 variables.


```{r}
# Plot of rides vs windspeed & weekend
# HINT: Start with a plot of rides vs windspeed, then add an aesthetic for weekend!

```



## Exercise 2: Review model

Let's build the model. Run the following code:

```{r}
bike_model_1 <- lm(rides ~ windspeed + weekend, data = bikes)
coef(summary(bike_model_1))
```

The model formula with our coefficient estimates filled in is therefore:

E[rides | windspeed, weekendTRUE] = 4738.38 - 63.97 * windspeed - 925.16 * weekendTRUE

This model formula is represented by 2 lines, one corresponding to weekends and the other to weekdays. Simplify the model formula above for weekdays and weekends:       
    
weekdays: rides = ___ - ___ windspeed   

weekends: rides = ___ - ___ windspeed



## Exercise 3: Review coefficient interpretation


a. The intercept coefficient, 4738.38, represents the *intercept* of the sub-model for weekdays, the reference category. What's its *contextual* interpretation?
    

b. The `windspeed` coefficient, -63.97, represents the *shared slope* of the weekend and weekday sub-models. What's its *contextual* interpretation?
    

c. The `weekendTRUE` coefficient, -925.16, represents the *change in intercept* for the weekend vs weekday sub-model. What's its *contextual* interpretation?


# MLR with 2 categorical predictors

## Exercise 4: 2 categorical predictors -- visualization

Thus far, we've explored a couple examples of multiple regression models that have 2 predictors, 1 quantitative and 1 categorical.

So what happens when *both* predictors are categorical?!

To this end, let's model `rides` by `weekend` status and `season`.

The below code plots `rides` vs `season`.

Modify this code to *also* include information about `weekend`.

HINT: Remember the visualization *principle* that additional categorical predictors require some sort of grouping mechanism / mechanism that distinguishes between the 2 groups.

```{r}
# rides vs season
bikes %>% 
  ggplot(aes(y = rides, x = season)) + 
  geom_boxplot()

rides vs season AND weekend
bikes %>%
  ggplot(aes(y = rides, x = season, ___ = ___)) +
  geom_boxplot()
```



## Exercise 5: follow-up

a. Describe (in words) the relationship of ridership with season & weekend status.



b. A model of `rides` by `season` alone would be represented by only 4 expected outcomes, 1 for each season. Considering this and the plot above, how do you *anticipate* a model of `rides` by `season` and `weekend` status will be represented?        
    - 2 lines, 1 for each weekend status
    - 8 lines, 1 for each possible combination of season & weekend
    - 2 expected outcomes, 1 for each weekend status
    - 8 expected outcomes, 1 for each possible combination of season & weekend
    




## Exercise 6: 2 categorical predictors -- build the model

Let's build the multiple regression model of `rides` vs `season` and `weekend`:
    
```{r}
bike_model_2 <- lm(rides ~ weekend + season, bikes)
coef(summary(bike_model_2))
```

Thus the model formula with coefficient estimates filled in is given by:

E[rides | weekend, season] = 4260.45 - 912.33 weekendTRUE - 116.38 seasonspring + 438.44 seasonsummer - 1719.06 seasonwinter

a. Use this model to predict the ridership on the following days:    
    
```{r}
# a fall weekday
4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___

# a winter weekday    
4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___

# a fall weekend day        
4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___

# a winter weekend day
4260.45 - 912.33*___ - 116.38*___  + 438.44*___ - 1719.06*___
```



b. We only made 4 predictions here. How many *possible* predictions does this model produce? Is this consistent with your intuition in the previous exercise?





## Exercise 7: 2 categorical predictors -- interpret the model

Use your above predictions and visualization to fill in the below interpretations of the model coefficients.

Hint: What is the consequence of plugging in 0 or 1 for the different `weekend` and `season` categories?    


a. Interpreting 4260: On average, we expect there to be 4260 riders on (weekdays/weekends) during the (fall/spring/summer/winter).    

b. Interpreting -912: On average, *in any season*, we expect there to be 912 (more/fewer) riders on weekends than on ___.

An alternative interpretation: On average, we expect there to be 912 (more/fewer) riders on weekends than on ___, adjusting for season.

c. Interpreting -1719: On average, *on both weekdays and weekends*, we expect there to be 1719 (more/fewer) riders in winter than in ___.

An alternative interpretation: On average, we expect there to be 1719 (more/fewer) riders in winter than in ___, controlling for weekday status.





# MLR with 2 quantitative predictors


## Exercise 8: 2 quantitative predictors -- visualization   

Next, consider the relationship between `rides` and 2 *quantitative* predictors: `windspeed` and `temp_feel`.
Check out the plot of this relationship below.

This reflect the visualization *principle* that quantitative variables require some sort of numerical scaling mechanism -- `rides` and `windspeed` get numerical axes, and `temp_feel` gets a color scale.

![](https://mac-stat.github.io/images/155/bikes_multivar_3.png)

Modify the code below to recreate this plot.

```{r}
bikes %>%
  ggplot(aes(y = rides, x = windspeed, ___ = ___)) +
  geom_point()
```




## Exercise 9: follow-up

Describe (in words) the relationship of ridership with windspeed & temperature.


    






## Exercise 10: 2 quantitative predictors -- modeling

Let's build the multiple regression model of `rides` vs `windspeed` and `temp_feel`:
    
```{r}
bike_model_3 <- lm(rides ~ windspeed + temp_feel, data = bikes)
coef(summary(bike_model_3))
```

Thus the model formula with coefficient estimates filled in is given by,

E[rides | windspeed, temp_feel] = -24.06 - 36.54 windspeed + 55.52 temp_feel


a. Interpret the intercept coefficient, -24.06, in context.



b. Interpret the `windspeed` coefficient, -36.54, in context. 


c. Interpret the `temp_feel` coefficient, 55.52, in context. 



    
    
# Comparing MLR models

## Exercise 11: Which is "best"?

We've now observed 3 different models of ridership, each having 2 predictors.
The R-squared values of these models, along with those of the simple linear regression models with each predictor alone, are summarized below.
    
model                     predictors                R-squared
------------------------- ------------------------- ------------
`bike_model_1`            `windspeed` & `weekend`   0.119
`bike_model_2`            `weekend` & `season`      0.349
`bike_model_3`            `windspeed` & `temp_feel` 0.310
`bike_model_4`            `windspeed`               0.047
`bike_model_5`            `temp_feel`               0.296
`bike_model_6`            `weekend`                 0.074
`bike_model_7`            `season`                  0.279


a. Which model does the best job of explaining the variability in ridership from day to day?


b. If you could only pick one predictor, which would it be?


c. What happens to R-squared when we add a second predictor to our model, and why does this make sense? For example, how does the R-squared for model 1 (with both windspeed and weekend) compare to those of model 4 (only windspeed) and model 6 (only weekend)?


d. Are 2 predictors always better than 1? Provide evidence and explain why this makes sense.





## Exercise 12: Principles of interpretation

These exercises have revealed some **principles** behind interpreting model coefficients, summarized below.

Review and confirm that these make sense.



---

# Even more practice

The following exercises provide extra practice.
If you don't get to these during class, you're encouraged to try them outside class.


## Exercise 13: Practice 1

Consider the relationship of `rides` vs `weekend` and `weather_cat`.    

a. Construct a visualization of this relationship.   
b. Construct a model of this relationship.    
c. Interpret the first 3 model coefficients. 



## Exercise 14: Practice 2

Consider the relationship of `rides` vs `temp_feel` and `humidity`.    

a. Construct a visualization of this relationship.    
b. Construct a model of this relationship.    
c. Interpret the first 3 model coefficients.    
    



## Exercise 15: Practice 3

Consider the relationship of `rides` vs `temp_feel` and `weather_cat`.    

a. Construct a visualization of this relationship.    
b. Construct a model of this relationship.    
c. Interpret the first 3 model coefficients.    
    


## Exercise 16: CHALLENGE

We've explored models with 2 predictors.
What about 3 predictors?!
Consider the relationship of `rides` vs `temp_feel`, `humidity`, AND `weekend`.

a. Construct a visualization of this relationship.    
b. Construct a model of this relationship.    
c. Interpret each model coefficient.    


<br><br><br><br><br><br>

[Solutions](../solutions/08_mlr_intro.qmd)
